{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the Brown Corpus\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Categories: 15\n"
     ]
    }
   ],
   "source": [
    "print('Total Categories:', len(brown.categories()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "print (brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There', 'were', 'thirty-eight', 'patients', 'on', 'the', 'bus', 'the', 'morning', 'I', 'left', 'for', 'Hanover', ',', 'most', 'of', 'them', 'disturbed', 'and', 'hallucinating', '.'], ['An', 'interne', ',', 'a', 'nurse', 'and', 'two', 'attendants', 'were', 'in', 'charge', 'of', 'us', '.'], ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized sentences\n",
    "brown.sents(categories='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('There', 'EX'), ('were', 'BED'), ('thirty-eight', 'CD'), ('patients', 'NNS'), ('on', 'IN'), ('the', 'AT'), ('bus', 'NN'), ('the', 'AT'), ('morning', 'NN'), ('I', 'PPSS'), ('left', 'VBD'), ('for', 'IN'), ('Hanover', 'NP'), (',', ','), ('most', 'AP'), ('of', 'IN'), ('them', 'PPO'), ('disturbed', 'VBN'), ('and', 'CC'), ('hallucinating', 'VBG'), ('.', '.')], [('An', 'AT'), ('interne', 'NN'), (',', ','), ('a', 'AT'), ('nurse', 'NN'), ('and', 'CC'), ('two', 'CD'), ('attendants', 'NNS'), ('were', 'BED'), ('in', 'IN'), ('charge', 'NN'), ('of', 'IN'), ('us', 'PPO'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tagged sentences\n",
    "brown.tagged_sents(categories='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There were thirty-eight patients on the bus the morning I left for Hanover , most of them disturbed and hallucinating .', 'An interne , a nurse and two attendants were in charge of us .', \"I felt lonely and depressed as I stared out the bus window at Chicago's grim , dirty West Side .\", 'It seemed incredible , as I listened to the monotonous drone of voices and smelled the fetid odors coming from the patients , that technically I was a ward of the state of Illinois , going to a hospital for the mentally ill .', 'I suddenly thought of Mary Jane Brennan , the way her pretty eyes could flash with anger , her quiet competence , the gentleness and sweetness that lay just beneath the surface of her defenses .']\n"
     ]
    }
   ],
   "source": [
    "# get sentences in natural form\n",
    "sentences = brown.sents(categories='mystery')\n",
    "sentences = [' '.join(sentence_token) for sentence_token in sentences]\n",
    "print (sentences[0:5]) # printing first 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('patients', 'NNS'), ('bus', 'NN'), ('morning', 'NN'), ('Hanover', 'NP'), ('interne', 'NN'), ('nurse', 'NN'), ('attendants', 'NNS'), ('charge', 'NN'), ('bus', 'NN'), ('window', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# get tagged words\n",
    "tagged_words = brown.tagged_words(categories='mystery')\n",
    "# get nouns from tagged words\n",
    "nouns = [(word, tag) for word, tag in tagged_words if any(noun_tag in tag for noun_tag in ['NP', 'NN'])]\n",
    "print (nouns[0:10]) # prints the first 10 nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('man', 106), ('time', 82), ('door', 80), ('car', 69), ('room', 65), ('Mr.', 63), ('way', 61), ('office', 50), ('eyes', 48), ('hand', 46)]\n"
     ]
    }
   ],
   "source": [
    "# build frequency distribution for nouns\n",
    "nouns_freq = nltk.FreqDist([word for word, tag in nouns])\n",
    "# print top 10 occuring nouns\n",
    "print (nouns_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the Reuters Corpus\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Categories: 90\n",
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "print ('Total Categories:', len(reuters.categories()))\n",
    "print (reuters.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"YUGOSLAV ECONOMY WORSENED IN 1986 , BANK DATA SHOWS National Bank economic data for 1986 shows that Yugoslavia ' s trade deficit grew , the inflation rate rose , wages were sharply higher , the money supply expanded and the value of the dinar fell .\", 'The trade deficit for 1986 was 2 . 012 billion dlrs , 25 . 7 pct higher than in 1985 .', 'The trend continued in the first three months of this year as exports dropped by 17 . 8 pct , in hard currency terms , to 2 . 124 billion dlrs .', 'Yugoslavia this year started quoting trade figures in dinars based on current exchange rates , instead of dollars based on a fixed exchange rate of 264 . 53 dinars per dollar .', \"Yugoslavia ' s balance of payments surplus with the convertible currency area fell to 245 mln dlrs in 1986 from 344 mln in 1985 .\"]\n"
     ]
    }
   ],
   "source": [
    "# get sentences in housing and income categories\n",
    "sentences = reuters.sents(categories=['housing', 'income'])\n",
    "sentences = [' '.join(sentence_tokens) for sentence_tokens in sentences]\n",
    "print (sentences[0:5]) # prints the first 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/16118', 'test/18534', 'test/18540', 'test/18664', 'test/18665', 'test/18672', 'test/18911', 'test/19875', 'test/20106', 'test/20116', 'training/1035', 'training/1036', 'training/10602', 'training/10604', 'training/11170', 'training/11665', 'training/2618', 'training/29', 'training/3105', 'training/3708', 'training/3720', 'training/3723', 'training/3898', 'training/5883', 'training/5886', 'training/6000', 'training/6067', 'training/6197', 'training/7005', 'training/7006', 'training/7015', 'training/7036', 'training/7098', 'training/7099', 'training/9615']\n"
     ]
    }
   ],
   "source": [
    "# fileid based access\n",
    "print (reuters.fileids(categories=['housing', 'income']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['YUGOSLAV', 'ECONOMY', 'WORSENED', 'IN', '1986', ',', 'BANK', 'DATA', 'SHOWS', 'National', 'Bank', 'economic', 'data', 'for', '1986', 'shows', 'that', 'Yugoslavia', \"'\", 's', 'trade', 'deficit', 'grew', ',', 'the', 'inflation', 'rate', 'rose', ',', 'wages', 'were', 'sharply', 'higher', ',', 'the', 'money', 'supply', 'expanded', 'and', 'the', 'value', 'of', 'the', 'dinar', 'fell', '.'], ['The', 'trade', 'deficit', 'for', '1986', 'was', '2', '.', '012', 'billion', 'dlrs', ',', '25', '.', '7', 'pct', 'higher', 'than', 'in', '1985', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "print (reuters.sents(fileids=[u'test/16118', u'test/18534']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the Wordnet Corpus\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('hike.n.01'), Synset('rise.n.09'), Synset('raise.n.01'), Synset('hike.v.01'), Synset('hike.v.02')]\n"
     ]
    }
   ],
   "source": [
    "word = 'hike' # taking hike as our word of interest\n",
    "# get word synsets\n",
    "word_synsets = wn.synsets(word)\n",
    "print (word_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset Name: hike.n.01\n",
      "POS Tag: n\n",
      "Definition: a long walk usually for exercise or pleasure\n",
      "Examples: ['she enjoys a hike in her spare time']\n",
      "\n",
      "Synset Name: rise.n.09\n",
      "POS Tag: n\n",
      "Definition: an increase in cost\n",
      "Examples: ['they asked for a 10% rise in rates']\n",
      "\n",
      "Synset Name: raise.n.01\n",
      "POS Tag: n\n",
      "Definition: the amount a salary is increased\n",
      "Examples: ['he got a 3% raise', 'he got a wage hike']\n",
      "\n",
      "Synset Name: hike.v.01\n",
      "POS Tag: v\n",
      "Definition: increase\n",
      "Examples: ['The landlord hiked up the rents']\n",
      "\n",
      "Synset Name: hike.v.02\n",
      "POS Tag: v\n",
      "Definition: walk a long way, as for pleasure or physical exercise\n",
      "Examples: ['We were hiking in Colorado', 'hike the Rockies']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get details for each synonym in synset\n",
    "for synset in word_synsets:\n",
    "    print ('Synset Name:', synset.name())\n",
    "    print ('POS Tag:', synset.pos())\n",
    "    print ('Definition:', synset.definition())\n",
    "    print ('Examples:', synset.examples())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing and Understanding Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Text Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alice = gutenberg.raw(fileids='carroll-alice.txt')\n",
    "sample_text = 'We will discuss briefly about the basic syntax, structure and design philosophies. There is a defined hierarchical syntax for Python code which you should remember when writing code! Python is a really powerful programming language!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144395"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total characters in Alice in Wonderland\n",
    "len(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
      "\n",
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was\n"
     ]
    }
   ],
   "source": [
    "# First 100 characters in the corpus\n",
    "print (alice[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in sample_text: 3\n",
      "Sample text sentences :-\n",
      "['We will discuss briefly about the basic syntax, structure and design '\n",
      " 'philosophies.',\n",
      " 'There is a defined hierarchical syntax for Python code which you should '\n",
      " 'remember when writing code!',\n",
      " 'Python is a really powerful programming language!']\n",
      "\n",
      "Total sentences in alice: 1625\n",
      "First 5 sentences in alice:-\n",
      "[\"[Alice's Adventures in Wonderland by Lewis Carroll 1865]\\n\\nCHAPTER I.\",\n",
      " 'Down the Rabbit-Hole\\n'\n",
      " '\\n'\n",
      " 'Alice was beginning to get very tired of sitting by her sister on the\\n'\n",
      " 'bank, and of having nothing to do: once or twice she had peeped into the\\n'\n",
      " 'book her sister was reading, but it had no pictures or conversations in\\n'\n",
      " \"it, 'and what is the use of a book,' thought Alice 'without pictures or\\n\"\n",
      " \"conversation?'\",\n",
      " 'So she was considering in her own mind (as well as she could, for the\\n'\n",
      " 'hot day made her feel very sleepy and stupid), whether the pleasure\\n'\n",
      " 'of making a daisy-chain would be worth the trouble of getting up and\\n'\n",
      " 'picking the daisies, when suddenly a White Rabbit with pink eyes ran\\n'\n",
      " 'close by her.',\n",
      " 'There was nothing so VERY remarkable in that; nor did Alice think it so\\n'\n",
      " \"VERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\",\n",
      " 'Oh dear!']\n"
     ]
    }
   ],
   "source": [
    "default_st = nltk.sent_tokenize\n",
    "alice_sentences = default_st(text=alice)\n",
    "sample_sentences = default_st(text=sample_text)\n",
    "\n",
    "print ('Total sentences in sample_text:', len(sample_sentences))\n",
    "print ('Sample text sentences :-')\n",
    "pprint(sample_sentences)\n",
    "print ('\\nTotal sentences in alice:', len(alice_sentences))\n",
    "print ('First 5 sentences in alice:-')\n",
    "pprint(alice_sentences[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize text of other languages\n",
    "from nltk.corpus import europarl_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157171\n",
      " \n",
      "Wiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sit\n"
     ]
    }
   ],
   "source": [
    "german_text = europarl_raw.german.raw(fileids='ep-00-01-17.de')\n",
    "# Total characters in the corpus\n",
    "print (len(german_text))\n",
    "# First 100 characters in the corpus\n",
    "print (german_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.tokenize.punkt.PunktSentenceTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "german_sentences_def = default_st(text=german_text,language='german')\n",
    "\n",
    "# loading german text tokenizer into a PunktSentenceTokenizer instance\n",
    "german_tokenizer = nltk.data.load(resource_url='tokenizers/punkt/german.pickle')\n",
    "german_sentences = german_tokenizer.tokenize(german_text)\n",
    "\n",
    "# verify the type of german_tokenizer\n",
    "# should be PunktSentenceTokenizer\n",
    "print (type(german_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      " \n",
      "Wiederaufnahme der Sitzungsperiode Ich erkläre die am Freitag , dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen , wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe , daß Sie schöne Ferien hatten .\n",
      "Wie Sie feststellen konnten , ist der gefürchtete \" Millenium-Bug \" nicht eingetreten .\n",
      "Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden .\n",
      "Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen .\n",
      "Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen - , allen Opfern der Stürme , insbesondere in den verschiedenen Ländern der Europäischen Union , in einer Schweigeminute zu gedenken .\n"
     ]
    }
   ],
   "source": [
    "print (german_sentences_def == german_sentences)\n",
    "# print first 5 sentences of the corpus\n",
    "for sent in german_sentences[0:5]:\n",
    "    print (sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We will discuss briefly about the basic syntax, structure and design '\n",
      " 'philosophies.',\n",
      " 'There is a defined hierarchical syntax for Python code which you should '\n",
      " 'remember when writing code!',\n",
      " 'Python is a really powerful programming language!']\n"
     ]
    }
   ],
   "source": [
    "punkt_st = nltk.tokenize.PunktSentenceTokenizer()\n",
    "sample_sentences = punkt_st.tokenize(sample_text)\n",
    "pprint(sample_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We will discuss briefly about the basic syntax, structure and design '\n",
      " 'philosophies.',\n",
      " 'There is a defined hierarchical syntax for Python code which you should '\n",
      " 'remember when writing code!',\n",
      " 'Python is a really powerful programming language!']\n"
     ]
    }
   ],
   "source": [
    "SENTENCE_TOKENS_PATTERN = '(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\.|\\?|\\!)\\s'\n",
    "regex_st = nltk.tokenize.RegexpTokenizer(pattern=SENTENCE_TOKENS_PATTERN,gaps=True)\n",
    "sample_sentences = regex_st.tokenize(sample_text)\n",
    "pprint(sample_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', 'was', \"n't\", 'that', 'quick', 'and', 'he', 'could', \"n't\", 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The brown fox wasn't that quick and he couldn't win the race\"\n",
    "\n",
    "default_wt = nltk.word_tokenize\n",
    "words = default_wt(sentence)\n",
    "print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', 'was', \"n't\", 'that', 'quick', 'and', 'he', 'could', \"n't\", 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "treebank_wt = nltk.TreebankWordTokenizer()\n",
    "words = treebank_wt.tokenize(sentence)\n",
    "print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', 'wasn', 't', 'that', 'quick', 'and', 'he', 'couldn', 't', 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "# pattern to identify tokens themselves\n",
    "TOKEN_PATTERN = '\\w+'\n",
    "regex_wt = nltk.RegexpTokenizer(pattern=TOKEN_PATTERN,gaps=False)\n",
    "words = regex_wt.tokenize(sentence)\n",
    "print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', \"wasn't\", 'that', 'quick', 'and', 'he', \"couldn't\", 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "# pattern to identify gaps in tokens\n",
    "GAP_PATTERN = '\\s+'\n",
    "regex_wt = nltk.RegexpTokenizer(pattern=GAP_PATTERN,gaps=True)\n",
    "words = regex_wt.tokenize(sentence)\n",
    "print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3), (4, 9), (10, 13), (14, 20), (21, 25), (26, 31), (32, 35), (36, 38), (39, 47), (48, 51), (52, 55), (56, 60)]\n",
      "['The', 'brown', 'fox', \"wasn't\", 'that', 'quick', 'and', 'he', \"couldn't\", 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "# get start and end indices of each token and then print them\n",
    "word_indices = list(regex_wt.span_tokenize(sentence))\n",
    "print (word_indices)\n",
    "print ([sentence[start:end] for start, end in word_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', 'wasn', \"'\", 't', 'that', 'quick', 'and', 'he', 'couldn', \"'\", 't', 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "wordpunkt_wt = nltk.WordPunctTokenizer()\n",
    "words = wordpunkt_wt.tokenize(sentence)\n",
    "print (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'brown', 'fox', \"wasn't\", 'that', 'quick', 'and', 'he', \"couldn't\", 'win', 'the', 'race']\n"
     ]
    }
   ],
   "source": [
    "whitespace_wt = nltk.WhitespaceTokenizer()\n",
    "words = whitespace_wt.tokenize(sentence)\n",
    "print (words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [\"The brown fox wasn't that quick and he couldn't win the race\", \"Hey that's a great deal! I just bought a phone for $199\", \"@@You'll (learn) a **lot** in the book. Python is an amazing language !@@\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    word_tokens = [nltk.word_tokenize(sentence) for sentence in sentences]\n",
    "    return word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['The', 'brown', 'fox', 'was', \"n't\", 'that', 'quick', 'and', 'he', 'could', \"n't\", 'win', 'the', 'race']], [['Hey', 'that', \"'s\", 'a', 'great', 'deal', '!'], ['I', 'just', 'bought', 'a', 'phone', 'for', '$', '199']], [['@', '@', 'You', \"'ll\", '(', 'learn', ')', 'a', '**lot**', 'in', 'the', 'book', '.'], ['Python', 'is', 'an', 'amazing', 'language', '!'], ['@', '@']]]\n"
     ]
    }
   ],
   "source": [
    "token_list = [tokenize_text(text) for text in corpus]\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_characters_after_tokenization(tokens):\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_characters(tokens):\n",
    "    pattern = re.compile('[{}]'.format(re.escape(string.punctuation)))\n",
    "    # filtered_tokens = filter(None, [pattern.sub('', token) for token in tokens])\n",
    "    filtered_tokens = [re.sub(pattern, \"\", token) for token in tokens]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<generator object <listcomp>.<genexpr> at 0x7f5aaa8f2d00>,\n",
       " <generator object <listcomp>.<genexpr> at 0x7f5aaa8f2ca8>,\n",
       " <generator object <listcomp>.<genexpr> at 0x7f5aaa8f2d58>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_list_1 = [(remove_characters(tokens) for tokens in sentence_tokens) for sentence_tokens in token_list] \n",
    "filtered_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_characters_before_tokenization(sentence,keep_apostrophes=False):\n",
    "    sentence = sentence.strip()\n",
    "    if keep_apostrophes:\n",
    "        PATTERN = '[?|$|&|*|%|@|(|)|~]' # add other characters here to remove them\n",
    "        filtered_sentence = re.sub(PATTERN, '', sentence)\n",
    "    else:\n",
    "        PATTERN = '[^a-zA-Z0-9 ]' # only extract alpha-numeric characters\n",
    "        filtered_sentence = re.sub(PATTERN, '', sentence)\n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The brown fox wasnt that quick and he couldnt win the race', 'Hey thats a great deal I just bought a phone for 199', 'Youll learn a lot in the book Python is an amazing language ']\n"
     ]
    }
   ],
   "source": [
    "filtered_list_2 = [remove_characters_before_tokenization(sentence) for sentence in corpus]\n",
    "print (filtered_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The brown fox wasn't that quick and he couldn't win the race\", \"Hey that's a great deal! I just bought a phone for 199\", \"You'll learn a lot in the book. Python is an amazing language !\"]\n"
     ]
    }
   ],
   "source": [
    "cleaned_corpus = [remove_characters_before_tokenization(sentence,keep_apostrophes=True) for sentence in corpus]\n",
    "print (cleaned_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def expand_contractions(sentence, contraction_mapping):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())),flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                        if contraction_mapping.get(match)\\\n",
    "                        else contraction_mapping.get(match.lower())\n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "    \n",
    "    expanded_sentence = contractions_pattern.sub(expand_match, sentence)\n",
    "    return expanded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The brown fox was not that quick and he could not win the race', 'Hey that is a great deal! I just bought a phone for 199', 'You will learn a lot in the book. Python is an amazing language !']\n"
     ]
    }
   ],
   "source": [
    "from contractions import CONTRACTION_MAP\n",
    "\n",
    "expanded_corpus = [expand_contractions(sentence, CONTRACTION_MAP) for sentence in cleaned_corpus]\n",
    "print (expanded_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    stopword_list = nltk.corpus.stopwords.words('english')\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['The', 'brown', 'fox', \"n't\", 'quick', 'could', \"n't\", 'win', 'race']], [['Hey', \"'s\", 'great', 'deal', '!'], ['I', 'bought', 'phone', '$', '199']], [['@', '@', 'You', \"'ll\", '(', 'learn', ')', '**lot**', 'book', '.'], ['Python', 'amazing', 'language', '!'], ['@', '@']]]\n"
     ]
    }
   ],
   "source": [
    "corpus_tokens = [tokenize_text(text) for text in corpus]\n",
    "filtered_list_3 = [[remove_stopwords(tokens) for tokens in sentence_tokens] for sentence_tokens in corpus_tokens]\n",
    "print (filtered_list_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting Repeating Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Word: finalllyy\n",
      "Step: 2 Word: finallly\n",
      "Step: 3 Word: finally\n",
      "Step: 4 Word: finaly\n",
      "Final word: finaly\n"
     ]
    }
   ],
   "source": [
    "old_word = 'finalllyyy'\n",
    "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "match_substitution = r'\\1\\2\\3'\n",
    "step = 1\n",
    "\n",
    "while True:\n",
    "    # remove one repeated character\n",
    "    new_word = repeat_pattern.sub(match_substitution,old_word)\n",
    "    if new_word != old_word:\n",
    "        print ('Step: {} Word: {}'.format(step, new_word))\n",
    "        step += 1 # update step\n",
    "        # update old word to last substituted state\n",
    "        old_word = new_word\n",
    "        continue\n",
    "    else:\n",
    "        print (\"Final word:\", new_word)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1 Word: finalllyy\n",
      "Step: 2 Word: finallly\n",
      "Step: 3 Word: finally\n",
      "Final correct word: finally\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "old_word = 'finalllyyy'\n",
    "repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "match_substitution = r'\\1\\2\\3'\n",
    "step = 1\n",
    "\n",
    "while True:\n",
    "    # check for semantically correct word\n",
    "    if wordnet.synsets(old_word):\n",
    "        print (\"Final correct word:\", old_word)\n",
    "        break\n",
    "\n",
    "    # remove one repeated character\n",
    "    new_word = repeat_pattern.sub(match_substitution,old_word)\n",
    "    if new_word != old_word:\n",
    "        print ('Step: {} Word: {}'.format(step, new_word))\n",
    "        step += 1 # update step\n",
    "        # update old word to last substituted state\n",
    "        old_word = new_word\n",
    "        continue\n",
    "    else:\n",
    "        print (\"Final word:\", new_word)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_repeated_characters(tokens):\n",
    "    repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "    match_substitution = r'\\1\\2\\3'\n",
    "    def replace(old_word):\n",
    "        if wordnet.synsets(old_word):\n",
    "            return old_word\n",
    "        new_word = repeat_pattern.sub(match_substitution, old_word)\n",
    "        return replace(new_word) if new_word != old_word else new_word\n",
    "\n",
    "    correct_tokens = [replace(word) for word in tokens]\n",
    "    return correct_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'schooool', 'is', 'realllllyyy', 'amaaazingggg']\n",
      "['My', 'school', 'is', 'really', 'amazing']\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = 'My schooool is realllllyyy amaaazingggg'\n",
    "sample_sentence_tokens = tokenize_text(sample_sentence)[0]\n",
    "print (sample_sentence_tokens)\n",
    "print (remove_repeated_characters(sample_sentence_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correcting Spellings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokens(text):\n",
    "    \"\"\"\n",
    "    Get all words from the corpus\n",
    "    \"\"\"\n",
    "    return re.findall('[a-z]+', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORDS = tokens(open('big.txt').read())\n",
    "WORD_COUNTS = collections.Counter(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 80030), ('of', 40025), ('and', 38313), ('to', 28766), ('in', 22050), ('a', 21155), ('that', 12512), ('he', 12401), ('was', 11410), ('it', 10681)]\n"
     ]
    }
   ],
   "source": [
    "# top 10 words in the corpus\n",
    "print (WORD_COUNTS.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits0(word): \n",
    "    \"\"\"\n",
    "    Return all strings that are zero edits away \n",
    "    from the input word (i.e., the word itself).\n",
    "    \"\"\"\n",
    "    return {word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    \"\"\"\n",
    "    Return all strings that are one edit away \n",
    "    from the input word.\n",
    "    \"\"\"\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    def splits(word):\n",
    "        \"\"\"\n",
    "        Return a list of all possible (first, rest) pairs \n",
    "        that the input word is made of.\n",
    "        \"\"\"\n",
    "        return [(word[:i], word[i:]) \n",
    "                for i in range(len(word)+1)]\n",
    "                \n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits2(word):\n",
    "    \"\"\"Return all strings that are two edits away \n",
    "    from the input word.\n",
    "    \"\"\"\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    \"\"\"\n",
    "    Return the subset of words that are actually \n",
    "    in our WORD_COUNTS dictionary.\n",
    "    \"\"\"\n",
    "    return {w for w in words if w in WORD_COUNTS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fianlly'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input word\n",
    "word = 'fianlly'\n",
    "# zero edit distance from input word\n",
    "edits0(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns null set since it is not a valid word\n",
    "known(edits0(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'afianlly',\n",
       " 'aianlly',\n",
       " 'bfianlly',\n",
       " 'bianlly',\n",
       " 'cfianlly',\n",
       " 'cianlly',\n",
       " 'dfianlly',\n",
       " 'dianlly',\n",
       " 'efianlly',\n",
       " 'eianlly',\n",
       " 'faanlly',\n",
       " 'faianlly',\n",
       " 'fainlly',\n",
       " 'fanlly',\n",
       " 'fbanlly',\n",
       " 'fbianlly',\n",
       " 'fcanlly',\n",
       " 'fcianlly',\n",
       " 'fdanlly',\n",
       " 'fdianlly',\n",
       " 'feanlly',\n",
       " 'feianlly',\n",
       " 'ffanlly',\n",
       " 'ffianlly',\n",
       " 'fganlly',\n",
       " 'fgianlly',\n",
       " 'fhanlly',\n",
       " 'fhianlly',\n",
       " 'fiaally',\n",
       " 'fiaanlly',\n",
       " 'fiablly',\n",
       " 'fiabnlly',\n",
       " 'fiaclly',\n",
       " 'fiacnlly',\n",
       " 'fiadlly',\n",
       " 'fiadnlly',\n",
       " 'fiaelly',\n",
       " 'fiaenlly',\n",
       " 'fiaflly',\n",
       " 'fiafnlly',\n",
       " 'fiaglly',\n",
       " 'fiagnlly',\n",
       " 'fiahlly',\n",
       " 'fiahnlly',\n",
       " 'fiailly',\n",
       " 'fiainlly',\n",
       " 'fiajlly',\n",
       " 'fiajnlly',\n",
       " 'fiaklly',\n",
       " 'fiaknlly',\n",
       " 'fiallly',\n",
       " 'fially',\n",
       " 'fialnlly',\n",
       " 'fialnly',\n",
       " 'fiamlly',\n",
       " 'fiamnlly',\n",
       " 'fianally',\n",
       " 'fianaly',\n",
       " 'fianblly',\n",
       " 'fianbly',\n",
       " 'fianclly',\n",
       " 'fiancly',\n",
       " 'fiandlly',\n",
       " 'fiandly',\n",
       " 'fianelly',\n",
       " 'fianely',\n",
       " 'fianflly',\n",
       " 'fianfly',\n",
       " 'fianglly',\n",
       " 'fiangly',\n",
       " 'fianhlly',\n",
       " 'fianhly',\n",
       " 'fianilly',\n",
       " 'fianily',\n",
       " 'fianjlly',\n",
       " 'fianjly',\n",
       " 'fianklly',\n",
       " 'fiankly',\n",
       " 'fianlaly',\n",
       " 'fianlay',\n",
       " 'fianlbly',\n",
       " 'fianlby',\n",
       " 'fianlcly',\n",
       " 'fianlcy',\n",
       " 'fianldly',\n",
       " 'fianldy',\n",
       " 'fianlely',\n",
       " 'fianley',\n",
       " 'fianlfly',\n",
       " 'fianlfy',\n",
       " 'fianlgly',\n",
       " 'fianlgy',\n",
       " 'fianlhly',\n",
       " 'fianlhy',\n",
       " 'fianlily',\n",
       " 'fianliy',\n",
       " 'fianljly',\n",
       " 'fianljy',\n",
       " 'fianlkly',\n",
       " 'fianlky',\n",
       " 'fianll',\n",
       " 'fianlla',\n",
       " 'fianllay',\n",
       " 'fianllb',\n",
       " 'fianllby',\n",
       " 'fianllc',\n",
       " 'fianllcy',\n",
       " 'fianlld',\n",
       " 'fianlldy',\n",
       " 'fianlle',\n",
       " 'fianlley',\n",
       " 'fianllf',\n",
       " 'fianllfy',\n",
       " 'fianllg',\n",
       " 'fianllgy',\n",
       " 'fianllh',\n",
       " 'fianllhy',\n",
       " 'fianlli',\n",
       " 'fianlliy',\n",
       " 'fianllj',\n",
       " 'fianlljy',\n",
       " 'fianllk',\n",
       " 'fianllky',\n",
       " 'fianlll',\n",
       " 'fianllly',\n",
       " 'fianllm',\n",
       " 'fianllmy',\n",
       " 'fianlln',\n",
       " 'fianllny',\n",
       " 'fianllo',\n",
       " 'fianlloy',\n",
       " 'fianllp',\n",
       " 'fianllpy',\n",
       " 'fianllq',\n",
       " 'fianllqy',\n",
       " 'fianllr',\n",
       " 'fianllry',\n",
       " 'fianlls',\n",
       " 'fianllsy',\n",
       " 'fianllt',\n",
       " 'fianllty',\n",
       " 'fianllu',\n",
       " 'fianlluy',\n",
       " 'fianllv',\n",
       " 'fianllvy',\n",
       " 'fianllw',\n",
       " 'fianllwy',\n",
       " 'fianllx',\n",
       " 'fianllxy',\n",
       " 'fianlly',\n",
       " 'fianllya',\n",
       " 'fianllyb',\n",
       " 'fianllyc',\n",
       " 'fianllyd',\n",
       " 'fianllye',\n",
       " 'fianllyf',\n",
       " 'fianllyg',\n",
       " 'fianllyh',\n",
       " 'fianllyi',\n",
       " 'fianllyj',\n",
       " 'fianllyk',\n",
       " 'fianllyl',\n",
       " 'fianllym',\n",
       " 'fianllyn',\n",
       " 'fianllyo',\n",
       " 'fianllyp',\n",
       " 'fianllyq',\n",
       " 'fianllyr',\n",
       " 'fianllys',\n",
       " 'fianllyt',\n",
       " 'fianllyu',\n",
       " 'fianllyv',\n",
       " 'fianllyw',\n",
       " 'fianllyx',\n",
       " 'fianllyy',\n",
       " 'fianllyz',\n",
       " 'fianllz',\n",
       " 'fianllzy',\n",
       " 'fianlmly',\n",
       " 'fianlmy',\n",
       " 'fianlnly',\n",
       " 'fianlny',\n",
       " 'fianloly',\n",
       " 'fianloy',\n",
       " 'fianlply',\n",
       " 'fianlpy',\n",
       " 'fianlqly',\n",
       " 'fianlqy',\n",
       " 'fianlrly',\n",
       " 'fianlry',\n",
       " 'fianlsly',\n",
       " 'fianlsy',\n",
       " 'fianltly',\n",
       " 'fianlty',\n",
       " 'fianluly',\n",
       " 'fianluy',\n",
       " 'fianlvly',\n",
       " 'fianlvy',\n",
       " 'fianlwly',\n",
       " 'fianlwy',\n",
       " 'fianlxly',\n",
       " 'fianlxy',\n",
       " 'fianly',\n",
       " 'fianlyl',\n",
       " 'fianlyly',\n",
       " 'fianlyy',\n",
       " 'fianlzly',\n",
       " 'fianlzy',\n",
       " 'fianmlly',\n",
       " 'fianmly',\n",
       " 'fiannlly',\n",
       " 'fiannly',\n",
       " 'fianolly',\n",
       " 'fianoly',\n",
       " 'fianplly',\n",
       " 'fianply',\n",
       " 'fianqlly',\n",
       " 'fianqly',\n",
       " 'fianrlly',\n",
       " 'fianrly',\n",
       " 'fianslly',\n",
       " 'fiansly',\n",
       " 'fiantlly',\n",
       " 'fiantly',\n",
       " 'fianully',\n",
       " 'fianuly',\n",
       " 'fianvlly',\n",
       " 'fianvly',\n",
       " 'fianwlly',\n",
       " 'fianwly',\n",
       " 'fianxlly',\n",
       " 'fianxly',\n",
       " 'fianylly',\n",
       " 'fianyly',\n",
       " 'fianzlly',\n",
       " 'fianzly',\n",
       " 'fiaolly',\n",
       " 'fiaonlly',\n",
       " 'fiaplly',\n",
       " 'fiapnlly',\n",
       " 'fiaqlly',\n",
       " 'fiaqnlly',\n",
       " 'fiarlly',\n",
       " 'fiarnlly',\n",
       " 'fiaslly',\n",
       " 'fiasnlly',\n",
       " 'fiatlly',\n",
       " 'fiatnlly',\n",
       " 'fiaully',\n",
       " 'fiaunlly',\n",
       " 'fiavlly',\n",
       " 'fiavnlly',\n",
       " 'fiawlly',\n",
       " 'fiawnlly',\n",
       " 'fiaxlly',\n",
       " 'fiaxnlly',\n",
       " 'fiaylly',\n",
       " 'fiaynlly',\n",
       " 'fiazlly',\n",
       " 'fiaznlly',\n",
       " 'fibanlly',\n",
       " 'fibnlly',\n",
       " 'ficanlly',\n",
       " 'ficnlly',\n",
       " 'fidanlly',\n",
       " 'fidnlly',\n",
       " 'fieanlly',\n",
       " 'fienlly',\n",
       " 'fifanlly',\n",
       " 'fifnlly',\n",
       " 'figanlly',\n",
       " 'fignlly',\n",
       " 'fihanlly',\n",
       " 'fihnlly',\n",
       " 'fiianlly',\n",
       " 'fiinlly',\n",
       " 'fijanlly',\n",
       " 'fijnlly',\n",
       " 'fikanlly',\n",
       " 'fiknlly',\n",
       " 'filanlly',\n",
       " 'filnlly',\n",
       " 'fimanlly',\n",
       " 'fimnlly',\n",
       " 'finally',\n",
       " 'finanlly',\n",
       " 'finlly',\n",
       " 'finnlly',\n",
       " 'fioanlly',\n",
       " 'fionlly',\n",
       " 'fipanlly',\n",
       " 'fipnlly',\n",
       " 'fiqanlly',\n",
       " 'fiqnlly',\n",
       " 'firanlly',\n",
       " 'firnlly',\n",
       " 'fisanlly',\n",
       " 'fisnlly',\n",
       " 'fitanlly',\n",
       " 'fitnlly',\n",
       " 'fiuanlly',\n",
       " 'fiunlly',\n",
       " 'fivanlly',\n",
       " 'fivnlly',\n",
       " 'fiwanlly',\n",
       " 'fiwnlly',\n",
       " 'fixanlly',\n",
       " 'fixnlly',\n",
       " 'fiyanlly',\n",
       " 'fiynlly',\n",
       " 'fizanlly',\n",
       " 'fiznlly',\n",
       " 'fjanlly',\n",
       " 'fjianlly',\n",
       " 'fkanlly',\n",
       " 'fkianlly',\n",
       " 'flanlly',\n",
       " 'flianlly',\n",
       " 'fmanlly',\n",
       " 'fmianlly',\n",
       " 'fnanlly',\n",
       " 'fnianlly',\n",
       " 'foanlly',\n",
       " 'foianlly',\n",
       " 'fpanlly',\n",
       " 'fpianlly',\n",
       " 'fqanlly',\n",
       " 'fqianlly',\n",
       " 'franlly',\n",
       " 'frianlly',\n",
       " 'fsanlly',\n",
       " 'fsianlly',\n",
       " 'ftanlly',\n",
       " 'ftianlly',\n",
       " 'fuanlly',\n",
       " 'fuianlly',\n",
       " 'fvanlly',\n",
       " 'fvianlly',\n",
       " 'fwanlly',\n",
       " 'fwianlly',\n",
       " 'fxanlly',\n",
       " 'fxianlly',\n",
       " 'fyanlly',\n",
       " 'fyianlly',\n",
       " 'fzanlly',\n",
       " 'fzianlly',\n",
       " 'gfianlly',\n",
       " 'gianlly',\n",
       " 'hfianlly',\n",
       " 'hianlly',\n",
       " 'ianlly',\n",
       " 'ifanlly',\n",
       " 'ifianlly',\n",
       " 'iianlly',\n",
       " 'jfianlly',\n",
       " 'jianlly',\n",
       " 'kfianlly',\n",
       " 'kianlly',\n",
       " 'lfianlly',\n",
       " 'lianlly',\n",
       " 'mfianlly',\n",
       " 'mianlly',\n",
       " 'nfianlly',\n",
       " 'nianlly',\n",
       " 'ofianlly',\n",
       " 'oianlly',\n",
       " 'pfianlly',\n",
       " 'pianlly',\n",
       " 'qfianlly',\n",
       " 'qianlly',\n",
       " 'rfianlly',\n",
       " 'rianlly',\n",
       " 'sfianlly',\n",
       " 'sianlly',\n",
       " 'tfianlly',\n",
       " 'tianlly',\n",
       " 'ufianlly',\n",
       " 'uianlly',\n",
       " 'vfianlly',\n",
       " 'vianlly',\n",
       " 'wfianlly',\n",
       " 'wianlly',\n",
       " 'xfianlly',\n",
       " 'xianlly',\n",
       " 'yfianlly',\n",
       " 'yianlly',\n",
       " 'zfianlly',\n",
       " 'zianlly'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one edit distance from input word\n",
    "edits1(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits1(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fapianlly',\n",
       " 'fiaolily',\n",
       " 'fzanyly',\n",
       " 'mianllyr',\n",
       " 'fianmlvly',\n",
       " 'wfianxlly',\n",
       " 'fiasnoly',\n",
       " 'jfianrly',\n",
       " 'fianellyu',\n",
       " 'fqaxnlly',\n",
       " 'fianlslcy',\n",
       " 'fzianyly',\n",
       " 'fiapnllmy',\n",
       " 'ufitnlly',\n",
       " 'fipnily',\n",
       " 'fdiaunlly',\n",
       " 'lkfianlly',\n",
       " 'fwianklly',\n",
       " 'cianlzy',\n",
       " 'yfiavnlly',\n",
       " 'efianllyj',\n",
       " 'fianlilyf',\n",
       " 'fivanwly',\n",
       " 'fbizanlly',\n",
       " 'fianlku',\n",
       " 'fiinllyc',\n",
       " 'fiaenlty',\n",
       " 'fizaplly',\n",
       " 'yfianxlly',\n",
       " 'vianllye',\n",
       " 'fiquanlly',\n",
       " 'fiabnlfly',\n",
       " 'figznlly',\n",
       " 'vianllvy',\n",
       " 'fianldyf',\n",
       " 'finlily',\n",
       " 'fiatllc',\n",
       " 'fiaxvnlly',\n",
       " 'fianlee',\n",
       " 'feianldly',\n",
       " 'fiaxnglly',\n",
       " 'rfianllo',\n",
       " 'fyianllyr',\n",
       " 'iapnlly',\n",
       " 'fianqllgy',\n",
       " 'xfiamnlly',\n",
       " 'fiaanilly',\n",
       " 'fiawllyp',\n",
       " 'fiaglbly',\n",
       " 'fiaxllty',\n",
       " 'fiianhly',\n",
       " 'fiauntlly',\n",
       " 'fianlalf',\n",
       " 'fianllmk',\n",
       " 'ifanlwy',\n",
       " 'rwanlly',\n",
       " 'fvianclly',\n",
       " 'fianllbwy',\n",
       " 'fimnslly',\n",
       " 'foianclly',\n",
       " 'fidajlly',\n",
       " 'fitnlwy',\n",
       " 'fiazlyly',\n",
       " 'ftqianlly',\n",
       " 'fkanlcy',\n",
       " 'mfianlloy',\n",
       " 'fhienlly',\n",
       " 'kianllyb',\n",
       " 'jfianlmly',\n",
       " 'fiboanlly',\n",
       " 'fiaxnllyp',\n",
       " 'fianllnyr',\n",
       " 'fiainlqly',\n",
       " 'fianiilly',\n",
       " 'fianillye',\n",
       " 'fianlwuly',\n",
       " 'fianallpy',\n",
       " 'faiansly',\n",
       " 'miganlly',\n",
       " 'fiaxnlrly',\n",
       " 'fiawllv',\n",
       " 'fanluly',\n",
       " 'fianemlly',\n",
       " 'fifnjlly',\n",
       " 'eianllky',\n",
       " 'fgiatnlly',\n",
       " 'flianllyq',\n",
       " 'fziaunlly',\n",
       " 'jfianlfly',\n",
       " 'fiacllyt',\n",
       " 'fganluy',\n",
       " 'jfianlhly',\n",
       " 'fianolyl',\n",
       " 'fianllwc',\n",
       " 'fianlqldy',\n",
       " 'pivnlly',\n",
       " 'fgfianlly',\n",
       " 'fiankklly',\n",
       " 'qfiaally',\n",
       " 'fianslu',\n",
       " 'firanxly',\n",
       " 'fiagqly',\n",
       " 'fixarnlly',\n",
       " 'fitmnlly',\n",
       " 'filanqlly',\n",
       " 'fiadenlly',\n",
       " 'fiatllv',\n",
       " 'fwanllyq',\n",
       " 'fiianllo',\n",
       " 'fianllbuy',\n",
       " 'fiamnlle',\n",
       " 'fiausly',\n",
       " 'tianllcy',\n",
       " 'fiavlily',\n",
       " 'fianljdy',\n",
       " 'fiangwy',\n",
       " 'fiaullyk',\n",
       " 'mfjianlly',\n",
       " 'fipanlky',\n",
       " 'viannlly',\n",
       " 'fijanqly',\n",
       " 'fxanljy',\n",
       " 'qfianlky',\n",
       " 'pfiamnlly',\n",
       " 'fianfla',\n",
       " 'fsanllfy',\n",
       " 'auanlly',\n",
       " 'aianmly',\n",
       " 'fiarqly',\n",
       " 'gianilly',\n",
       " 'fizanllyj',\n",
       " 'gfiahlly',\n",
       " 'figanfly',\n",
       " 'fianlzlyn',\n",
       " 'fiavloy',\n",
       " 'hfwianlly',\n",
       " 'fspianlly',\n",
       " 'fioenlly',\n",
       " 'fianlzay',\n",
       " 'ifanlxly',\n",
       " 'fkanllsy',\n",
       " 'fianolky',\n",
       " 'qfianllyi',\n",
       " 'wfdianlly',\n",
       " 'fianvllv',\n",
       " 'vefianlly',\n",
       " 'fcuanlly',\n",
       " 'fienllyl',\n",
       " 'fiakllz',\n",
       " 'flxnlly',\n",
       " 'lfiranlly',\n",
       " 'pianelly',\n",
       " 'dianglly',\n",
       " 'franllx',\n",
       " 'fuianclly',\n",
       " 'ejanlly',\n",
       " 'fiantlly',\n",
       " 'tfianily',\n",
       " 'filnblly',\n",
       " 'fixjnlly',\n",
       " 'fiaynlldy',\n",
       " 'frixanlly',\n",
       " 'fianlwlzy',\n",
       " 'fiavaly',\n",
       " 'fitntlly',\n",
       " 'gfianley',\n",
       " 'fianqlf',\n",
       " 'fianlkhy',\n",
       " 'fiahllys',\n",
       " 'fiagnnlly',\n",
       " 'fuianllyt',\n",
       " 'fizanwly',\n",
       " 'ffanwlly',\n",
       " 'filnlfly',\n",
       " 'lqanlly',\n",
       " 'fhiahnlly',\n",
       " 'fignlqly',\n",
       " 'fwianllf',\n",
       " 'fianlluay',\n",
       " 'fiapnllsy',\n",
       " 'filnvlly',\n",
       " 'fixanlmly',\n",
       " 'fiknanlly',\n",
       " 'fzanllx',\n",
       " 'fianllvg',\n",
       " 'fiapnlty',\n",
       " 'fifnnly',\n",
       " 'fiatnlloy',\n",
       " 'fijnllky',\n",
       " 'filnllr',\n",
       " 'dfianclly',\n",
       " 'fianollyp',\n",
       " 'fiaiwly',\n",
       " 'fianldlx',\n",
       " 'fianlleky',\n",
       " 'fcenlly',\n",
       " 'fianflgy',\n",
       " 'fianllvy',\n",
       " 'filanlky',\n",
       " 'fjianllyw',\n",
       " 'filvlly',\n",
       " 'nufianlly',\n",
       " 'fiynlvly',\n",
       " 'fipanllly',\n",
       " 'fanllys',\n",
       " 'efianuly',\n",
       " 'pfiafnlly',\n",
       " 'mianlwly',\n",
       " 'fienqlly',\n",
       " 'fiakbly',\n",
       " 'mfizanlly',\n",
       " 'fsianlky',\n",
       " 'filancly',\n",
       " 'iianluly',\n",
       " 'finllmy',\n",
       " 'fmanllf',\n",
       " 'fiianlny',\n",
       " 'fiaknlcy',\n",
       " 'fifqanlly',\n",
       " 'fhagnlly',\n",
       " 'fianltlxy',\n",
       " 'fianmllyw',\n",
       " 'jfidnlly',\n",
       " 'fixnllyo',\n",
       " 'fikanllyx',\n",
       " 'qianely',\n",
       " 'siannly',\n",
       " 'fifanwly',\n",
       " 'fjanllm',\n",
       " 'ftanllyf',\n",
       " 'gihanlly',\n",
       " 'pfiwanlly',\n",
       " 'fianeay',\n",
       " 'fianlsyj',\n",
       " 'fianledly',\n",
       " 'fiaisly',\n",
       " 'gfianlky',\n",
       " 'fgnianlly',\n",
       " 'fmianlily',\n",
       " 'jfianloy',\n",
       " 'fianpfly',\n",
       " 'fiaxllq',\n",
       " 'ufmianlly',\n",
       " 'fiynlply',\n",
       " 'tiacnlly',\n",
       " 'fianlyply',\n",
       " 'fiawnllby',\n",
       " 'fivanllb',\n",
       " 'fizanelly',\n",
       " 'fianilq',\n",
       " 'dfianbly',\n",
       " 'fianfllg',\n",
       " 'sfibanlly',\n",
       " 'fianhyy',\n",
       " 'fianzlyly',\n",
       " 'fiabnllyz',\n",
       " 'fiwrlly',\n",
       " 'fianlblp',\n",
       " 'fiwanllyx',\n",
       " 'pianlyy',\n",
       " 'fiannmy',\n",
       " 'ffanllk',\n",
       " 'fdanllyc',\n",
       " 'fianlsily',\n",
       " 'fgbanlly',\n",
       " 'mfianllw',\n",
       " 'kianglly',\n",
       " 'fiaxblly',\n",
       " 'fiaunlll',\n",
       " 'fiahlky',\n",
       " 'fivanlsly',\n",
       " 'fianljlc',\n",
       " 'hfiasnlly',\n",
       " 'fdkianlly',\n",
       " 'feianily',\n",
       " 'fioanllyh',\n",
       " 'fianalqy',\n",
       " 'fiatnlluy',\n",
       " 'fiaslnly',\n",
       " 'fvanlhly',\n",
       " 'fiayaly',\n",
       " 'fianlno',\n",
       " 'ffawlly',\n",
       " 'fianzy',\n",
       " 'fionllr',\n",
       " 'gianllyl',\n",
       " 'feanllye',\n",
       " 'fiuanllyp',\n",
       " 'dfianllq',\n",
       " 'fiaalpy',\n",
       " 'fiagnllyj',\n",
       " 'fqanrly',\n",
       " 'fitlly',\n",
       " 'wianllyc',\n",
       " 'ifianylly',\n",
       " 'faenlly',\n",
       " 'fmianlldy',\n",
       " 'fianuvly',\n",
       " 'fxianllly',\n",
       " 'fiapnelly',\n",
       " 'fwanlcy',\n",
       " 'fniamnlly',\n",
       " 'flahnlly',\n",
       " 'eianljly',\n",
       " 'fixnlljy',\n",
       " 'fieaully',\n",
       " 'fqanllr',\n",
       " 'fianqlyk',\n",
       " 'fivnqlly',\n",
       " 'fwianllya',\n",
       " 'fiknllyn',\n",
       " 'fiansla',\n",
       " 'fianald',\n",
       " 'fizavnlly',\n",
       " 'wianxlly',\n",
       " 'fxkianlly',\n",
       " 'olianlly',\n",
       " 'fizanltly',\n",
       " 'foanily',\n",
       " 'fianlolny',\n",
       " 'fianlqlz',\n",
       " 'cfianllgy',\n",
       " 'kfianllzy',\n",
       " 'fixanlldy',\n",
       " 'feanlnly',\n",
       " 'fianyllyc',\n",
       " 'fziuanlly',\n",
       " 'fianlmlo',\n",
       " 'fijanbly',\n",
       " 'fzanllyn',\n",
       " 'fifnllx',\n",
       " 'feanllyj',\n",
       " 'ftianlsy',\n",
       " 'feanzlly',\n",
       " 'fikzlly',\n",
       " 'fiurnlly',\n",
       " 'dfianljly',\n",
       " 'fianlfjly',\n",
       " 'fjiantlly',\n",
       " 'fiabntlly',\n",
       " 'fiuanllpy',\n",
       " 'fiqailly',\n",
       " 'fianllykv',\n",
       " 'fiantllc',\n",
       " 'fiaunally',\n",
       " 'fganlcy',\n",
       " 'mfianflly',\n",
       " 'fianlelya',\n",
       " 'fiarlwly',\n",
       " 'qzanlly',\n",
       " 'fliawlly',\n",
       " 'finnllpy',\n",
       " 'fianlbyo',\n",
       " 'fiaxldly',\n",
       " 'fisanlxly',\n",
       " 'fiyanllfy',\n",
       " 'bfianlly',\n",
       " 'fikplly',\n",
       " 'fiongly',\n",
       " 'fmiaqnlly',\n",
       " 'fianlliyb',\n",
       " 'fhanllp',\n",
       " 'fhanllz',\n",
       " 'fipnlxly',\n",
       " 'fianltll',\n",
       " 'hianllly',\n",
       " 'fianllydx',\n",
       " 'fianlss',\n",
       " 'bfianllqy',\n",
       " 'fbvnlly',\n",
       " 'hfianqly',\n",
       " 'fhianhly',\n",
       " 'fianlclyj',\n",
       " 'fgznlly',\n",
       " 'ffhanlly',\n",
       " 'fianmblly',\n",
       " 'fiandoly',\n",
       " 'fikanuly',\n",
       " 'ufianlby',\n",
       " 'fjanzlly',\n",
       " 'firanlliy',\n",
       " 'fianbllyo',\n",
       " 'eianllyi',\n",
       " 'fianlnnly',\n",
       " 'foiaally',\n",
       " 'fiacjlly',\n",
       " 'fianulyu',\n",
       " 'feanlny',\n",
       " 'xianllyx',\n",
       " 'fgankly',\n",
       " 'fdiqanlly',\n",
       " 'fazinlly',\n",
       " 'ffiantly',\n",
       " 'fiagnllqy',\n",
       " 'zimanlly',\n",
       " 'feianglly',\n",
       " 'fikanllny',\n",
       " 'fiianllx',\n",
       " 'ianlld',\n",
       " 'fiainllc',\n",
       " 'fianlldr',\n",
       " 'afilnlly',\n",
       " 'finllyj',\n",
       " 'fiazaly',\n",
       " 'ficanply',\n",
       " 'ficnllyu',\n",
       " 'fianlxya',\n",
       " 'fgiarnlly',\n",
       " 'fiapfly',\n",
       " 'fzanluy',\n",
       " 'sianlls',\n",
       " 'hfkanlly',\n",
       " 'ficanlxly',\n",
       " 'xfiabnlly',\n",
       " 'fitnlby',\n",
       " 'fihnlhy',\n",
       " 'fiwanflly',\n",
       " 'fiaylely',\n",
       " 'fianlnli',\n",
       " 'firnjlly',\n",
       " 'fiunlaly',\n",
       " 'fianwlnly',\n",
       " 'fianlylyi',\n",
       " 'fioanplly',\n",
       " 'mfianlliy',\n",
       " 'rianlily',\n",
       " 'fbiajlly',\n",
       " 'fpanllv',\n",
       " 'fixanlll',\n",
       " 'xfiganlly',\n",
       " 'fcipnlly',\n",
       " 'fgkianlly',\n",
       " 'oianclly',\n",
       " 'fganllyp',\n",
       " 'afianloly',\n",
       " 'licnlly',\n",
       " 'fiatvly',\n",
       " 'fgaolly',\n",
       " 'fiaqnlily',\n",
       " 'dianplly',\n",
       " 'hfianrly',\n",
       " 'fianllvny',\n",
       " 'fifnlyly',\n",
       " 'fibanbly',\n",
       " 'fyanlsy',\n",
       " 'fijndlly',\n",
       " 'fianllyut',\n",
       " 'fiajnlkly',\n",
       " 'wfiangly',\n",
       " 'wianllvy',\n",
       " 'fiunllc',\n",
       " 'fianlgily',\n",
       " 'fihanllfy',\n",
       " 'fiatltly',\n",
       " 'fijanlln',\n",
       " 'fwiahlly',\n",
       " 'foalnlly',\n",
       " 'rfiaglly',\n",
       " 'yfianlla',\n",
       " 'gianwly',\n",
       " 'faanllk',\n",
       " 'cfianllyk',\n",
       " 'fianlluty',\n",
       " 'fiuanvlly',\n",
       " 'fianllgx',\n",
       " 'fiyanxlly',\n",
       " 'fianqllyc',\n",
       " 'fipanllyp',\n",
       " 'ufianlly',\n",
       " 'fianmllyo',\n",
       " 'fianllbe',\n",
       " 'sianlljy',\n",
       " 'fmaqnlly',\n",
       " 'nianllya',\n",
       " 'fianlhlyb',\n",
       " 'fainlby',\n",
       " 'fiayley',\n",
       " 'fitnly',\n",
       " 'fianllymy',\n",
       " 'rianllwy',\n",
       " 'fqicnlly',\n",
       " 'pfsanlly',\n",
       " 'fiankllm',\n",
       " 'fhanully',\n",
       " 'fgianlby',\n",
       " 'fbanlqly',\n",
       " 'fyianllky',\n",
       " 'gianllly',\n",
       " 'nicnlly',\n",
       " 'fiaqnslly',\n",
       " 'fsoanlly',\n",
       " 'ifianuly',\n",
       " 'fiearlly',\n",
       " 'fianfllzy',\n",
       " 'fsanllyr',\n",
       " 'piandlly',\n",
       " 'fihnllvy',\n",
       " 'fdaenlly',\n",
       " 'fiankllty',\n",
       " 'fianillcy',\n",
       " 'ffifanlly',\n",
       " 'fianctlly',\n",
       " 'fianlczy',\n",
       " 'fiacbly',\n",
       " 'fianllwk',\n",
       " 'fiazllmy',\n",
       " 'fiaehnlly',\n",
       " 'fioanllny',\n",
       " 'fniajnlly',\n",
       " 'fiaddly',\n",
       " 'uijanlly',\n",
       " 'fiainlyly',\n",
       " 'fianlfe',\n",
       " 'fianlvyj',\n",
       " 'yianllwy',\n",
       " 'fianjllt',\n",
       " 'fiinllty',\n",
       " 'xeanlly',\n",
       " 'fianlvlys',\n",
       " 'iahlly',\n",
       " 'mfijnlly',\n",
       " 'fiandlb',\n",
       " 'fhiarlly',\n",
       " 'fizanlluy',\n",
       " 'fiaslky',\n",
       " 'nianolly',\n",
       " 'fianbfly',\n",
       " 'fisanlqy',\n",
       " 'fganllt',\n",
       " 'fianhllyk',\n",
       " 'fqanllyw',\n",
       " 'bianllry',\n",
       " 'fiwanuly',\n",
       " 'fianllbyd',\n",
       " 'xyanlly',\n",
       " 'fmipanlly',\n",
       " 'fgkanlly',\n",
       " 'fiajllym',\n",
       " 'fidnlls',\n",
       " 'fbaynlly',\n",
       " 'fkianlely',\n",
       " 'finalpy',\n",
       " 'fianolyb',\n",
       " 'kianllyx',\n",
       " 'fjianflly',\n",
       " 'fitnllc',\n",
       " 'firnlla',\n",
       " 'fianyllyy',\n",
       " 'fxianolly',\n",
       " 'fidinlly',\n",
       " 'fidnllyy',\n",
       " 'fianullny',\n",
       " 'fiagnfly',\n",
       " 'fqanllyh',\n",
       " 'nsianlly',\n",
       " 'fianltlyt',\n",
       " 'fianlhzy',\n",
       " 'finnlgly',\n",
       " 'flianlly',\n",
       " 'fianlvlm',\n",
       " 'fvianluly',\n",
       " 'efianllw',\n",
       " 'efiawlly',\n",
       " 'wianlyl',\n",
       " 'fianxvlly',\n",
       " 'fianlbyy',\n",
       " 'fiaknllhy',\n",
       " 'agfianlly',\n",
       " 'fjoianlly',\n",
       " 'fiayllq',\n",
       " 'fiannplly',\n",
       " 'fianxllyg',\n",
       " 'fliaslly',\n",
       " 'fgianllky',\n",
       " 'znanlly',\n",
       " 'fianllcn',\n",
       " 'qianuly',\n",
       " 'fimnjlly',\n",
       " 'fmanolly',\n",
       " 'flanllyf',\n",
       " 'xianllgy',\n",
       " 'pfianlldy',\n",
       " 'wianfly',\n",
       " 'fiwnlll',\n",
       " 'fimanllyg',\n",
       " 'fianlne',\n",
       " 'wfianlzy',\n",
       " 'unianlly',\n",
       " 'fdanlny',\n",
       " 'fialnlu',\n",
       " 'jianlby',\n",
       " 'fiaplvly',\n",
       " 'fiatlldy',\n",
       " 'fiavnllyf',\n",
       " 'fuianlxy',\n",
       " 'faeanlly',\n",
       " 'sfianjlly',\n",
       " 'fbiagnlly',\n",
       " 'fajnlly',\n",
       " 'ftynlly',\n",
       " 'lfianluy',\n",
       " 'faiaknlly',\n",
       " 'fiakllyv',\n",
       " 'fdiwnlly',\n",
       " 'xfiarlly',\n",
       " 'fanwlly',\n",
       " 'bfdanlly',\n",
       " 'fcanlkly',\n",
       " 'fizanjly',\n",
       " 'fiaznglly',\n",
       " 'fihanvly',\n",
       " 'fairnlly',\n",
       " 'sianlxy',\n",
       " 'fkianjlly',\n",
       " 'fiaignlly',\n",
       " 'fianlbp',\n",
       " 'fiasnlwy',\n",
       " 'fwanply',\n",
       " 'fisnllo',\n",
       " 'franllyy',\n",
       " 'fienylly',\n",
       " 'fxianllyq',\n",
       " 'fwanlley',\n",
       " 'fxianllry',\n",
       " 'fianllnw',\n",
       " 'fitanlls',\n",
       " 'fihanllyq',\n",
       " 'fianelg',\n",
       " 'fianllrj',\n",
       " 'hianllyn',\n",
       " 'fiawaly',\n",
       " 'fianlrlyi',\n",
       " 'fiaznlln',\n",
       " 'xianllyt',\n",
       " 'fianlxwy',\n",
       " 'fjnnlly',\n",
       " 'cfianlay',\n",
       " 'gfialnlly',\n",
       " 'fianlolyb',\n",
       " 'fibaglly',\n",
       " 'fianylp',\n",
       " 'fiarnlly',\n",
       " 'fpaclly',\n",
       " 'fianlwlyz',\n",
       " 'fuioanlly',\n",
       " 'fnanllye',\n",
       " 'fianjcy',\n",
       " 'iiatnlly',\n",
       " 'fbianlll',\n",
       " 'fiaonvly',\n",
       " 'ficanly',\n",
       " 'lianlmy',\n",
       " 'fkanily',\n",
       " 'fjianllym',\n",
       " 'fianlkpy',\n",
       " 'fianrlbly',\n",
       " 'fieanlrly',\n",
       " 'tianlay',\n",
       " 'fianvdly',\n",
       " 'fwiaknlly',\n",
       " 'riacnlly',\n",
       " 'fianlcey',\n",
       " 'wfpianlly',\n",
       " 'fianlyo',\n",
       " 'gfianlhy',\n",
       " 'fzarlly',\n",
       " 'fibnllb',\n",
       " 'wfianjly',\n",
       " 'fzadnlly',\n",
       " 'fimnllr',\n",
       " 'fsajlly',\n",
       " 'fxianllya',\n",
       " 'fiznllyt',\n",
       " 'fiantlyk',\n",
       " 'fianulhy',\n",
       " 'franily',\n",
       " 'kianlxy',\n",
       " 'uftianlly',\n",
       " 'jfiatnlly',\n",
       " 'fwanllfy',\n",
       " 'fianlcyf',\n",
       " 'wipnlly',\n",
       " 'fianlglyd',\n",
       " 'fianxlluy',\n",
       " 'franyly',\n",
       " 'fiaslyy',\n",
       " 'vfieanlly',\n",
       " 'fianlgf',\n",
       " 'fifnllyd',\n",
       " 'fmianlpy',\n",
       " 'fkuianlly',\n",
       " 'ffanllyu',\n",
       " 'fisanllyc',\n",
       " 'fiaalhy',\n",
       " 'fibanlcly',\n",
       " 'iianlmy',\n",
       " 'fuanley',\n",
       " 'fiaonsly',\n",
       " 'fisanully',\n",
       " 'fianlklu',\n",
       " 'fihnlldy',\n",
       " 'frarlly',\n",
       " 'finanllyv',\n",
       " 'fiauloy',\n",
       " 'fianlulj',\n",
       " 'fisnllyj',\n",
       " 'fialnsly',\n",
       " 'milanlly',\n",
       " 'fdanlnly',\n",
       " 'afiantlly',\n",
       " 'sfialnly',\n",
       " 'wzfianlly',\n",
       " 'fiaulily',\n",
       " 'kiranlly',\n",
       " 'fiapnlkly',\n",
       " 'fiwqlly',\n",
       " 'aiaqlly',\n",
       " 'fitnjly',\n",
       " 'fiaxllyk',\n",
       " 'fiagnhlly',\n",
       " 'fianjljly',\n",
       " 'fianmyl',\n",
       " 'fiankllyg',\n",
       " 'fizapnlly',\n",
       " 'fianllcyh',\n",
       " 'fianljaly',\n",
       " 'fiznll',\n",
       " 'fiynllv',\n",
       " 'mfiatlly',\n",
       " 'fianrglly',\n",
       " 'fianqlo',\n",
       " 'fiaulla',\n",
       " 'fialhlly',\n",
       " 'cfieanlly',\n",
       " 'figqnlly',\n",
       " 'frgianlly',\n",
       " 'fuanllyv',\n",
       " 'sianlrly',\n",
       " 'fianlmlky',\n",
       " 'rfianllyq',\n",
       " 'rfianuly',\n",
       " 'kfianllu',\n",
       " 'fianblby',\n",
       " 'flianldly',\n",
       " 'fiunqly',\n",
       " 'fiannllvy',\n",
       " 'ftanxly',\n",
       " 'fuanlluy',\n",
       " 'fiynllyx',\n",
       " 'firnlbly',\n",
       " 'tianllmy',\n",
       " 'qianllq',\n",
       " 'fiaxvly',\n",
       " 'fiafnllyn',\n",
       " 'fianylyd',\n",
       " 'fianlolyj',\n",
       " 'zfcianlly',\n",
       " 'mfianllxy',\n",
       " 'fiahlldy',\n",
       " 'kflanlly',\n",
       " 'qfiaunlly',\n",
       " 'fianpllyt',\n",
       " 'fianllgty',\n",
       " 'ufianlgy',\n",
       " 'fipnllgy',\n",
       " 'fiarnyly',\n",
       " 'fianllywg',\n",
       " 'fiasnllh',\n",
       " 'gfjanlly',\n",
       " 'bianlsy',\n",
       " 'uiagnlly',\n",
       " 'dialnlly',\n",
       " 'fiavdly',\n",
       " 'fianol',\n",
       " 'fiazlla',\n",
       " 'dfkanlly',\n",
       " 'feanluy',\n",
       " 'fiaulll',\n",
       " 'fianlgvly',\n",
       " 'fqianllyn',\n",
       " 'wianllyw',\n",
       " 'fialllvy',\n",
       " 'fitanely',\n",
       " 'fiarlxy',\n",
       " 'fiakllx',\n",
       " 'ufiianlly',\n",
       " 'fianlleh',\n",
       " 'ianlljy',\n",
       " 'lwfianlly',\n",
       " 'fianmnlly',\n",
       " 'feiamnlly',\n",
       " 'fianlpys',\n",
       " 'fianlhm',\n",
       " 'ffianllyv',\n",
       " 'yiabnlly',\n",
       " 'fianvllyy',\n",
       " 'fidnljly',\n",
       " 'fianlvlyz',\n",
       " 'fiinqly',\n",
       " 'fiavllby',\n",
       " 'fiaxllby',\n",
       " 'fuanlly',\n",
       " 'finlty',\n",
       " 'fianljzly',\n",
       " 'fiabllv',\n",
       " 'fiarsnlly',\n",
       " 'fiynply',\n",
       " 'fianmay',\n",
       " 'fcanllmy',\n",
       " 'fsangly',\n",
       " 'fiatnsly',\n",
       " 'fiabnllyw',\n",
       " 'hizanlly',\n",
       " 'sianlwly',\n",
       " 'hioanlly',\n",
       " 'hfianllyb',\n",
       " 'oianvlly',\n",
       " 'fistnlly',\n",
       " 'ifianbly',\n",
       " 'fianllia',\n",
       " 'fieully',\n",
       " 'fisanliy',\n",
       " 'fiqflly',\n",
       " 'fianlnkly',\n",
       " 'foianily',\n",
       " 'fiadllyc',\n",
       " 'bianlln',\n",
       " 'fipanilly',\n",
       " 'gimanlly',\n",
       " 'fyimanlly',\n",
       " 'fyanloly',\n",
       " 'wfianply',\n",
       " 'fiawnllyh',\n",
       " 'fxianyly',\n",
       " 'jfianslly',\n",
       " 'fcianlty',\n",
       " 'fiknltly',\n",
       " 'fianllsyi',\n",
       " 'fuanllqy',\n",
       " 'fiaadly',\n",
       " 'fiazllyu',\n",
       " 'fianrllt',\n",
       " 'fyianllyw',\n",
       " 'fpanlsy',\n",
       " 'kqfianlly',\n",
       " 'fvanlely',\n",
       " 'foqnlly',\n",
       " 'fiaznllyg',\n",
       " 'afiaqlly',\n",
       " 'faanllys',\n",
       " 'fianlryv',\n",
       " 'fiatnllp',\n",
       " 'fsanaly',\n",
       " 'fianclyw',\n",
       " 'xianllyo',\n",
       " 'fibnllay',\n",
       " 'fiarnmlly',\n",
       " 'qianclly',\n",
       " 'fianleyr',\n",
       " 'cfiannlly',\n",
       " 'fianlclqy',\n",
       " 'foanljy',\n",
       " 'fpinanlly',\n",
       " 'afifnlly',\n",
       " 'fianllryc',\n",
       " 'yianllly',\n",
       " 'fiaonlvy',\n",
       " 'gfianllyh',\n",
       " 'fiangflly',\n",
       " 'nfianolly',\n",
       " 'eqianlly',\n",
       " 'fianzlya',\n",
       " 'fiarnllly',\n",
       " 'fciahlly',\n",
       " 'fxally',\n",
       " 'feanllfy',\n",
       " 'lfivnlly',\n",
       " 'fiatnlxly',\n",
       " 'ryanlly',\n",
       " 'fwanxly',\n",
       " 'fiqxlly',\n",
       " 'fiavtlly',\n",
       " 'fianyllr',\n",
       " 'fsiajlly',\n",
       " 'fidznlly',\n",
       " 'fnianllo',\n",
       " 'filanllp',\n",
       " 'fianjvly',\n",
       " 'udanlly',\n",
       " 'finblly',\n",
       " 'fuianuly',\n",
       " 'fianlcz',\n",
       " 'fianllwly',\n",
       " 'fipanllyt',\n",
       " 'siknlly',\n",
       " 'fieaglly',\n",
       " 'fiaanllc',\n",
       " 'fidnylly',\n",
       " 'fihanlxy',\n",
       " 'vivanlly',\n",
       " 'fiaumnlly',\n",
       " 'zfianlny',\n",
       " 'fipnllyy',\n",
       " 'fianlgxy',\n",
       " 'zfianllxy',\n",
       " 'rfdanlly',\n",
       " 'aianlln',\n",
       " 'fiabllcy',\n",
       " 'pfionlly',\n",
       " 'fianbli',\n",
       " 'fianllpey',\n",
       " 'fiandllry',\n",
       " 'gwanlly',\n",
       " 'fifandly',\n",
       " 'ffianlls',\n",
       " 'giaolly',\n",
       " 'jfuanlly',\n",
       " 'fianlxyw',\n",
       " 'hianlfy',\n",
       " 'fqiwnlly',\n",
       " 'fiooanlly',\n",
       " 'fnienlly',\n",
       " 'fianlpya',\n",
       " 'fianmlfly',\n",
       " 'hiankly',\n",
       " 'ufrianlly',\n",
       " 'firully',\n",
       " 'fiavynlly',\n",
       " 'nionlly',\n",
       " 'yianlkly',\n",
       " 'fiakllp',\n",
       " 'fvianlcly',\n",
       " 'ficanllyh',\n",
       " 'fianclcy',\n",
       " 'fcanllo',\n",
       " 'fifaxnlly',\n",
       " 'fiyanrly',\n",
       " 'fibadnlly',\n",
       " 'fiuanklly',\n",
       " 'fanllyp',\n",
       " 'fianelye',\n",
       " 'fiancllb',\n",
       " 'nianrlly',\n",
       " 'fiafvlly',\n",
       " 'fjianllyt',\n",
       " 'niatlly',\n",
       " 'fiately',\n",
       " 'bfianllj',\n",
       " 'ufianllu',\n",
       " 'fianrcy',\n",
       " 'fijnlily',\n",
       " 'fiamllyy',\n",
       " 'fiazlrly',\n",
       " 'uihanlly',\n",
       " 'fioankly',\n",
       " 'fxawlly',\n",
       " 'fiaxnlely',\n",
       " 'iianlyl',\n",
       " 'sianlvly',\n",
       " 'fianvcly',\n",
       " 'fihatnlly',\n",
       " 'iwfianlly',\n",
       " 'fiunlply',\n",
       " 'fiddlly',\n",
       " 'fianlglhy',\n",
       " 'fibhlly',\n",
       " 'firrnlly',\n",
       " 'fiafnllyr',\n",
       " 'fipanllpy',\n",
       " 'fiaplls',\n",
       " 'fivjanlly',\n",
       " 'fuiantlly',\n",
       " 'fkianllyr',\n",
       " 'oianllpy',\n",
       " 'fidnly',\n",
       " 'fiagnllyb',\n",
       " 'fianllysd',\n",
       " 'fianwvy',\n",
       " 'kfidanlly',\n",
       " 'fitanllyj',\n",
       " 'fiaanllcy',\n",
       " 'fianllyrs',\n",
       " 'fvanloy',\n",
       " 'ftianllyf',\n",
       " 'fiaznllpy',\n",
       " 'fidnllyq',\n",
       " 'fjianllyy',\n",
       " 'fianllbby',\n",
       " 'fianlckly',\n",
       " 'fizaglly',\n",
       " 'afianllc',\n",
       " 'fiawllyq',\n",
       " 'fiayllym',\n",
       " 'fwhnlly',\n",
       " 'vkianlly',\n",
       " 'feanlmy',\n",
       " 'riaenlly',\n",
       " 'fiaznlzly',\n",
       " 'eiailly',\n",
       " 'fianllem',\n",
       " ...}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# two edit distances from input word\n",
    "edits2(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faintly', 'finally', 'finely', 'frankly'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get correct words from above set\n",
    "known(edits2(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finally'}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = (known(edits0(word)) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    \"\"\"\n",
    "    Get the best correct spelling for the input word\n",
    "    \"\"\"\n",
    "    # Priority is for edit distance 0, then 1, then 2\n",
    "    # else defaults to the input word itself.\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return max(candidates, key=WORD_COUNTS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('fianlly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FIANLLY'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('FIANLLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_match(match):\n",
    "    \"\"\"\n",
    "    Spell-correct word in match, \n",
    "    and preserve proper upper/lower/title case.\n",
    "    \"\"\"\n",
    "    \n",
    "    word = match.group()\n",
    "    def case_of(text):\n",
    "        \"\"\"\n",
    "        Return the case-function appropriate \n",
    "        for text: upper, lower, title, or just str.:\n",
    "            \"\"\"\n",
    "        return (str.upper if text.isupper() else\n",
    "                str.lower if text.islower() else\n",
    "                str.title if text.istitle() else\n",
    "                str)\n",
    "    return case_of(word)(correct(word.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_text_generic(text):\n",
    "    \"\"\"\n",
    "    Correct all the words within a text, \n",
    "    returning the corrected text.\n",
    "    \"\"\"\n",
    "    return re.sub('[a-zA-Z]+', correct_match, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'finally'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text_generic('fianlly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINALLY'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text_generic('FIANLLY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (tree.py, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/toniachu/ProgramFiles/Anaconda3/lib/python3.6/site-packages/pattern3/text/tree.py\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    except:\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from pattern3.en import suggest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-84-f89ba718ba8b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-84-f89ba718ba8b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print suggest('fianlly')\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print suggest('fianlly')\n",
    "print suggest('flaot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump jump jump\n"
     ]
    }
   ],
   "source": [
    "print (ps.stem('jumping'), ps.stem('jumps'), ps.stem('jumped'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lie\n"
     ]
    }
   ],
   "source": [
    "print (ps.stem('lying'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strang\n"
     ]
    }
   ],
   "source": [
    "print (ps.stem('strange'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lancaster Stemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "ls = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump jump jump\n"
     ]
    }
   ],
   "source": [
    "print (ls.stem('jumping'), ls.stem('jumps'), ls.stem('jumped'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lying\n"
     ]
    }
   ],
   "source": [
    "print (ls.stem('lying'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strange\n"
     ]
    }
   ],
   "source": [
    "print (ls.stem('strange'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regex based stemmer\n",
    "from nltk.stem import RegexpStemmer\n",
    "rs = RegexpStemmer('ing$|s$|ed$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jump jump jump\n"
     ]
    }
   ],
   "source": [
    "print (rs.stem('jumping'), rs.stem('jumps'), rs.stem('jumped'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ly\n"
     ]
    }
   ],
   "source": [
    "print (rs.stem('lying'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strange\n"
     ]
    }
   ],
   "source": [
    "print (rs.stem('strange'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Snowball Stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "ss = SnowballStemmer(\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported Languages: ('danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "print ('Supported Languages:', SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autobahn'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.stem('autobahnen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spring'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss.stem('springen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatize nouns\n",
    "wnl.lemmatize('cars', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'men'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize('men', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "eat\n"
     ]
    }
   ],
   "source": [
    "# lemmatize verbs\n",
    "print (wnl.lemmatize('running', 'v'))\n",
    "print (wnl.lemmatize('ate', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n",
      "fancy\n"
     ]
    }
   ],
   "source": [
    "# lemmatize adjectives\n",
    "print (wnl.lemmatize('saddest', 'a'))\n",
    "print (wnl.lemmatize('fancier', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'help'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize('helped', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize('cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saddest'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize('saddest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize('women')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (tree.py, line 37)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/toniachu/ProgramFiles/Anaconda3/lib/python3.6/site-packages/pattern3/text/tree.py\"\u001b[0;36m, line \u001b[0;32m37\u001b[0m\n\u001b[0;31m    except:\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "from pattern3.en import tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# Annotate text tokens with POS tags\n",
    "def pos_tag_text(text):\n",
    "    \n",
    "    def penn_to_wn_tags(pos_tag):\n",
    "        if pos_tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        elif pos_tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        elif pos_tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        elif pos_tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    tagged_text = tag(text)\n",
    "    tagged_lower_text = [(word.lower(), penn_to_wn_tags(pos_tag))\n",
    "                         for word, pos_tag in\n",
    "                         tagged_text]\n",
    "    return tagged_lower_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lemmatize text based on POS tags    \n",
    "def lemmatize_text(text):\n",
    "    \n",
    "    pos_tagged_text = pos_tag_text(text)\n",
    "    lemmatized_tokens = [wnl.lemmatize(word, pos_tag) if pos_tag\n",
    "                         else word                     \n",
    "                         for word, pos_tag in pos_tagged_text]\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
