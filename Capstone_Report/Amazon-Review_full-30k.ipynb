{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How many stars will I give? Predicting ratings of Amazon reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "## Purpose\n",
    "Many product reviews (from other platforms than Amazon) are not accompanied by a scale rating system, consisting only of a textual evaluation. In this case, it becomes daunting and time-consuming to compare different products in order to eventually make a choice between them. Therefore, models able to predict the user rating from the text review are critically important. Getting an overall sense of a textual review could in turn improve consumer experience. Also, it can help business to increase sales, and improve the product by understanding customers' needs and pain-points.\n",
    "\n",
    "The purpose of this project is to develop models that are able to predict the user rating from the text review. While our model is built to work with any kind of product, the review dataset provided by Amazon only includes Clothing and Shoes  reviews.\n",
    " \n",
    "## Data-Source\n",
    "Amazon product data:  http://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "## Sample review:\n",
    "    \"reviewerID\": \"A2SUAM1J3GNN3B\",  \n",
    "    \"asin\": \"0000013714\",  \n",
    "    \"reviewerName\": \"J. McDonald\",  \n",
    "    \"helpful\": [2, 3],  \n",
    "    \"reviewText\": \"I bought this for my husband who plays the piano.  He is having a wonderful time playing these old hymns.  The music  is at times hard to read because we think the book was published for singing from more than playing from.  Great purchase though!\",  \n",
    "    \"overall\": 5.0,  \n",
    "    \"summary\": \"Heavenly Highway Hymns\",  \n",
    "    \"unixReviewTime\": 1252800000,  \n",
    "    \"reviewTime\": \"09 13, 2009\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "## I. Preparing Amazon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "## 1.1 IMPORT DATA IN PANDAS\n",
    "##########################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "review_df = pd.read_json('Amazon_reviews/Clothing_Shoes_and_Jewelry_5.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: (278677, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>Rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>02 12, 2011</td>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>Amazon Customer \"cameramom\"</td>\n",
       "      <td>Great tutu-  not cheaply made</td>\n",
       "      <td>1297468800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>01 19, 2013</td>\n",
       "      <td>A2G5TCU2WDFZ65</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Very Cute!!</td>\n",
       "      <td>1358553600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>01 4, 2013</td>\n",
       "      <td>A1RLQXYNCMWRWN</td>\n",
       "      <td>Carola</td>\n",
       "      <td>I have buy more than one</td>\n",
       "      <td>1357257600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>04 27, 2014</td>\n",
       "      <td>A8U3FAMSJVHS5</td>\n",
       "      <td>Caromcg</td>\n",
       "      <td>Adorable, Sturdy</td>\n",
       "      <td>1398556800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>03 15, 2014</td>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>CJ</td>\n",
       "      <td>Grammy's Angels Love it</td>\n",
       "      <td>1394841600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  Rating  \\\n",
       "0  0000031887  [0, 0]       5   \n",
       "1  0000031887  [0, 0]       5   \n",
       "2  0000031887  [0, 0]       5   \n",
       "3  0000031887  [0, 0]       5   \n",
       "4  0000031887  [0, 0]       5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  This is a great tutu and at a really great pri...  02 12, 2011   \n",
       "1  I bought this for my 4 yr old daughter for dan...  01 19, 2013   \n",
       "2  What can I say... my daughters have it in oran...   01 4, 2013   \n",
       "3  We bought several tutus at once, and they are ...  04 27, 2014   \n",
       "4  Thank you Halo Heaven great product for Little...  03 15, 2014   \n",
       "\n",
       "       reviewerID                 reviewerName                        summary  \\\n",
       "0  A1KLRMWW2FWPL4  Amazon Customer \"cameramom\"  Great tutu-  not cheaply made   \n",
       "1  A2G5TCU2WDFZ65              Amazon Customer                    Very Cute!!   \n",
       "2  A1RLQXYNCMWRWN                       Carola       I have buy more than one   \n",
       "3   A8U3FAMSJVHS5                      Caromcg               Adorable, Sturdy   \n",
       "4  A3GEOILWLK86XM                           CJ        Grammy's Angels Love it   \n",
       "\n",
       "   unixReviewTime  \n",
       "0      1297468800  \n",
       "1      1358553600  \n",
       "2      1357257600  \n",
       "3      1398556800  \n",
       "4      1394841600  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################\n",
    "## 1.2 CHECK DATA IN PANDAS\n",
    "##########################################\n",
    "\n",
    "# change column name \n",
    "review_df = review_df.rename(columns={'overall': 'Rating'})\n",
    "\n",
    "print (\"Total data:\", str(review_df.shape))\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## II. Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Number of reviews:  278677\n",
      "\n",
      "Number of unique reviewers:  39387\n",
      "Prop of unique reviewers:  0.141\n",
      "\n",
      "Number of unique products:  23033\n",
      "Prop of unique products:  0.083\n",
      "\n",
      "Average rating score:  4.245\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "## 2.1 DESCRIPTIVE STATISTICS\n",
    "##########################################\n",
    "\n",
    "print (\"================================================\")\n",
    "\n",
    "### Total reviews\n",
    "total = len(review_df)\n",
    "print (\"Number of reviews: \",total)\n",
    "print ()\n",
    "\n",
    "### How many unique reviewers?\n",
    "print (\"Number of unique reviewers: \",len(review_df.reviewerID.unique()))\n",
    "reviewer_prop = float(len(review_df.reviewerID.unique())/total)\n",
    "print (\"Prop of unique reviewers: \",round(reviewer_prop,3))\n",
    "print ()\n",
    "\n",
    "### How many unique products?\n",
    "print (\"Number of unique products: \", len(review_df.asin.unique()))\n",
    "product_prop = float(len(review_df.asin.unique())/total)\n",
    "print (\"Prop of unique products: \",round(product_prop,3))\n",
    "print ()\n",
    "\n",
    "### Average star score\n",
    "print (\"Average rating score: \",round(review_df.Rating.mean(),3))\n",
    "\n",
    "print (\"================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "1     11192\n",
       "2     15463\n",
       "3     30425\n",
       "4     58357\n",
       "5    163240\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################################\n",
    "## 2.2 DISTRIBUTION OF RATING SCORE\n",
    "########################################## \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class_counts = review_df.groupby('Rating').size()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFnCAYAAAA7VkqGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb741b07908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_df.groupby('Rating').size().plot(kind='bar')\n",
    "plt.title(\"Frequency of Review Rating\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Number of reviews\")\n",
    "plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb741a8bc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################################\n",
    "## 2.3 DISTRIBUTION OF RATING PROPOTION\n",
    "########################################## \n",
    "\n",
    "(review_df.groupby('Rating').size()/total).plot(kind='bar')\n",
    "plt.title(\"Propotion of Review Rating\")\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Propotion of reviews\")\n",
    "plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Pre-processing —— Text Normalization (Text Wrangling)\n",
    "Text normalization is defined as a process that consists of a series of steps that should be followed to wrangle, clean, and standardize textual data into a form that\n",
    "could be consumed by other NLP and analytics systems and applications as input. Besides tokenization, various other techniques include cleaning text, case conversion, correcting spellings,\n",
    "removing stopwords and other unnecessary terms, stemming, and lemmatization. Text normalization is also often called text cleansing or wrangling.  \n",
    "\n",
    "Below are various techniques used in the process of text normalization:\n",
    "* __Cleaning Text__\n",
    "* __Tokenizing Text__\n",
    "* __Removing Special Characters__\n",
    "* __Expanding Contractions__\n",
    "* __Case Conversions__\n",
    "* __Removing Stopwords__\n",
    "* __Correcting Words__\n",
    "* __Stemming__\n",
    "* __Lemmatization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>Rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>02 12, 2011</td>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>Amazon Customer \"cameramom\"</td>\n",
       "      <td>Great tutu-  not cheaply made</td>\n",
       "      <td>1297468800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>01 19, 2013</td>\n",
       "      <td>A2G5TCU2WDFZ65</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Very Cute!!</td>\n",
       "      <td>1358553600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>01 4, 2013</td>\n",
       "      <td>A1RLQXYNCMWRWN</td>\n",
       "      <td>Carola</td>\n",
       "      <td>I have buy more than one</td>\n",
       "      <td>1357257600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>04 27, 2014</td>\n",
       "      <td>A8U3FAMSJVHS5</td>\n",
       "      <td>Caromcg</td>\n",
       "      <td>Adorable, Sturdy</td>\n",
       "      <td>1398556800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>03 15, 2014</td>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>CJ</td>\n",
       "      <td>Grammy's Angels Love it</td>\n",
       "      <td>1394841600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  Rating  \\\n",
       "0  0000031887  [0, 0]       5   \n",
       "1  0000031887  [0, 0]       5   \n",
       "2  0000031887  [0, 0]       5   \n",
       "3  0000031887  [0, 0]       5   \n",
       "4  0000031887  [0, 0]       5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  This is a great tutu and at a really great pri...  02 12, 2011   \n",
       "1  I bought this for my 4 yr old daughter for dan...  01 19, 2013   \n",
       "2  What can I say... my daughters have it in oran...   01 4, 2013   \n",
       "3  We bought several tutus at once, and they are ...  04 27, 2014   \n",
       "4  Thank you Halo Heaven great product for Little...  03 15, 2014   \n",
       "\n",
       "       reviewerID                 reviewerName                        summary  \\\n",
       "0  A1KLRMWW2FWPL4  Amazon Customer \"cameramom\"  Great tutu-  not cheaply made   \n",
       "1  A2G5TCU2WDFZ65              Amazon Customer                    Very Cute!!   \n",
       "2  A1RLQXYNCMWRWN                       Carola       I have buy more than one   \n",
       "3   A8U3FAMSJVHS5                      Caromcg               Adorable, Sturdy   \n",
       "4  A3GEOILWLK86XM                           CJ        Grammy's Angels Love it   \n",
       "\n",
       "   unixReviewTime  \n",
       "0      1297468800  \n",
       "1      1358553600  \n",
       "2      1357257600  \n",
       "3      1398556800  \n",
       "4      1394841600  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = review_df.copy()\n",
    "sdf.index = range(total)\n",
    "sdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Expanding Contractions\n",
    "Contractions are shortened version of words or syllables. They exist in either written or spoken forms. Shortened versions of existing words are created by removing specific letters and sounds. In case of English contractions, they are often created by removing one of the vowels from the word. \n",
    "\n",
    "By nature, contractions do pose a problem for NLP and text analytics because, to start with, we have a special apostrophe character in the word. Ideally, we can have a proper mapping for contractions and their corresponding expansions and then use it to expand all the contractions in our text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from contractions import CONTRACTION_MAP\n",
    "\n",
    "# Define function to expand contractions\n",
    "def expand_contractions(text):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(CONTRACTION_MAP.keys())),flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = CONTRACTION_MAP.get(match)\\\n",
    "                        if CONTRACTION_MAP.get(match)\\\n",
    "                        else CONTRACTION_MAP.get(match.lower())\n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "    \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Removing Special Characters\n",
    "One important task in text normalization involves removing unnecessary and *special characters*. These may be special symbols or even punctuation that occurs in sentences. This step is often performed before or after tokenization. The main reason for doing so is because often punctuation or special characters do not have much significance when we analyze the text and utilize it for extracting features or information based on NLP and ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the function to remove special characters\n",
    "def remove_characters(text):\n",
    "    text = text.strip()\n",
    "    PATTERN = '[^a-zA-Z ]' # only extract alpha characters\n",
    "    filtered_text = re.sub(PATTERN, '', text)\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tokenizing Text\n",
    "Tokenization can be defined as the process of breaking down or splitting textual data into smaller meaningful components called tokens.  \n",
    "\n",
    "**Sentence tokenization** is the process of splitting a text corpus into sentences that act as the first level of tokens which the corpus is comprised of. This is also known as sentence segmentation , because we try to segment the text into meaningful sentences.  \n",
    "\n",
    "**Word tokenization** is the process of splitting or segmenting sentences into their constituent words. A sentence is a collection of words, and with tokenization we essentially split a sentence into a list of words that can be used to reconstruct the sentence.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the tokenization function\n",
    "def tokenize_text(text):\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token.strip() for token in word_tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Removing Stopwords\n",
    "*Stopwords* are words that have little or no significance. They are usually removed from text during processing so as to retain words having maximum significance and context. Stopwords are usually words that end up occurring the most if you aggregated any corpus of text based on singular tokens and checked their frequencies. Words like a, the , me , and so on are stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# In Python, searching a set is much faster than searching a list, \n",
    "# so convert the stop words to a set\n",
    "stopword_list = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Define function to remove stopwords\n",
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Correcting Words\n",
    "One of the main challenges faced in text normalization is the presence of incorrect words in the text. The definition of incorrect here covers words that have spelling mistakes as well as words with several letters repeated that do not contribute much to its overall significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 Correcting Repeating Characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Define function to remove repeated characters\n",
    "def remove_repeated_characters(tokens):\n",
    "    repeat_pattern = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "    match_substitution = r'\\1\\2\\3'\n",
    "    def replace(old_word):\n",
    "        if wordnet.synsets(old_word):\n",
    "            return old_word\n",
    "        new_word = repeat_pattern.sub(match_substitution, old_word)\n",
    "        return replace(new_word) if new_word != old_word else new_word\n",
    "\n",
    "    correct_tokens = [replace(word) for word in tokens]\n",
    "    return correct_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 Correcting Spellings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Generate a map of frequently occurring words in English and their counts\n",
    "\"\"\"\n",
    "The input corpus we use is a file containing several books from the Gutenberg corpus and also \n",
    "a list of most frequent words from Wiktionary and the British National Corpus. You can find \n",
    "the file under the name big.txt or download it from http://norvig.com/big.txt and use it.\n",
    "\"\"\"\n",
    "def tokens(text):\n",
    "    \"\"\"\n",
    "    Get all words from the corpus\n",
    "    \"\"\"\n",
    "    return re.findall('[a-z]+', text.lower())\n",
    "\n",
    "WORDS = tokens(open('big.txt').read())\n",
    "WORD_COUNTS = Counter(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions that compute sets of words that are one and two edits away from input word.\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function that returns a subset of words from our candidate set of words obtained from \n",
    "# the edit functions, based on whether they occur in our vocabulary dictionary WORD_COUNTS.\n",
    "# This gives us a list of valid words from our set of candidate words.\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORD_COUNTS.\"\n",
    "    return set(w for w in words if w in WORD_COUNTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to correct words\n",
    "def correct(words):\n",
    "    # Get the best correct spellings for the input words\n",
    "    def candidates(word): \n",
    "        # Generate possible spelling corrections for word.\n",
    "        # Priority is for edit distance 0, then 1, then 2, else defaults to the input word itself.\n",
    "        candidates = known([word]) or known(edits1(word)) or known(edits2(word)) or [word]\n",
    "        return candidates\n",
    "    \n",
    "    corrected_words = [max(candidates(word), key=WORD_COUNTS.get) for word in words]\n",
    "    return corrected_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Lemmatization\n",
    "The process of lemmatization is to remove word affixes to get to a base form of the word. The base form is also known as the root word, or the lemma, will always be present in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function for Lemmatization\n",
    "def Lemmatize_tokens(tokens):\n",
    "    doc = ' '.join(tokens)\n",
    "    Lemmatized_tokens = [token.lemma_ for token in nlp(doc)]\n",
    "    return Lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus):\n",
    "    normalized_corpus = []    \n",
    "    for text in corpus:\n",
    "        text = text.lower()\n",
    "        text = expand_contractions(text)\n",
    "        text = remove_characters(text)\n",
    "        tokens = tokenize_text(text)\n",
    "        tokens = remove_stopwords(tokens)\n",
    "        tokens = remove_repeated_characters(tokens)\n",
    "        tokens = correct(tokens)\n",
    "        tokens = Lemmatize_tokens(tokens)\n",
    "        text = ' '.join(tokens)\n",
    "        normalized_corpus.append(text)\n",
    "                    \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize reviewText\n",
    "sdf = sdf.assign(Norm_reviewText = normalize_corpus(sdf.reviewText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize summary\n",
    "sdf = sdf.assign(Norm_summary = normalize_corpus(sdf.summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>Rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>Norm_reviewText</th>\n",
       "      <th>Norm_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>02 12, 2011</td>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>Amazon Customer \"cameramom\"</td>\n",
       "      <td>Great tutu-  not cheaply made</td>\n",
       "      <td>1297468800</td>\n",
       "      <td>great tut really great price look cheap glad l...</td>\n",
       "      <td>great tut cheaply make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>01 19, 2013</td>\n",
       "      <td>A2G5TCU2WDFZ65</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Very Cute!!</td>\n",
       "      <td>1358553600</td>\n",
       "      <td>buy or old daughter dance class wear today fir...</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>01 4, 2013</td>\n",
       "      <td>A1RLQXYNCMWRWN</td>\n",
       "      <td>Carola</td>\n",
       "      <td>I have buy more than one</td>\n",
       "      <td>1357257600</td>\n",
       "      <td>say daughter orange black white pink thinking ...</td>\n",
       "      <td>buy one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>04 27, 2014</td>\n",
       "      <td>A8U3FAMSJVHS5</td>\n",
       "      <td>Caromcg</td>\n",
       "      <td>Adorable, Sturdy</td>\n",
       "      <td>1398556800</td>\n",
       "      <td>buy several titus get high review sturdy seemi...</td>\n",
       "      <td>adorable sturdy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>03 15, 2014</td>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>CJ</td>\n",
       "      <td>Grammy's Angels Love it</td>\n",
       "      <td>1394841600</td>\n",
       "      <td>thank halo heaven great product little girl gr...</td>\n",
       "      <td>gray angel love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  Rating  \\\n",
       "0  0000031887  [0, 0]       5   \n",
       "1  0000031887  [0, 0]       5   \n",
       "2  0000031887  [0, 0]       5   \n",
       "3  0000031887  [0, 0]       5   \n",
       "4  0000031887  [0, 0]       5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  This is a great tutu and at a really great pri...  02 12, 2011   \n",
       "1  I bought this for my 4 yr old daughter for dan...  01 19, 2013   \n",
       "2  What can I say... my daughters have it in oran...   01 4, 2013   \n",
       "3  We bought several tutus at once, and they are ...  04 27, 2014   \n",
       "4  Thank you Halo Heaven great product for Little...  03 15, 2014   \n",
       "\n",
       "       reviewerID                 reviewerName                        summary  \\\n",
       "0  A1KLRMWW2FWPL4  Amazon Customer \"cameramom\"  Great tutu-  not cheaply made   \n",
       "1  A2G5TCU2WDFZ65              Amazon Customer                    Very Cute!!   \n",
       "2  A1RLQXYNCMWRWN                       Carola       I have buy more than one   \n",
       "3   A8U3FAMSJVHS5                      Caromcg               Adorable, Sturdy   \n",
       "4  A3GEOILWLK86XM                           CJ        Grammy's Angels Love it   \n",
       "\n",
       "   unixReviewTime                                    Norm_reviewText  \\\n",
       "0      1297468800  great tut really great price look cheap glad l...   \n",
       "1      1358553600  buy or old daughter dance class wear today fir...   \n",
       "2      1357257600  say daughter orange black white pink thinking ...   \n",
       "3      1398556800  buy several titus get high review sturdy seemi...   \n",
       "4      1394841600  thank halo heaven great product little girl gr...   \n",
       "\n",
       "             Norm_summary  \n",
       "0  great tut cheaply make  \n",
       "1                     cut  \n",
       "2                 buy one  \n",
       "3         adorable sturdy  \n",
       "4         gray angel love  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save data sets to files\n",
    "sdf.to_csv('normalized_full-corpus.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('normalized_full-corpus.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sdf = df[0:30001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>Rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>Norm_reviewText</th>\n",
       "      <th>Norm_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>02 12, 2011</td>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>Amazon Customer \"cameramom\"</td>\n",
       "      <td>Great tutu-  not cheaply made</td>\n",
       "      <td>1297468800</td>\n",
       "      <td>great tut really great price look cheap glad l...</td>\n",
       "      <td>great tut cheaply make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>01 19, 2013</td>\n",
       "      <td>A2G5TCU2WDFZ65</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>Very Cute!!</td>\n",
       "      <td>1358553600</td>\n",
       "      <td>buy or old daughter dance class wear today fir...</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>01 4, 2013</td>\n",
       "      <td>A1RLQXYNCMWRWN</td>\n",
       "      <td>Carola</td>\n",
       "      <td>I have buy more than one</td>\n",
       "      <td>1357257600</td>\n",
       "      <td>say daughter orange black white pink thinking ...</td>\n",
       "      <td>buy one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>04 27, 2014</td>\n",
       "      <td>A8U3FAMSJVHS5</td>\n",
       "      <td>Caromcg</td>\n",
       "      <td>Adorable, Sturdy</td>\n",
       "      <td>1398556800</td>\n",
       "      <td>buy several titus get high review sturdy seemi...</td>\n",
       "      <td>adorable sturdy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000031887</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>03 15, 2014</td>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>CJ</td>\n",
       "      <td>Grammy's Angels Love it</td>\n",
       "      <td>1394841600</td>\n",
       "      <td>thank halo heaven great product little girl gr...</td>\n",
       "      <td>gray angel love</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  Rating  \\\n",
       "0  0000031887  [0, 0]       5   \n",
       "1  0000031887  [0, 0]       5   \n",
       "2  0000031887  [0, 0]       5   \n",
       "3  0000031887  [0, 0]       5   \n",
       "4  0000031887  [0, 0]       5   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  This is a great tutu and at a really great pri...  02 12, 2011   \n",
       "1  I bought this for my 4 yr old daughter for dan...  01 19, 2013   \n",
       "2  What can I say... my daughters have it in oran...   01 4, 2013   \n",
       "3  We bought several tutus at once, and they are ...  04 27, 2014   \n",
       "4  Thank you Halo Heaven great product for Little...  03 15, 2014   \n",
       "\n",
       "       reviewerID                 reviewerName                        summary  \\\n",
       "0  A1KLRMWW2FWPL4  Amazon Customer \"cameramom\"  Great tutu-  not cheaply made   \n",
       "1  A2G5TCU2WDFZ65              Amazon Customer                    Very Cute!!   \n",
       "2  A1RLQXYNCMWRWN                       Carola       I have buy more than one   \n",
       "3   A8U3FAMSJVHS5                      Caromcg               Adorable, Sturdy   \n",
       "4  A3GEOILWLK86XM                           CJ        Grammy's Angels Love it   \n",
       "\n",
       "   unixReviewTime                                    Norm_reviewText  \\\n",
       "0      1297468800  great tut really great price look cheap glad l...   \n",
       "1      1358553600  buy or old daughter dance class wear today fir...   \n",
       "2      1357257600  say daughter orange black white pink thinking ...   \n",
       "3      1398556800  buy several titus get high review sturdy seemi...   \n",
       "4      1394841600  thank halo heaven great product little girl gr...   \n",
       "\n",
       "             Norm_summary  \n",
       "0  great tut cheaply make  \n",
       "1                     cut  \n",
       "2                 buy one  \n",
       "3         adorable sturdy  \n",
       "4         gray angel love  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. Bag of Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def bow_extractor(corpus, ngram_range=(1,1)):\n",
    "    vectorizer = CountVectorizer(min_df=1, ngram_range=ngram_range, max_features = 5000)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TF-IDF Model \n",
    "TF-IDF stands for Term Frequency-Inverse Document Frequency, a combination of two metrics: term frequency and inverse document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define function to directly compute the tfidf-based feature vectors for documents from the raw documents.\n",
    "def tfidf_extractor(corpus, ngram_range=(1,1)):\n",
    "    vectorizer = TfidfVectorizer(min_df=1,\n",
    "                                 norm='l2',\n",
    "                                 smooth_idf=True,\n",
    "                                 use_idf=True,\n",
    "                                 ngram_range=ngram_range,\n",
    "                                 max_features = 5000)\n",
    "    features = vectorizer.fit_transform(corpus)\n",
    "    return vectorizer, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Averaged Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np    \n",
    "\n",
    "# Define function to average word vectors for a text document\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "    \n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model[word])\n",
    "    \n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "        \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generalize above function for a corpus of documents  \n",
    "def averaged_word_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    features = [average_word_vectors(sentence, model, vocabulary, num_features) for sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. TF-IDF Weighted Averaged Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to compute tfidf weighted averaged word vector for a document\n",
    "def tfidf_wtd_avg_word_vectors(words, tfidf_vector, tfidf_vocabulary, model, num_features):\n",
    "    \n",
    "    word_tfidfs = [tfidf_vector[0, tfidf_vocabulary.get(word)] \n",
    "                   if tfidf_vocabulary.get(word) \n",
    "                   else 0 for word in words]    \n",
    "    word_tfidf_map = {word:tfidf_val for word, tfidf_val in zip(words, word_tfidfs)}\n",
    "    \n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    wts = 0.\n",
    "    for word in words:\n",
    "        if word in vocabulary: \n",
    "            word_vector = model[word]\n",
    "            weighted_word_vector = word_tfidf_map[word] * word_vector\n",
    "            wts = wts + word_tfidf_map[word]\n",
    "            feature_vector = np.add(feature_vector, weighted_word_vector)\n",
    "    if wts:\n",
    "        feature_vector = np.divide(feature_vector, wts)\n",
    "        \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generalize above function for a corpus of documents\n",
    "def tfidf_weighted_averaged_word_vectorizer(corpus, tfidf_vectors, \n",
    "                                   tfidf_vocabulary, model, num_features):\n",
    "                                       \n",
    "    docs_tfidfs = [(doc, doc_tfidf) \n",
    "                   for doc, doc_tfidf \n",
    "                   in zip(corpus, tfidf_vectors)]\n",
    "    features = [tfidf_wtd_avg_word_vectors(tokenized_sentence, tfidf, tfidf_vocabulary,\n",
    "                                   model, num_features)\n",
    "                    for tokenized_sentence, tfidf in docs_tfidfs]\n",
    "    return np.array(features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000,)\n",
      "(6001,)\n",
      "(24000,)\n",
      "(6001,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = sdf.Norm_reviewText\n",
    "Y = sdf.Rating\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_corpus, test_corpus = train_X.values.astype('U'), test_X.values.astype('U')\n",
    "train_labels, test_labels = train_Y, test_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to display feature names\n",
    "def display_features(features, feature_names):\n",
    "    df = pd.DataFrame(data=features,\n",
    "                      columns=feature_names)\n",
    "    print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Bag of Words Features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bag of words features\n",
    "bow_vectorizer, bow_train_features = bow_extractor(train_corpus)  \n",
    "bow_test_features = bow_vectorizer.transform(test_corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ab', 'abdominal', 'ability', 'able', 'abolish', 'about', 'abrasion', 'abroad', 'absent', 'absolute', 'absolutely', 'absorb', 'absorbent', 'absurd', 'abuse', 'accent', 'accentuate', 'accept', 'acceptable', 'access', 'accessible', 'accessory', 'accident', 'accidentally', 'accidently', 'accommodate', 'accompany', 'accomplish', 'accord', 'accordingly', 'account', 'accuracy', 'accurate', 'accurately', 'accustomed', 'ache', 'achieve', 'achille', 'acorn', 'acquire', 'across', 'acrylic', 'act', 'action', 'activate', 'active', 'activity', 'actual', 'actually', 'acutely', 'ad', 'adam', 'adapt', 'add', 'added', 'adding', 'addition', 'additional', 'address', 'adequate', 'adequately', 'adhere', 'adhesive', 'adjust', 'adjustable', 'adjusted', 'adjustment', 'admire', 'admit', 'admittedly', 'adorable', 'adore', 'adult', 'advance', 'advanced', 'advantage', 'adventure', 'advertise', 'advertised', 'advertisement', 'advertising', 'advice', 'advise', 'advocate', 'aerobic', 'aesthetic', 'aesthetically', 'affair', 'affect', 'afford', 'afghanistan', 'afraid', 'africa', 'after', 'afternoon', 'afterthought', 'afterwards', 'again', 'against', 'age', 'agent', 'aggressive', 'agitator', 'ago', 'agree', 'ah', 'ahead', 'aid', 'aide', 'aim', 'air', 'airline', 'airplane', 'airport', 'airy', 'aisle', 'ak', 'al', 'ala', 'alan', 'alarm', 'alas', 'alaska', 'albeit', 'alcohol', 'ali', 'alien', 'align', 'alike', 'all', 'allen', 'allergic', 'alleviate', 'alley', 'allot', 'allow', 'almost', 'alone', 'along', 'alphabet', 'already', 'alright', 'also', 'altar', 'alter', 'alteration', 'alternate', 'alternative', 'although', 'altimeter', 'altogether', 'aluminium', 'always', 'amaze', 'amazed', 'amazing', 'amazingly', 'amazon', 'amazoncom', 'amazonthe', 'amber', 'america', 'american', 'among', 'amongst', 'amount', 'ample', 'an', 'anadigi', 'analogy', 'anatomy', 'anchor', 'and', 'anel', 'angel', 'angle', 'angry', 'animal', 'ankl', 'ankle', 'anna', 'anniversary', 'annoy', 'annoyance', 'annoyed', 'annoying', 'another', 'answer', 'anti', 'anticipate', 'antimicrobial', 'antique', 'antitarnish', 'any', 'anybody', 'anyhow', 'anymore', 'anyone', 'anything', 'anyway', 'anywhere', 'apart', 'apparel', 'apparent', 'apparently', 'appeal', 'appealing', 'appear', 'appearance', 'apple', 'application', 'apply', 'appreciate', 'apprehensive', 'approach', 'appropriate', 'appropriately', 'approve', 'approximately', 'april', 'apron', 'arbat', 'arch', 'arctic', 'ardor', 'area', 'argue', 'arise', 'arizona', 'arm', 'armor', 'armour', 'armpit', 'army', 'aroma', 'around', 'arrange', 'arrangement', 'array', 'arrival', 'arrive', 'arrived', 'arrow', 'art', 'arthritis', 'article', 'articular', 'artificial', 'as', 'ascit', 'ascite', 'ash', 'asia', 'aside', 'ask', 'asleep', 'aspect', 'ass', 'assemble', 'assembly', 'assert', 'asset', 'assist', 'associate', 'assortment', 'assume', 'assure', 'at', 'athlete', 'athletic', 'atlantic', 'atomic', 'attach', 'attached', 'attachment', 'attack', 'attempt', 'attend', 'attention', 'attire', 'attitude', 'attract', 'attractive', 'attribute', 'audit', 'august', 'aunt', 'austin', 'australia', 'authentic', 'authenticity', 'authorize', 'auto', 'automatic', 'automatically', 'autumn', 'avail', 'availability', 'available', 'ave', 'avenue', 'average', 'avoid', 'await', 'aware', 'away', 'awe', 'awesome', 'awful', 'awhile', 'awkward', 'baby', 'back', 'background', 'backing', 'backlight', 'backpack', 'backpacking', 'backside', 'backward', 'backwards', 'bad', 'badge', 'badly', 'bag', 'bagalini', 'baggage', 'baggy', 'bah', 'baker', 'balaclava', 'balance', 'balanced', 'balconete', 'balcony', 'ball', 'ballet', 'ballroom', 'ban', 'banana', 'band', 'bandage', 'bandit', 'bandolier', 'bang', 'bangladesh', 'bank', 'banking', 'bar', 'bare', 'barefoot', 'barely', 'bargain', 'barn', 'barrier', 'base', 'baseball', 'basement', 'basic', 'basically', 'basis', 'basket', 'basketball', 'bass', 'bat', 'batch', 'bath', 'bathe', 'bathing', 'bathroom', 'batman', 'battery', 'battle', 'bay', 'bc', 'be', 'beach', 'bead', 'beam', 'bean', 'bear', 'bearable', 'bearer', 'bearpaw', 'beat', 'beating', 'beautiful', 'beautifully', 'beauty', 'because', 'become', 'bed', 'bedroom', 'bee', 'beef', 'beer', 'beeswax', 'before', 'beg', 'begin', 'beginning', 'behalf', 'behind', 'behold', 'beige', 'believe', 'believer', 'bell', 'belly', 'belong', 'belova', 'beloved', 'below', 'belt', 'bend', 'beneath', 'beneficial', 'benefit', 'bent', 'berkshire', 'beside', 'besides', 'best', 'bet', 'better', 'beware', 'beyond', 'bicycle', 'bid', 'bidding', 'bien', 'big', 'bigger', 'bike', 'bill', 'billfold', 'bin', 'bind', 'binder', 'binding', 'birch', 'bird', 'birkenstock', 'birth', 'birthday', 'birthstone', 'bit', 'bite', 'bitter', 'bizarre', 'black', 'bladder', 'blade', 'blaine', 'blame', 'blanket', 'blast', 'blaze', 'bleed', 'blend', 'bless', 'blessing', 'blind', 'blister', 'bloch', 'block', 'blood', 'blow', 'blue', 'bluish', 'blush', 'board', 'boat', 'bodice', 'body', 'bodysuit', 'boil', 'bold', 'bolster', 'bolt', 'bomb', 'bomber', 'bone', 'bonus', 'book', 'booklet', 'boot', 'border', 'bore', 'boring', 'boris', 'borrow', 'bosom', 'boss', 'boston', 'bostonian', 'both', 'bother', 'bothersome', 'bottle', 'bottom', 'bough', 'bought', 'bounce', 'bound', 'bout', 'boutique', 'bow', 'box', 'boxer', 'boy', 'boyfriend', 'boyshort', 'br', 'brace', 'bracelet', 'brag', 'brain', 'branch', 'brand', 'brass', 'bravado', 'brazil', 'breach', 'break', 'breaker', 'breaking', 'breast', 'breasted', 'breastfeed', 'breath', 'breathability', 'breathable', 'breathe', 'breathing', 'breeze', 'breezy', 'brick', 'bridesmaid', 'bridge', 'brief', 'briefcase', 'bright', 'brighter', 'brightly', 'brightness', 'brilliant', 'brim', 'bring', 'britain', 'british', 'brittle', 'broad', 'broke', 'broken', 'bronze', 'brother', 'brotherinlaw', 'brown', 'browse', 'bruise', 'brush', 'bsetup', 'bubble', 'buck', 'bucket', 'buckle', 'bud', 'budget', 'buena', 'buff', 'bug', 'buggy', 'build', 'building', 'bulge', 'bulk', 'bulky', 'bull', 'bullet', 'bump', 'bunch', 'bundle', 'bunion', 'burgundy', 'burn', 'bury', 'bus', 'bush', 'bushy', 'business', 'bust', 'busy', 'but', 'butt', 'butterfly', 'buttock', 'button', 'buxton', 'buy', 'buyer', 'buying', 'buzz', 'by', 'cadet', 'cage', 'cake', 'calculate', 'calculated', 'calculation', 'calendar', 'calf', 'calibre', 'calidad', 'california', 'call', 'calvin', 'camel', 'camera', 'camisole', 'camouflage', 'camp', 'camping', 'can', 'canada', 'cancel', 'cancer', 'candle', 'candy', 'canopy', 'canva', 'canvas', 'cap', 'capability', 'capable', 'capacity', 'cape', 'caper', 'capered', 'capezio', 'captain', 'capture', 'car', 'carbon', 'card', 'cardboard', 'cardinal', 'care', 'career', 'careful', 'carefully', 'careless', 'cargo', 'caribbean', 'carpenter', 'carpet', 'carpi', 'carrier', 'carry', 'cart', 'carter', 'case', 'caseback', 'cash', 'cashier', 'casque', 'cast', 'casual', 'casually', 'cat', 'catalogue', 'catch', 'category', 'caterpillar', 'cathcart', 'caught', 'cause', 'caution', 'cautious', 'cedar', 'celebrate', 'cell', 'cellar', 'celtic', 'cement', 'cent', 'center', 'central', 'century', 'ceremony', 'certain', 'certainly', 'chafe', 'chaff', 'chaffing', 'chain', 'chair', 'challenge', 'champ', 'champion', 'chance', 'change', 'changed', 'channel', 'chaos', 'character', 'characteristic', 'charcoal', 'charge', 'charity', 'charm', 'chart', 'chase', 'cheap', 'cheaper', 'cheaply', 'check', 'checkbook', 'checking', 'cheek', 'cheese', 'chemical', 'chemise', 'cherokee', 'chest', 'chester', 'chestnut', 'chew', 'chicago', 'chicken', 'chief', 'child', 'childhood', 'chill', 'chilly', 'chime', 'chin', 'china', 'chinchilla', 'chinese', 'chink', 'chintz', 'chip', 'chlorine', 'chocolate', 'choice', 'choke', 'choose', 'chose', 'christma', 'christmas', 'chronic', 'chronograph', 'chronometer', 'chubby', 'chuck', 'church', 'circle', 'circular', 'circulation', 'circumstance', 'citizen', 'city', 'civilian', 'cl', 'claim', 'clamp', 'clarity', 'clark', 'clash', 'clasp', 'class', 'classic', 'classroom', 'claw', 'clean', 'cleaner', 'cleaning', 'clear', 'clearance', 'clearly', 'cleavage', 'cleft', 'clergy', 'clever', 'click', 'client', 'climate', 'climb', 'climbing', 'clinch', 'cling', 'clinical', 'clip', 'clock', 'close', 'closed', 'closely', 'closer', 'closet', 'closing', 'closure', 'clot', 'cloth', 'clothe', 'clothing', 'cloud', 'clown', 'club', 'clue', 'clumsy', 'clung', 'clutch', 'cm', 'co', 'coach', 'coal', 'coarse', 'coast', 'coat', 'coating', 'cobbler', 'code', 'coffee', 'coffin', 'coil', 'coin', 'cold', 'colder', 'colfax', 'coli', 'collapse', 'collar', 'collect', 'collection', 'collector', 'college', 'color', 'colorado', 'colored', 'coloring', 'colour', 'coloured', 'colourful', 'columbia', 'comb', 'combat', 'combination', 'combine', 'come', 'comedy', 'comfort', 'comfortable', 'comfortablethe', 'comfortably', 'command', 'comment', 'commercial', 'common', 'commune', 'community', 'compact', 'companion', 'company', 'comparable', 'compare', 'comparison', 'compartment', 'compass', 'compensate', 'compete', 'competition', 'competitive', 'competitor', 'complain', 'complaint', 'complement', 'complete', 'completely', 'complex', 'complicate', 'complicated', 'compliment', 'comply', 'component', 'composite', 'composition', 'compress', 'compression', 'compromise', 'computer', 'con', 'conceal', 'concentrate', 'concept', 'concern', 'concerned', 'concert', 'conclusion', 'concrete', 'condition', 'cone', 'confidence', 'confident', 'configuration', 'confine', 'confirm', 'conform', 'confuse', 'confused', 'confusing', 'conjunction', 'connect', 'connection', 'connoisseur', 'conscious', 'consequently', 'conservative', 'consider', 'considerable', 'considerably', 'consideration', 'considering', 'consist', 'consistency', 'consistent', 'consistently', 'console', 'constant', 'constantly', 'constrict', 'construct', 'construction', 'consumer', 'contact', 'contain', 'container', 'content', 'contest', 'continually', 'continue', 'continuous', 'contour', 'contract', 'contractor', 'contrast', 'contribute', 'control', 'convenience', 'convenient', 'convention', 'conventional', 'conversation', 'converse', 'convert', 'convertible', 'convince', 'convinced', 'cook', 'cooking', 'cool', 'coolness', 'cooper', 'coordinate', 'copper', 'copy', 'coral', 'cord', 'cordon', 'core', 'cork', 'corn', 'corner', 'corporate', 'correct', 'correctly', 'correspond', 'corset', 'cortex', 'cos', 'cosmetic', 'cost', 'costa', 'costly', 'costo', 'costume', 'cotton', 'couch', 'could', 'couldn', 'count', 'countdown', 'counter', 'counterfeit', 'countless', 'country', 'county', 'couple', 'coupon', 'course', 'court', 'cousin', 'couture', 'cover', 'coverage', 'covered', 'cowboy', 'crack', 'cradle', 'craft', 'craftsmanship', 'cram', 'cramp', 'cramped', 'crawl', 'crazy', 'cream', 'crease', 'create', 'credit', 'creek', 'creep', 'crew', 'crime', 'cripple', 'crisp', 'criterion', 'critical', 'criticism', 'crooked', 'crop', 'cros', 'crosbody', 'cross', 'crouch', 'crowd', 'crown', 'cruise', 'crumple', 'crush', 'crutch', 'cruz', 'cry', 'crystal', 'cuba', 'cuff', 'culture', 'cumberland', 'cumbersome', 'cup', 'cure', 'curious', 'curl', 'curly', 'currency', 'current', 'currently', 'curse', 'curve', 'curved', 'cushion', 'cushioned', 'custom', 'customer', 'cut', 'cycle', 'cycling', 'cyclop', 'cylinder', 'da', 'dad', 'daddy', 'daily', 'dainty', 'dakin', 'dakota', 'damage', 'damaged', 'damn', 'damp', 'dan', 'dance', 'dancer', 'dancing', 'danger', 'dangerous', 'dangle', 'daniel', 'dare', 'dark', 'darker', 'darkness', 'darling', 'dash', 'database', 'date', 'datum', 'daughter', 'daughterinlaw', 'dawn', 'day', 'daycare', 'daylight', 'daypack', 'daysthe', 'daytime', 'dayton', 'de', 'dead', 'deal', 'dealer', 'dear', 'dearfoam', 'death', 'debate', 'debit', 'debut', 'decade', 'deceive', 'december', 'decent', 'decently', 'decide', 'decision', 'deck', 'declare', 'decline', 'decorate', 'decoration', 'decorative', 'deduce', 'deep', 'deeper', 'deer', 'def', 'default', 'defeat', 'defect', 'defective', 'defiantly', 'definite', 'definitely', 'definition', 'deglazer', 'degree', 'del', 'delay', 'delegate', 'delicate', 'delight', 'delighted', 'delightful', 'deliver', 'delivery', 'demand', 'deni', 'denis', 'dense', 'deny', 'deodorant', 'department', 'depend', 'dependable', 'dependent', 'depict', 'deploy', 'depth', 'describe', 'description', 'desert', 'deserve', 'design', 'designate', 'designer', 'desire', 'desk', 'desperate', 'despite', 'destination', 'destroy', 'detachable', 'detail', 'detailed', 'deter', 'detergent', 'deteriorate', 'determine', 'develop', 'device', 'dew', 'dexterity', 'diabetic', 'dial', 'diameter', 'diamond', 'didn', 'die', 'diet', 'differ', 'difference', 'different', 'differently', 'difficult', 'difficulty', 'dig', 'dighton', 'digit', 'digital', 'digitalanalog', 'dilute', 'dim', 'dimension', 'diminish', 'dingley', 'dingy', 'dining', 'dinner', 'dinnerless', 'dip', 'direct', 'direction', 'directly', 'dirt', 'dirty', 'disability', 'disabled', 'disagree', 'disappear', 'disappoint', 'disappointed', 'disappointing', 'disappointment', 'disc', 'discard', 'discoloration', 'discomfort', 'discontinue', 'discount', 'discover', 'discreet', 'discrepancy', 'discrete', 'disguise', 'dish', 'disintegrate', 'dislike', 'dismount', 'displace', 'display', 'disposable', 'disposal', 'dissection', 'distance', 'distinct', 'distinctive', 'distract', 'distressed', 'distribute', 'dive', 'diver', 'divide', 'diving', 'division', 'do', 'dock', 'doctor', 'document', 'doesn', 'dog', 'doll', 'dollar', 'dome', 'dominican', 'donate', 'donation', 'done', 'door', 'dootie', 'dose', 'dot', 'double', 'doubt', 'doubtful', 'down', 'downgrade', 'download', 'downpour', 'downside', 'downward', 'dozen', 'dr', 'drab', 'draft', 'drag', 'dragon', 'drain', 'drama', 'dramatic', 'dramatically', 'drape', 'draw', 'drawback', 'drawer', 'drawstr', 'drawstring', 'dread', 'dream', 'dres', 'dress', 'dressed', 'dresser', 'dressing', 'drift', 'drill', 'drink', 'drip', 'drive', 'driver', 'driveway', 'driving', 'drone', 'droning', 'droop', 'drop', 'dry', 'drying', 'du', 'dual', 'duck', 'duct', 'due', 'dull', 'dumb', 'dump', 'dung', 'dungaree', 'duplicate', 'duragold', 'during', 'dust', 'dusted', 'dutch', 'duty', 'dwyer', 'dye', 'each', 'eagle', 'ear', 'earlier', 'early', 'earmuff', 'earn', 'earner', 'earning', 'earring', 'earth', 'ease', 'easier', 'easily', 'east', 'easter', 'easy', 'eat', 'ebook', 'ecodrive', 'economic', 'economical', 'ecstatic', 'edge', 'edit', 'edition', 'edmund', 'effect', 'effective', 'effectively', 'efficient', 'effort', 'eg', 'egg', 'egypt', 'eight', 'either', 'el', 'elastic', 'elasticity', 'elbow', 'elder', 'elderly', 'electric', 'electricity', 'electronic', 'elegance', 'elegant', 'element', 'eleven', 'eligible', 'eliminate', 'elingwod', 'elite', 'elope', 'else', 'elsewhere', 'em', 'email', 'embarrass', 'embarrassed', 'embarrassing', 'emblem', 'emboss', 'embrace', 'embroider', 'embroidery', 'emergency', 'emphasize', 'employ', 'employment', 'empty', 'en', 'enable', 'enclose', 'encounter', 'encourage', 'end', 'endless', 'endorsement', 'endow', 'endowed', 'endure', 'enemy', 'energy', 'engage', 'engaged', 'engineer', 'engineering', 'england', 'english', 'enhance', 'enjoy', 'enormous', 'enough', 'ensure', 'enter', 'entire', 'entirely', 'entreat', 'entry', 'envelope', 'environment', 'equal', 'equally', 'equipment', 'equivalent', 'er', 'era', 'errand', 'error', 'es', 'escape', 'esp', 'especially', 'essential', 'essentially', 'est', 'estate', 'estimate', 'etc', 'euer', 'europe', 'european', 'evaluate', 'evan', 'eve', 'even', 'evening', 'evenly', 'event', 'eventhough', 'eventually', 'ever', 'every', 'everybody', 'everyday', 'everyone', 'everything', 'everytime', 'everywhere', 'evidence', 'evident', 'evidently', 'evil', 'ex', 'exact', 'exactly', 'examine', 'example', 'exceed', 'excellence', 'excellent', 'except', 'exception', 'exceptional', 'exceptionally', 'excess', 'excessive', 'excessively', 'exchange', 'excite', 'excited', 'excitement', 'exciting', 'exclusively', 'excursion', 'exercise', 'exist', 'exit', 'exodri', 'exoficio', 'expand', 'expandable', 'expansion', 'expect', 'expectation', 'expected', 'expedition', 'expense', 'expensive', 'experience', 'experienced', 'experiment', 'expert', 'explain', 'explanation', 'explore', 'expose', 'exposure', 'express', 'extend', 'extended', 'extension', 'extensive', 'extent', 'exterior', 'external', 'extra', 'extreme', 'extremely', 'eye', 'eyeglass', 'eyelid', 'fabric', 'fabulous', 'face', 'facility', 'fact', 'factor', 'factory', 'fad', 'fade', 'fail', 'failure', 'fair', 'fairly', 'fairy', 'faithful', 'fall', 'false', 'familiar', 'family', 'famous', 'fan', 'fancy', 'fanny', 'fantastic', 'far', 'fare', 'farm', 'farmer', 'farther', 'fashion', 'fashionable', 'fashioned', 'fashioning', 'fast', 'fasten', 'fastened', 'fastener', 'faster', 'fat', 'father', 'fatherinlaw', 'fatigue', 'fatty', 'fault', 'faut', 'favor', 'favorit', 'favorite', 'favourite', 'fear', 'fearless', 'fearlessly', 'feather', 'feature', 'feb', 'february', 'fee', 'feed', 'feedback', 'feel', 'feeling', 'feet', 'fell', 'fellow', 'felt', 'female', 'feminine', 'fence', 'festival', 'fetch', 'fete', 'few', 'fiance', 'fianceacute', 'fiancee', 'fibre', 'field', 'fifteen', 'fifth', 'fifty', 'fig', 'fight', 'figure', 'figured', 'file', 'filigree', 'fill', 'film', 'filter', 'filthy', 'final', 'finally', 'find', 'finding', 'fine', 'finer', 'finger', 'fingernail', 'fingertip', 'finish', 'finished', 'fir', 'fire', 'firing', 'firm', 'firmly', 'first', 'firstly', 'fish', 'fisherman', 'fishing', 'fit', 'fitness', 'fitted', 'fitting', 'five', 'fivestar', 'fix', 'flag', 'flair', 'flame', 'flannel', 'flap', 'flaps', 'flare', 'flash', 'flashlight', 'flat', 'flatten', 'flatter', 'flattering', 'flaw', 'fleecy', 'flesh', 'flex', 'flexibility', 'flexible', 'flight', 'flipflop', 'flipflops', 'float', 'flog', 'flood', 'floor', 'flop', 'floppy', 'flora', 'florida', 'florsheim', 'flow', 'flower', 'fluctuate', 'fluff', 'fluffy', 'fluid', 'flush', 'fly', 'foam', 'focus', 'fog', 'foi', 'foil', 'fold', 'folk', 'follow', 'follower', 'fond', 'font', 'food', 'fool', 'foot', 'football', 'footgear', 'footstep', 'for', 'forbid', 'force', 'forearm', 'forehead', 'foreign', 'foreman', 'foremost', 'forest', 'forever', 'forgery', 'forget', 'forgive', 'form', 'formal', 'format', 'former', 'formula', 'forth', 'fortunate', 'fortunately', 'fortune', 'forty', 'forward', 'fossil', 'found', 'foundation', 'four', 'fourth', 'fox', 'fraction', 'fragile', 'frame', 'france', 'frankly', 'fraser', 'fray', 'frayed', 'freak', 'free', 'freedom', 'freely', 'freeze', 'french', 'frequent', 'frequently', 'fresh', 'friction', 'friday', 'friend', 'friendly', 'frigid', 'fringe', 'from', 'front', 'frontier', 'fruit', 'frustrate', 'frustrated', 'frustration', 'frye', 'ft', 'fulfil', 'fulfill', 'full', 'fully', 'fulsize', 'fun', 'function', 'functional', 'functionality', 'funeral', 'funny', 'fur', 'furniture', 'fuss', 'fussy', 'future', 'gain', 'gaiter', 'gal', 'gallery', 'gallop', 'gamble', 'game', 'gap', 'garage', 'garden', 'gardening', 'garment', 'garter', 'gas', 'gascon', 'gasp', 'gate', 'gather', 'gauge', 'gauzy', 'gear', 'gem', 'general', 'generally', 'generation', 'generous', 'generously', 'genetic', 'genius', 'gentle', 'gentleman', 'gently', 'genuine', 'georgia', 'german', 'germany', 'get', 'getting', 'ghost', 'giant', 'gift', 'gigantic', 'gilman', 'ginger', 'girdle', 'girl', 'girlfriend', 'girth', 'give', 'glad', 'gladly', 'glamorise', 'glance', 'glander', 'glare', 'glass', 'glide', 'glimmer', 'glitter', 'glory', 'gloss', 'glossy', 'glove', 'glow', 'glue', 'go', 'goal', 'god', 'goddess', 'godlok', 'godson', 'gold', 'golden', 'golf', 'gone', 'good', 'goodness', 'goodwill', 'goose', 'gordon', 'gorge', 'gorgeous', 'got', 'gotten', 'gouge', 'gown', 'grab', 'gracious', 'grade', 'gradually', 'graduate', 'graft', 'grain', 'grand', 'grandchild', 'granddad', 'granddaughter', 'grandmother', 'grandson', 'granger', 'granny', 'grant', 'grape', 'graphic', 'grass', 'grateful', 'grave', 'gravel', 'gravity', 'gray', 'grease', 'great', 'greatly', 'green', 'greenish', 'grey', 'grid', 'grime', 'grind', 'grip', 'grm', 'grocer', 'grocery', 'groin', 'grommet', 'groom', 'groove', 'gross', 'ground', 'group', 'grow', 'grown', 'growth', 'grumpy', 'guarantee', 'guard', 'gues', 'guess', 'guest', 'guide', 'guideline', 'guilty', 'gum', 'gumma', 'gun', 'gusset', 'gust', 'gustave', 'gusto', 'gut', 'guy', 'ha', 'habit', 'hack', 'hair', 'haired', 'haiti', 'half', 'halfsize', 'halfway', 'halloween', 'halo', 'halt', 'hammer', 'hamper', 'hand', 'handcuff', 'handful', 'handkerchief', 'handle', 'handling', 'handsome', 'handwash', 'handy', 'hang', 'hanging', 'happen', 'happier', 'happily', 'happy', 'hard', 'harder', 'hardihood', 'hardly', 'hardware', 'hardy', 'harley', 'harm', 'harness', 'harold', 'harry', 'harsh', 'haste', 'hat', 'hata', 'hate', 'haul', 'havaiana', 'havana', 'have', 'haven', 'hawaii', 'head', 'headache', 'headband', 'headphone', 'heal', 'healing', 'health', 'healthy', 'heap', 'hear', 'hearing', 'heart', 'heartbroken', 'heartfelt', 'heartily', 'heat', 'heather', 'heaven', 'heavenly', 'heavier', 'heavily', 'heavy', 'heavyduty', 'heavyweight', 'heel', 'height', 'held', 'hell', 'hello', 'helmet', 'help', 'helpful', 'hem', 'hemp', 'hence', 'henry', 'her', 'here', 'herethe', 'hero', 'hesitate', 'hesitation', 'hetty', 'hey', 'hi', 'hidden', 'hide', 'hideous', 'hiding', 'high', 'higher', 'highly', 'highquality', 'hill', 'hinder', 'hinge', 'hint', 'hip', 'hiram', 'history', 'hit', 'hm', 'ho', 'hobby', 'hold', 'holder', 'holding', 'hole', 'holiday', 'holy', 'homage', 'home', 'homework', 'hondura', 'honest', 'honestly', 'honey', 'honeymoon', 'honor', 'hood', 'hooded', 'hoofs', 'hook', 'hooked', 'hop', 'hope', 'hopeful', 'hopefully', 'hoping', 'horizontal', 'horn', 'horrible', 'horribly', 'horrid', 'horror', 'horse', 'hosmer', 'hospital', 'host', 'hot', 'hotel', 'hour', 'hourglass', 'hours', 'house', 'household', 'how', 'however', 'hue', 'hug', 'huge', 'hum', 'human', 'humble', 'humid', 'humidity', 'hundred', 'hung', 'hunger', 'hunt', 'hunter', 'hunting', 'hurry', 'hurt', 'husband', 'husky', 'hut', 'hydration', 'ice', 'icy', 'idea', 'ideal', 'ideally', 'identical', 'identify', 'if', 'ignore', 'ii', 'ill', 'illuminate', 'illumination', 'iluminator', 'image', 'imagination', 'imagine', 'imitation', 'immediate', 'immediately', 'immensely', 'immersion', 'impact', 'imperfection', 'import', 'importance', 'important', 'importantly', 'impossible', 'impres', 'impress', 'impressed', 'impression', 'impressive', 'imprint', 'improve', 'improved', 'improvement', 'in', 'inaccurate', 'inbetwen', 'inch', 'incline', 'inclined', 'include', 'inconsistency', 'inconsistent', 'inconvenience', 'inconvenient', 'incorrect', 'incorrectly', 'increase', 'incredible', 'incredibly', 'indeed', 'indentation', 'indestructible', 'index', 'india', 'indicate', 'indicator', 'indie', 'indigo', 'individual', 'individually', 'indoor', 'indoors', 'induration', 'industrial', 'industry', 'inevitably', 'infant', 'infection', 'inferior', 'inflammable', 'inform', 'informal', 'information', 'ingenious', 'initial', 'initially', 'injury', 'ink', 'inner', 'insanely', 'insect', 'insert', 'inside', 'insight', 'insist', 'inspect', 'inspection', 'inspector', 'inspire', 'instal', 'install', 'instance', 'instant', 'instantly', 'instead', 'instep', 'instruct', 'instruction', 'instructor', 'instrument', 'insulate', 'insulated', 'insult', 'insurance', 'intact', 'integrity', 'intend', 'intended', 'intense', 'intent', 'intention', 'intentionally', 'interest', 'interested', 'interesting', 'interface', 'interfere', 'interior', 'internal', 'international', 'internet', 'interval', 'interview', 'intimate', 'into', 'introduce', 'intuition', 'invent', 'inventor', 'invest', 'investment', 'invisible', 'invite', 'involf', 'involve', 'involved', 'inward', 'ireland', 'iridium', 'irish', 'iron', 'ironic', 'irregular', 'irritate', 'irritated', 'irritating', 'irritation', 'island', 'isn', 'iso', 'isotoner', 'issue', 'it', 'italian', 'italy', 'itch', 'itchiness', 'itchy', 'item', 'ivory', 'jack', 'jacket', 'jam', 'jame', 'jan', 'jane', 'january', 'japan', 'japanese', 'jaw', 'jazz', 'jealous', 'jean', 'jeansthey', 'jersey', 'jesuit', 'jet', 'jewel', 'jeweller', 'jewellery', 'jezebel', 'jim', 'jingle', 'job', 'jockey', 'john', 'join', 'joint', 'joke', 'journey', 'joy', 'judge', 'julie', 'july', 'jump', 'jumper', 'jumping', 'june', 'jungle', 'junior', 'just', 'justice', 'justify', 'kangaroo', 'kayaking', 'keen', 'keep', 'keeper', 'keeping', 'keepsake', 'kenneth', 'kept', 'key', 'kick', 'kid', 'kill', 'killer', 'kind', 'kindle', 'kinetic', 'king', 'kis', 'kiss', 'kit', 'kitchen', 'kitty', 'knee', 'kneel', 'knife', 'knit', 'knob', 'knock', 'knockoff', 'knot', 'know', 'knowledge', 'known', 'knuckle', 'la', 'lab', 'label', 'labor', 'lace', 'lack', 'lacking', 'ladder', 'lady', 'lag', 'lagging', 'lake', 'lamb', 'lamp', 'land', 'landau', 'lane', 'language', 'lank', 'lap', 'large', 'largely', 'larger', 'las', 'last', 'lasting', 'lastly', 'latch', 'late', 'lately', 'later', 'lateral', 'lathe', 'latter', 'laugh', 'laura', 'laurel', 'lavender', 'law', 'lawless', 'lawn', 'lawton', 'lay', 'layer', 'laying', 'layout', 'lazy', 'lb', 'le', 'lead', 'leader', 'leaf', 'leak', 'leakage', 'lean', 'leap', 'learn', 'learning', 'least', 'leather', 'leave', 'lee', 'left', 'leg', 'legendary', 'legging', 'legible', 'legs', 'leisure', 'len', 'lend', 'length', 'lengthen', 'lengthwise', 'lengthy', 'lens', 'leopard', 'les', 'less', 'lessen', 'lesson', 'let', 'letter', 'level', 'lever', 'leverback', 'levi', 'levy', 'lewi', 'lewis', 'liable', 'liberal', 'license', 'lick', 'lid', 'lie', 'life', 'lifesaver', 'lifespan', 'lifestyle', 'lifetime', 'lift', 'lifting', 'ligament', 'light', 'lighter', 'lighting', 'lightly', 'lightness', 'lightning', 'lightweight', 'like', 'liked', 'likely', 'likewise', 'liking', 'lilac', 'lilyete', 'limb', 'lime', 'limit', 'limitation', 'limited', 'limp', 'lincoln', 'line', 'liner', 'linger', 'lingered', 'lingo', 'lining', 'link', 'lint', 'lip', 'lipped', 'lipping', 'lipstick', 'liquid', 'list', 'listen', 'literally', 'lithe', 'lithium', 'little', 'live', 'living', 'll', 'lo', 'load', 'loaded', 'loafer', 'loathe', 'lobster', 'local', 'locally', 'locate', 'location', 'lock', 'locket', 'log', 'logging', 'login', 'lollipop', 'london', 'long', 'longer', 'longevity', 'longlast', 'longsleve', 'look', 'looked', 'looking', 'lookout', 'loom', 'loop', 'loose', 'loosely', 'loosen', 'loot', 'lord', 'los', 'lose', 'loss', 'lost', 'lot', 'lotion', 'loud', 'louise', 'lounge', 'louse', 'love', 'loved', 'lovely', 'lover', 'loving', 'low', 'lower', 'loyal', 'luck', 'luckily', 'lucky', 'luggage', 'lui', 'luke', 'luman', 'lumen', 'luminescent', 'luminous', 'lump', 'lunaire', 'lunch', 'lure', 'luster', 'luxurious', 'luxury', 'ma', 'machine', 'mad', 'made', 'madman', 'madonna', 'magazine', 'magic', 'magical', 'magnet', 'magnetic', 'magnify', 'magnifying', 'mahogany', 'maidenform', 'mail', 'mailbox', 'main', 'maine', 'mainly', 'maintain', 'maintenance', 'major', 'majority', 'make', 'maker', 'making', 'male', 'mall', 'mamma', 'man', 'manage', 'mandate', 'maneuver', 'manipulate', 'manly', 'manner', 'manual', 'manufacture', 'manufacturer', 'manufacturing', 'many', 'map', 'marathon', 'march', 'margin', 'marine', 'mark', 'marked', 'marker', 'market', 'marketing', 'marking', 'maroon', 'married', 'marshall', 'marvelous', 'mary', 'masculine', 'mask', 'mass', 'massage', 'massive', 'master', 'mat', 'match', 'material', 'matter', 'mature', 'max', 'maxim', 'maximum', 'may', 'maybe', 'meal', 'mean', 'meaning', 'meant', 'meantime', 'measure', 'measured', 'measurement', 'mechanic', 'mechanical', 'mechanism', 'med', 'medal', 'medical', 'medium', 'meet', 'meeting', 'melissa', 'melt', 'member', 'membership', 'memory', 'mend', 'mental', 'mentally', 'mention', 'mephisto', 'merchandise', 'merchant', 'mere', 'merely', 'merit', 'merry', 'mesh', 'mess', 'message', 'messenger', 'metal', 'metallic', 'mete', 'method', 'mexico', 'mi', 'michigan', 'micro', 'microfiber', 'microphone', 'mid', 'midcalf', 'middle', 'midnight', 'midst', 'midwife', 'milan', 'mild', 'mile', 'mileage', 'military', 'milk', 'million', 'mimi', 'min', 'mind', 'minded', 'mine', 'mineral', 'minetonka', 'minetonkas', 'minimal', 'minimalist', 'minimize', 'minimum', 'minor', 'minus', 'minute', 'miracle', 'mirror', 'mis', 'miserable', 'misha', 'mislabel', 'mislead', 'miss', 'missing', 'mission', 'mistake', 'mistaken', 'misty', 'mix', 'mixed', 'mm', 'mo', 'mob', 'mobile', 'mock', 'mode', 'model', 'moderate', 'moderately', 'modern', 'modest', 'modestly', 'modesty', 'modification', 'modify', 'module', 'moisture', 'mold', 'molded', 'moment', 'mon', 'monday', 'money', 'monitor', 'monkey', 'monster', 'month', 'monthly', 'mood', 'moon', 'moral', 'more', 'moreover', 'mormon', 'morning', 'mortar', 'moscow', 'moss', 'most', 'mostly', 'mother', 'motherinlaw', 'motion', 'motorcycle', 'mount', 'mountain', 'mouth', 'movable', 'move', 'movement', 'movie', 'moving', 'mow', 'mrs', 'ms', 'much', 'mud', 'muddy', 'mug', 'mule', 'multi', 'multiple', 'multipurpose', 'mummy', 'munch', 'mundi', 'muscle', 'muscular', 'music', 'must', 'myoma', 'mystery', 'na', 'nail', 'naked', 'name', 'nan', 'narrow', 'narrowed', 'nasal', 'naso', 'nasty', 'national', 'native', 'natural', 'naturally', 'nature', 'naval', 'navigable', 'navy', 'nd', 'ne', 'near', 'nearby', 'nearly', 'neat', 'neatly', 'necessarily', 'necessary', 'necessity', 'neck', 'necklace', 'need', 'needed', 'needle', 'needless', 'negative', 'neighbor', 'neighborhood', 'neither', 'neoprene', 'nephew', 'nerve', 'nervous', 'net', 'nether', 'network', 'neuro', 'neuroma', 'neuropathic', 'neutral', 'never', 'nevertheless', 'new', 'newer', 'newport', 'news', 'newspaper', 'next', 'nice', 'nicely', 'nicer', 'nicest', 'nicety', 'nickel', 'niece', 'night', 'nightgown', 'nightmare', 'nighttime', 'nina', 'nine', 'nip', 'nipper', 'nipple', 'no', 'nobody', 'nodule', 'noise', 'noisy', 'non', 'none', 'nonetheless', 'nonexistent', 'nonpolariz', 'nonsense', 'nonslip', 'nonstop', 'noon', 'nordstrom', 'norm', 'normal', 'normally', 'north', 'northeast', 'northern', 'northwest', 'nose', 'not', 'notch', 'note', 'notebook', 'noted', 'nothing', 'notice', 'noticeable', 'noticeably', 'noticed', 'novel', 'november', 'now', 'nowadays', 'nowhere', 'numb', 'number', 'numerous', 'nurse', 'nursing', 'nut', 'nuts', 'ny', 'object', 'obnoxious', 'obscure', 'observation', 'obsess', 'obtain', 'obvious', 'obviously', 'occasion', 'occasional', 'occasionally', 'occur', 'ocean', 'october', 'odd', 'oddly', 'odor', 'of', 'off', 'offer', 'offering', 'office', 'officer', 'official', 'offset', 'often', 'oh', 'oil', 'oily', 'ointment', 'ok', 'oka', 'okay', 'old', 'oldfashion', 'olga', 'olive', 'on', 'one', 'onepiece', 'onethis', 'online', 'only', 'onset', 'onto', 'ooze', 'op', 'opaque', 'open', 'opened', 'opening', 'opera', 'operate', 'operation', 'operator', 'opinion', 'opportunity', 'oppose', 'opposite', 'opt', 'option', 'or', 'orange', 'order', 'ordered', 'ordering', 'ordinarily', 'ordinary', 'org', 'organic', 'organization', 'organizational', 'organize', 'organized', 'organizer', 'original', 'originally', 'orthopaedic', 'orthotic', 'other', 'otherwise', 'ought', 'ounce', 'out', 'outcast', 'outcome', 'outdoor', 'outer', 'outerwear', 'outfit', 'outgrowth', 'outing', 'outlet', 'outline', 'outrageous', 'outre', 'outside', 'outstanding', 'outward', 'oval', 'oven', 'over', 'overall', 'overcoat', 'overhead', 'overlap', 'overlay', 'overlie', 'overlook', 'overnight', 'overprice', 'overpriced', 'overseas', 'overshoe', 'overshoes', 'oversiz', 'oversized', 'overstuffed', 'overwhelming', 'owe', 'own', 'owner', 'oxford', 'oz', 'pace', 'pacific', 'pack', 'package', 'packed', 'packet', 'packing', 'pad', 'padded', 'page', 'pain', 'painful', 'painless', 'paint', 'painter', 'painting', 'pair', 'pairs', 'palace', 'pale', 'palm', 'palmar', 'panama', 'panel', 'pantyhose', 'pantyline', 'paper', 'paperthin', 'paperwork', 'par', 'para', 'parade', 'parameter', 'paratrooper', 'parent', 'paris', 'park', 'parking', 'part', 'partially', 'particular', 'particularly', 'partie', 'partition', 'partner', 'party', 'pas', 'pass', 'passion', 'passport', 'past', 'paste', 'pat', 'patch', 'patent', 'paternity', 'path', 'pathfinder', 'patience', 'patient', 'pattern', 'pavement', 'paw', 'pay', 'peace', 'peak', 'pear', 'pearl', 'peasant', 'pebble', 'peel', 'pen', 'pencil', 'penetrate', 'penny', 'people', 'per', 'percent', 'percentage', 'perfect', 'perfection', 'perfectly', 'perform', 'performance', 'perhaps', 'peri', 'period', 'periodically', 'periwinkle', 'permanent', 'permanently', 'perpetual', 'perry', 'person', 'personal', 'personality', 'personally', 'perspective', 'perspiration', 'pet', 'peter', 'petite', 'petty', 'phantom', 'phase', 'phone', 'photo', 'photograph', 'photographer', 'phrase', 'physical', 'pick', 'picking', 'pickpocket', 'picnic', 'picture', 'pictured', 'piece', 'pier', 'pierce', 'pierre', 'pig', 'pile', 'pill', 'pillage', 'pillow', 'pilot', 'pin', 'pinch', 'pink', 'pinkish', 'pip', 'pirate', 'pistol', 'pit', 'pitch', 'pity', 'place', 'placement', 'plague', 'plaid', 'plain', 'plan', 'plane', 'planet', 'planning', 'plant', 'plantar', 'planter', 'plastic', 'plate', 'platform', 'plating', 'platino', 'play', 'player', 'playing', 'plea', 'pleas', 'pleasant', 'pleasantly', 'please', 'pleased', 'pleasing', 'pleasure', 'plenty', 'pliable', 'plover', 'plug', 'plumber', 'plunge', 'plus', 'plush', 'pm', 'pobox', 'pock', 'pocket', 'podiatrist', 'point', 'pointed', 'poke', 'poland', 'polar', 'polarize', 'polarized', 'polartec', 'pole', 'police', 'policy', 'polish', 'polished', 'polite', 'poly', 'polyester', 'polyurethane', 'pool', 'poor', 'poorly', 'pop', 'popular', 'popularization', 'porch', 'port', 'portable', 'porter', 'portion', 'pose', 'position', 'positive', 'possibility', 'possible', 'possibly', 'post', 'postage', 'postpartum', 'posture', 'pot', 'potential', 'potentially', 'pouch', 'pound', 'pour', 'powder', 'power', 'powerful', 'pp', 'practical', 'practically', 'practice', 'praise', 'pre', 'preach', 'precious', 'precise', 'precisely', 'precision', 'predict', 'prefer', 'preferable', 'preference', 'preferred', 'pregnancy', 'pregnant', 'premature', 'premium', 'prepare', 'prepared', 'prepregnancy', 'preschool', 'prescription', 'present', 'presentable', 'presentation', 'preserve', 'preshrunk', 'preside', 'press', 'pressure', 'pretend', 'pretty', 'prevent', 'previous', 'previously', 'price', 'pricethe', 'prick', 'pricking', 'pride', 'primarily', 'primary', 'prime', 'princess', 'print', 'printing', 'prior', 'priority', 'private', 'pro', 'probably', 'problem', 'problematical', 'process', 'produce', 'product', 'production', 'profession', 'professional', 'professionally', 'profile', 'profit', 'program', 'progress', 'project', 'prolong', 'prominent', 'promise', 'promote', 'promotion', 'prompt', 'promptly', 'pron', 'pronation', 'prone', 'pronounce', 'pronounced', 'pronunciation', 'proof', 'prop', 'proper', 'properly', 'property', 'proportion', 'proportionate', 'protect', 'protection', 'protective', 'protrude', 'proud', 'prove', 'provide', 'provider', 'public', 'pucker', 'puddle', 'puff', 'puffy', 'pull', 'pump', 'punch', 'punishment', 'puppet', 'puppy', 'purchase', 'purchased', 'purchaser', 'purchasing', 'pure', 'purely', 'purple', 'purpose', 'purposely', 'purse', 'pursue', 'pus', 'push', 'put', 'quality', 'qualitythe', 'qualm', 'quantity', 'quarante', 'quart', 'quarter', 'que', 'queen', 'quest', 'question', 'quick', 'quickly', 'quiet', 'quietly', 'quit', 'quite', 'race', 'racerback', 'rack', 'radiant', 'radio', 'rag', 'ragged', 'rain', 'rainbow', 'raincoat', 'raincover', 'rainy', 'raise', 'ralph', 'ran', 'random', 'range', 'rank', 'rapid', 'rapidly', 'rare', 'rarely', 'rash', 'rat', 'rate', 'rather', 'rating', 'ratio', 'rattle', 'rave', 'raw', 'ray', 'rayban', 'razor', 'rd', 're', 'reach', 'reaction', 'read', 'readable', 'reader', 'readily', 'reading', 'readjust', 'ready', 'real', 'realise', 'realistic', 'reality', 'realize', 'really', 'rear', 'reason', 'reasonable', 'reasonably', 'recall', 'receipt', 'receive', 'received', 'receiver', 'recent', 'recently', 'reception', 'recess', 'recipient', 'reckless', 'recognition', 'recognize', 'recommend', 'recommendation', 'reconstruct', 'record', 'recorder', 'recover', 'rectangular', 'red', 'reddish', 'redoubt', 'redstone', 'reduce', 'reduction', 'reed', 'reef', 'refer', 'reference', 'reflect', 'reflection', 'reform', 'refresh', 'refund', 'refuse', 'regard', 'regardless', 'region', 'register', 'regret', 'regular', 'regularly', 'reinforce', 'reinforcement', 'relate', 'relation', 'relative', 'relatively', 'relax', 'relaxed', 'release', 'reliability', 'reliable', 'relief', 'relieve', 'relit', 'reluctant', 'reluctantly', 'rely', 'remain', 'remark', 'remarkable', 'remarkably', 'remedi', 'remedy', 'remember', 'remind', 'reminder', 'remote', 'removable', 'removal', 'remove', 'removed', 'render', 'renew', 'repair', 'repeat', 'repeatedly', 'repellent', 'replace', 'replaceable', 'replaced', 'replacement', 'reply', 'report', 'represent', 'republic', 'reputation', 'request', 'require', 'requirement', 'research', 'resect', 'resemble', 'reservation', 'reserve', 'reside', 'resident', 'residue', 'resin', 'resist', 'resistance', 'resistant', 'resolve', 'resort', 'respect', 'respond', 'response', 'responsible', 'rest', 'restaurant', 'restore', 'restrict', 'restrictive', 'restroom', 'result', 'retail', 'retailer', 'retain', 'retainer', 'retire', 'retract', 'retro', 'return', 'returned', 'reveal', 'reverse', 'reversible', 'review', 'reviews', 'rib', 'ribbed', 'ribbon', 'ribcage', 'rich', 'rid', 'ride', 'rider', 'ridge', 'ridiculous', 'ridiculously', 'riding', 'right', 'rigid', 'rigor', 'ring', 'rinse', 'rip', 'ripstop', 'rise', 'risk', 'risky', 'rite', 'rival', 'river', 'rivet', 'road', 'robe', 'robin', 'robust', 'rock', 'rocket', 'rockie', 'rockport', 'rocky', 'rod', 'role', 'roll', 'roller', 'rolling', 'roman', 'rome', 'roof', 'room', 'roomy', 'root', 'rope', 'rose', 'rosy', 'rotate', 'rotation', 'roth', 'rough', 'roughly', 'roughness', 'round', 'rounded', 'route', 'routine', 'row', 'royal', 'rub', 'rubber', 'rubberized', 'rude', 'ruffle', 'rug', 'rugg', 'rugged', 'ruin', 'rule', 'run', 'runner', 'running', 'rural', 'ruse', 'rush', 'russell', 'rust', 'ryazan', 'saber', 'sack', 'sacrifice', 'sad', 'saddle', 'sadly', 'safe', 'safely', 'safety', 'sage', 'sail', 'sailor', 'sake', 'salary', 'sale', 'salon', 'salt', 'same', 'samoan', 'san', 'sanction', 'sand', 'sandbag', 'sandstone', 'sandy', 'sang', 'sank', 'santa', 'santo', 'sap', 'sapphire', 'satin', 'satisfaction', 'satisfactory', 'satisfied', 'satisfy', 'saturday', 'sausage', 'savage', 'save', 'saving', 'saw', 'say', 'scale', 'scan', 'scandal', 'scar', 'scarf', 'scenario', 'scent', 'schedule', 'scheme', 'school', 'scissor', 'scoop', 'score', 'scot', 'scrap', 'scratch', 'scratched', 'scream', 'screen', 'screw', 'screwdown', 'screwdriver', 'scrub', 'scuffle', 'se', 'sea', 'seal', 'seam', 'seams', 'sear', 'search', 'season', 'seat', 'seattle', 'seawalker', 'sebago', 'second', 'secondary', 'secondly', 'secret', 'section', 'secure', 'securely', 'security', 'see', 'seek', 'seem', 'seemingly', 'seen', 'seize', 'seizing', 'seldom', 'select', 'selection', 'self', 'sell', 'seller', 'selling', 'semi', 'send', 'senior', 'sensation', 'sense', 'sensitive', 'sensitivity', 'separate', 'separately', 'separation', 'september', 'serie', 'series', 'serious', 'seriously', 'serve', 'service', 'serviceable', 'session', 'set', 'setting', 'settle', 'seven', 'several', 'severe', 'sevi', 'sew', 'sewing', 'sewn', 'sex', 'shade', 'shadowline', 'shaft', 'shake', 'shako', 'shakos', 'shall', 'shallow', 'shalt', 'shame', 'shampoo', 'shape', 'shapely', 'shapewear', 'share', 'sharp', 'shave', 'shaving', 'shawl', 'sheath', 'shed', 'sheen', 'sheep', 'sheepskin', 'sheer', 'sheet', 'shelf', 'shell', 'shelter', 'sherman', 'shield', 'shift', 'shin', 'shine', 'shiny', 'ship', 'shipment', 'shipper', 'shipping', 'shirt', 'shiver', 'shock', 'shocked', 'shod', 'shoe', 'shoelace', 'shoesandal', 'shoesthe', 'shoesthey', 'shoot', 'shop', 'shopping', 'shore', 'short', 'shortcoming', 'shorten', 'shorter', 'shortly', 'shot', 'should', 'shoulder', 'shout', 'shove', 'shovel', 'show', 'shower', 'showing', 'shrank', 'shred', 'shrink', 'shrinkage', 'shrinktofit', 'shrunk', 'shut', 'shy', 'si', 'sick', 'sickle', 'sickness', 'side', 'sidewalk', 'sideways', 'sigh', 'sight', 'sign', 'signal', 'signature', 'significant', 'significantly', 'silent', 'silhouette', 'silicon', 'silicone', 'silk', 'silly', 'silver', 'silvery', 'similar', 'similarly', 'simon', 'simple', 'simplicity', 'simply', 'sin', 'since', 'sing', 'singapore', 'single', 'sink', 'sinner', 'sister', 'sit', 'site', 'situation', 'six', 'size', 'sized', 'sizethe', 'skeptically', 'sketch', 'ski', 'skill', 'skin', 'skinny', 'skirt', 'skull', 'sky', 'slack', 'slander', 'slap', 'slate', 'sleek', 'sleep', 'sleeping', 'sleepless', 'sleev', 'sleeve', 'slender', 'slice', 'slide', 'slight', 'slightly', 'slim', 'sling', 'slip', 'slipper', 'slippered', 'slippers', 'slippery', 'slit', 'slogger', 'slope', 'slot', 'slough', 'sloughy', 'slow', 'slowly', 'small', 'smaller', 'smallish', 'smart', 'smartphone', 'smartwol', 'smash', 'smell', 'smile', 'smith', 'smoke', 'smooth', 'smoothly', 'smoothness', 'smudge', 'smythe', 'snack', 'snake', 'snakeskin', 'snap', 'sneer', 'snorkel', 'snort', 'snow', 'snowy', 'snuff', 'snug', 'snuggery', 'snugly', 'so', 'soak', 'soap', 'soccer', 'social', 'society', 'sock', 'socket', 'soda', 'soft', 'soften', 'softer', 'softly', 'softness', 'software', 'soil', 'sol', 'solar', 'solaratomic', 'soldier', 'sole', 'solid', 'solo', 'solution', 'solve', 'some', 'somebody', 'someday', 'somehow', 'someone', 'someplace', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'son', 'song', 'soninlaw', 'soon', 'sooner', 'soothe', 'sophisticated', 'sore', 'sorry', 'sort', 'soul', 'sound', 'source', 'south', 'southern', 'space', 'spacious', 'spade', 'spaghetti', 'spain', 'span', 'spanish', 'spare', 'sparkle', 'speak', 'speaker', 'special', 'specially', 'specific', 'specifically', 'specification', 'specify', 'speck', 'spectacular', 'speech', 'speed', 'speedy', 'spell', 'spend', 'spending', 'spent', 'spice', 'spider', 'spike', 'spill', 'spin', 'spine', 'spiral', 'spirit', 'spit', 'spite', 'splash', 'splint', 'split', 'spoil', 'sponge', 'spoon', 'sport', 'sporting', 'spot', 'spouse', 'spr', 'spray', 'spread', 'spring', 'springsumer', 'spur', 'spy', 'spyglass', 'square', 'squat', 'squeak', 'squeaky', 'squeeze', 'squish', 'squishy', 'st', 'stab', 'stability', 'stabilizer', 'stable', 'staff', 'stage', 'stain', 'stair', 'stamp', 'stance', 'stand', 'standard', 'standing', 'staple', 'star', 'starch', 'start', 'startle', 'state', 'statement', 'static', 'station', 'stationary', 'status', 'stay', 'stayed', 'stays', 'steady', 'steal', 'steam', 'steel', 'steep', 'stem', 'step', 'sterling', 'sternum', 'stick', 'sticky', 'stiff', 'stiffen', 'stiffness', 'still', 'stink', 'stitch', 'stitching', 'stock', 'stocking', 'stomach', 'stone', 'stonewash', 'stop', 'stoper', 'stoppage', 'stopwatch', 'storage', 'store', 'storm', 'story', 'stout', 'str', 'straight', 'straighten', 'straightforward', 'strain', 'strange', 'strangely', 'stranger', 'strap', 'straps', 'strapsthe', 'stray', 'stream', 'street', 'strength', 'strenuous', 'stress', 'stretch', 'stretchable', 'stretched', 'stretcher', 'stretchiness', 'strict', 'strictly', 'stride', 'strike', 'string', 'strip', 'stripe', 'stroke', 'stroll', 'strong', 'strongly', 'structure', 'struggle', 'stuck', 'stud', 'student', 'studio', 'study', 'stuff', 'stuffed', 'stumble', 'stun', 'stunning', 'stupid', 'sturdiness', 'sturdy', 'style', 'stylish', 'sub', 'subject', 'subjective', 'submarine', 'submerge', 'substance', 'substantial', 'substantially', 'substitute', 'subtle', 'subtract', 'success', 'successful', 'successfully', 'such', 'suck', 'sudden', 'suddenly', 'sue', 'suffer', 'suffice', 'sufficient', 'sufficiently', 'suggest', 'suggestion', 'suit', 'suitable', 'suitcase', 'suited', 'sum', 'summary', 'summer', 'summertime', 'sun', 'sunday', 'sundry', 'sunglass', 'sunlight', 'sunny', 'sunscreen', 'sunshine', 'super', 'superb', 'superbe', 'superbreak', 'superhero', 'superior', 'supper', 'supple', 'supplement', 'supplier', 'supply', 'support', 'suppose', 'supposed', 'supposedly', 'suppurative', 'sure', 'surely', 'surf', 'surface', 'surge', 'surgery', 'surgical', 'surpass', 'surplus', 'surprise', 'surprised', 'surprising', 'surprisingly', 'surround', 'survive', 'suspect', 'suspend', 'swam', 'swamp', 'swan', 'swap', 'swarovski', 'swear', 'sweat', 'sweatpant', 'sweatshirt', 'sweep', 'sweet', 'sweeter', 'swell', 'swim', 'swimmer', 'swimming', 'swimsuit', 'swing', 'swis', 'swiss', 'switch', 'swollen', 'sword', 'symbol', 'synthesis', 'system', 'ta', 'tabe', 'table', 'tablet', 'tack', 'tactical', 'tag', 'tail', 'tailor', 'take', 'talk', 'tall', 'tamarac', 'tangle', 'tank', 'tap', 'tape', 'taper', 'target', 'tarso', 'task', 'taste', 'tattoo', 'tax', 'taylor', 'te', 'tea', 'teach', 'teacher', 'teaching', 'team', 'teamster', 'tear', 'technical', 'technically', 'technique', 'technology', 'teenage', 'teenager', 'telephone', 'tell', 'temp', 'temperature', 'temple', 'temporary', 'tempt', 'ten', 'tend', 'tendency', 'tender', 'tendon', 'tennis', 'tension', 'tent', 'tenth', 'teramar', 'term', 'terrain', 'terrible', 'terribly', 'terrific', 'test', 'testing', 'texas', 'text', 'textbook', 'texture', 'th', 'thailand', 'than', 'thank', 'thankful', 'thanksgiv', 'that', 'the', 'theater', 'thembut', 'theme', 'themthese', 'themthey', 'themthis', 'then', 'theory', 'there', 'therefore', 'thermal', 'thermasilk', 'thermometer', 'these', 'thesethey', 'thick', 'thicker', 'thickness', 'thigh', 'thighigh', 'thighs', 'thin', 'thing', 'think', 'thinking', 'thinner', 'thinness', 'third', 'thirty', 'this', 'thither', 'thorax', 'thorn', 'thoroughly', 'those', 'thou', 'though', 'thought', 'thousand', 'thread', 'threadbare', 'three', 'threw', 'thrifty', 'thrill', 'thrilled', 'through', 'throughout', 'throw', 'thumb', 'thumbs', 'thursday', 'thus', 'thy', 'ti', 'tick', 'ticket', 'tie', 'tien', 'tiger', 'tight', 'tighten', 'tighter', 'tightly', 'tightness', 'til', 'tile', 'tiled', 'till', 'tilt', 'timberland', 'time', 'timekeeping', 'timely', 'timepiece', 'timezone', 'timing', 'timothy', 'tin', 'tint', 'tiny', 'tip', 'tire', 'tired', 'tireless', 'tis', 'tissue', 'tit', 'titanic', 'title', 'titus', 'tm', 'to', 'toast', 'today', 'toe', 'toes', 'together', 'toi', 'toil', 'toilet', 'toiletry', 'tolerable', 'tolerance', 'tolerate', 'toller', 'tomorrow', 'ton', 'tone', 'tongue', 'tonic', 'tonight', 'tonsil', 'too', 'tool', 'tooth', 'toothbrush', 'toothpaste', 'top', 'torn', 'tortoise', 'torture', 'tory', 'toss', 'total', 'totally', 'touch', 'tough', 'tour', 'tourist', 'toward', 'towards', 'towel', 'tower', 'town', 'toy', 'trace', 'track', 'traction', 'trade', 'tradition', 'traditional', 'traffic', 'trail', 'train', 'trainer', 'training', 'tramp', 'transfer', 'transition', 'translate', 'transparent', 'transport', 'trap', 'trash', 'travel', 'traveler', 'traveling', 'traveltime', 'tread', 'treadmill', 'treasure', 'treat', 'treatment', 'tree', 'tremendous', 'trend', 'trial', 'triangle', 'triangular', 'triathlon', 'trick', 'tricky', 'trifle', 'trigger', 'trim', 'trip', 'triple', 'troop', 'tropical', 'trotter', 'trouble', 'trouser', 'truck', 'true', 'truetosize', 'truly', 'trunk', 'trust', 'trusty', 'truth', 'try', 'trying', 'tub', 'tube', 'tuck', 'tucked', 'tug', 'tumble', 'tune', 'tungsten', 'tunic', 'turk', 'turn', 'turquoise', 'turtle', 'turtleneck', 'tut', 'twelve', 'twenty', 'twice', 'twin', 'twist', 'twisted', 'twitch', 'two', 'twofold', 'twotone', 'type', 'typical', 'typically', 'ugh', 'ugly', 'ultimate', 'ultimately', 'ultra', 'ultrasonic', 'umbrella', 'un', 'unable', 'unacceptable', 'unattractive', 'unbearable', 'unbelievable', 'unbelievably', 'uncle', 'uncomfortable', 'under', 'underarm', 'undergarment', 'undermine', 'underneath', 'underpant', 'undershirt', 'undersized', 'understand', 'undertake', 'underwater', 'underwear', 'underwir', 'underwire', 'undo', 'undone', 'uneven', 'unexpected', 'unexpectedly', 'unfordable', 'unfortunate', 'unfortunately', 'unhappy', 'unidirectional', 'uniform', 'union', 'unique', 'unit', 'unite', 'united', 'universal', 'unknown', 'unless', 'unlike', 'unlikely', 'unload', 'unlock', 'unnatural', 'unnecessary', 'unobtrusive', 'unpack', 'unpleasant', 'unravel', 'unseen', 'unsightly', 'untied', 'until', 'unusual', 'unusually', 'unwanted', 'up', 'update', 'updated', 'upgrade', 'uplift', 'upon', 'upper', 'upright', 'upset', 'upside', 'upward', 'upwards', 'urban', 'urge', 'us', 'usage', 'use', 'used', 'useful', 'usefulness', 'useless', 'user', 'usual', 'usually', 'utilitarian', 'utility', 'utilize', 'utterly', 'vacation', 'vagrant', 'valentine', 'valley', 'valuable', 'value', 'van', 'vanity', 'vantage', 'variation', 'variety', 'various', 'varnish', 'varnished', 'vary', 'vector', 'vehicle', 'vein', 'velcro', 'velvet', 'vendor', 'venezuela', 'venice', 'ventilator', 'venture', 'verify', 'versatile', 'versatility', 'version', 'versus', 'vertical', 'very', 'vest', 'via', 'vice', 'victor', 'victoria', 'victory', 'video', 'vienna', 'view', 'viewing', 'vigor', 'vigorous', 'vinegar', 'virtually', 'visibility', 'visible', 'vision', 'visit', 'visitor', 'visual', 'vital', 'vivid', 'vocabulary', 'voice', 'voila', 'vol', 'volume', 'vote', 'vs', 'wa', 'wad', 'wagram', 'waist', 'waistband', 'wait', 'wake', 'walk', 'walker', 'walking', 'walks', 'wall', 'wallerian', 'wallet', 'walnut', 'wan', 'wand', 'wander', 'want', 'wanted', 'war', 'wardrobe', 'ware', 'warehouse', 'warfare', 'warm', 'warmer', 'warmth', 'warn', 'warning', 'warrant', 'warranty', 'wary', 'wash', 'washable', 'washed', 'washerdryer', 'washing', 'washington', 'waste', 'watch', 'watchband', 'watchful', 'watchman', 'watchthe', 'watchthis', 'water', 'wateresistant', 'waterproof', 'waterproofing', 'wave', 'wax', 'way', 'wayfarer', 'weak', 'wealth', 'weapon', 'wear', 'wearer', 'wearing', 'wears', 'weary', 'weather', 'weave', 'web', 'webbing', 'webpage', 'webster', 'wed', 'wedding', 'wedge', 'wee', 'week', 'weekend', 'weekly', 'weeper', 'weigh', 'weight', 'weird', 'welcome', 'welfare', 'welfit', 'well', 'went', 'weren', 'west', 'western', 'wet', 'what', 'whatev', 'whatnot', 'whatsoever', 'wheel', 'wheelchair', 'when', 'whenever', 'whereas', 'wherever', 'whether', 'whichev', 'whim', 'whisper', 'whistle', 'white', 'who', 'whoever', 'whole', 'whose', 'wick', 'wicked', 'wide', 'widely', 'widen', 'wider', 'width', 'wife', 'wig', 'wild', 'wildly', 'will', 'willing', 'win', 'wind', 'windbreaker', 'winding', 'window', 'windsor', 'windy', 'wine', 'wing', 'winner', 'winter', 'wipe', 'wire', 'wirefre', 'wisconsin', 'wise', 'wish', 'with', 'within', 'without', 'withstand', 'wizard', 'wo', 'wodlore', 'wolf', 'woman', 'wonder', 'wonderful', 'wonderfully', 'wood', 'wooden', 'woodland', 'woodwork', 'wool', 'word', 'wore', 'work', 'workbag', 'worked', 'worker', 'workhouse', 'working', 'workmanship', 'workout', 'workshop', 'world', 'worldly', 'worn', 'worried', 'worry', 'worse', 'worth', 'worthless', 'worthwhile', 'worthy', 'would', 'wouldn', 'wound', 'wrangle', 'wrap', 'wreck', 'wrestle', 'wriggle', 'wrinkle', 'wrinkled', 'wrist', 'wristband', 'write', 'writer', 'writing', 'wrong', 'wythe', 'xx', 'yaktrax', 'yard', 'yea', 'yeah', 'year', 'yellow', 'yep', 'yes', 'yesterday', 'yet', 'yoke', 'york', 'young', 'youth', 'zealand', 'zenger', 'zero', 'zip', 'zone']\n"
     ]
    }
   ],
   "source": [
    "# Print feature names\n",
    "feature_names = bow_vectorizer.get_feature_names()\n",
    "print (feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ab  abdominal  ability  able  abolish  about  abrasion  abroad  absent  \\\n",
      "0   0          0        0     0        0      0         0       0       0   \n",
      "1   0          0        0     0        0      0         0       0       0   \n",
      "2   0          0        0     0        0      0         0       0       0   \n",
      "3   0          0        0     0        0      0         0       0       0   \n",
      "4   0          0        0     0        0      0         0       0       0   \n",
      "\n",
      "   absolute  ...   yet  yoke  york  young  youth  zealand  zenger  zero  zip  \\\n",
      "0         0  ...     0     0     0      0      0        0       0     0    0   \n",
      "1         0  ...     0     0     0      0      0        0       0     0    0   \n",
      "2         0  ...     0     0     0      0      0        0       0     0    0   \n",
      "3         0  ...     0     0     0      0      0        0       0     0    0   \n",
      "4         0  ...     0     0     0      0      0        0       0     0    0   \n",
      "\n",
      "   zone  \n",
      "0     0  \n",
      "1     0  \n",
      "2     0  \n",
      "3     0  \n",
      "4     0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "features_bow = bow_train_features.todense()\n",
    "display_features(features_bow[0:5], feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __TF-IDF Features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tfidf features\n",
    "tfidf_vectorizer, tfidf_train_features = tfidf_extractor(train_corpus)  \n",
    "tfidf_test_features = tfidf_vectorizer.transform(test_corpus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ab', 'abdominal', 'ability', 'able', 'abolish', 'about', 'abrasion', 'abroad', 'absent', 'absolute', 'absolutely', 'absorb', 'absorbent', 'absurd', 'abuse', 'accent', 'accentuate', 'accept', 'acceptable', 'access', 'accessible', 'accessory', 'accident', 'accidentally', 'accidently', 'accommodate', 'accompany', 'accomplish', 'accord', 'accordingly', 'account', 'accuracy', 'accurate', 'accurately', 'accustomed', 'ache', 'achieve', 'achille', 'acorn', 'acquire', 'across', 'acrylic', 'act', 'action', 'activate', 'active', 'activity', 'actual', 'actually', 'acutely', 'ad', 'adam', 'adapt', 'add', 'added', 'adding', 'addition', 'additional', 'address', 'adequate', 'adequately', 'adhere', 'adhesive', 'adjust', 'adjustable', 'adjusted', 'adjustment', 'admire', 'admit', 'admittedly', 'adorable', 'adore', 'adult', 'advance', 'advanced', 'advantage', 'adventure', 'advertise', 'advertised', 'advertisement', 'advertising', 'advice', 'advise', 'advocate', 'aerobic', 'aesthetic', 'aesthetically', 'affair', 'affect', 'afford', 'afghanistan', 'afraid', 'africa', 'after', 'afternoon', 'afterthought', 'afterwards', 'again', 'against', 'age', 'agent', 'aggressive', 'agitator', 'ago', 'agree', 'ah', 'ahead', 'aid', 'aide', 'aim', 'air', 'airline', 'airplane', 'airport', 'airy', 'aisle', 'ak', 'al', 'ala', 'alan', 'alarm', 'alas', 'alaska', 'albeit', 'alcohol', 'ali', 'alien', 'align', 'alike', 'all', 'allen', 'allergic', 'alleviate', 'alley', 'allot', 'allow', 'almost', 'alone', 'along', 'alphabet', 'already', 'alright', 'also', 'altar', 'alter', 'alteration', 'alternate', 'alternative', 'although', 'altimeter', 'altogether', 'aluminium', 'always', 'amaze', 'amazed', 'amazing', 'amazingly', 'amazon', 'amazoncom', 'amazonthe', 'amber', 'america', 'american', 'among', 'amongst', 'amount', 'ample', 'an', 'anadigi', 'analogy', 'anatomy', 'anchor', 'and', 'anel', 'angel', 'angle', 'angry', 'animal', 'ankl', 'ankle', 'anna', 'anniversary', 'annoy', 'annoyance', 'annoyed', 'annoying', 'another', 'answer', 'anti', 'anticipate', 'antimicrobial', 'antique', 'antitarnish', 'any', 'anybody', 'anyhow', 'anymore', 'anyone', 'anything', 'anyway', 'anywhere', 'apart', 'apparel', 'apparent', 'apparently', 'appeal', 'appealing', 'appear', 'appearance', 'apple', 'application', 'apply', 'appreciate', 'apprehensive', 'approach', 'appropriate', 'appropriately', 'approve', 'approximately', 'april', 'apron', 'arbat', 'arch', 'arctic', 'ardor', 'area', 'argue', 'arise', 'arizona', 'arm', 'armor', 'armour', 'armpit', 'army', 'aroma', 'around', 'arrange', 'arrangement', 'array', 'arrival', 'arrive', 'arrived', 'arrow', 'art', 'arthritis', 'article', 'articular', 'artificial', 'as', 'ascit', 'ascite', 'ash', 'asia', 'aside', 'ask', 'asleep', 'aspect', 'ass', 'assemble', 'assembly', 'assert', 'asset', 'assist', 'associate', 'assortment', 'assume', 'assure', 'at', 'athlete', 'athletic', 'atlantic', 'atomic', 'attach', 'attached', 'attachment', 'attack', 'attempt', 'attend', 'attention', 'attire', 'attitude', 'attract', 'attractive', 'attribute', 'audit', 'august', 'aunt', 'austin', 'australia', 'authentic', 'authenticity', 'authorize', 'auto', 'automatic', 'automatically', 'autumn', 'avail', 'availability', 'available', 'ave', 'avenue', 'average', 'avoid', 'await', 'aware', 'away', 'awe', 'awesome', 'awful', 'awhile', 'awkward', 'baby', 'back', 'background', 'backing', 'backlight', 'backpack', 'backpacking', 'backside', 'backward', 'backwards', 'bad', 'badge', 'badly', 'bag', 'bagalini', 'baggage', 'baggy', 'bah', 'baker', 'balaclava', 'balance', 'balanced', 'balconete', 'balcony', 'ball', 'ballet', 'ballroom', 'ban', 'banana', 'band', 'bandage', 'bandit', 'bandolier', 'bang', 'bangladesh', 'bank', 'banking', 'bar', 'bare', 'barefoot', 'barely', 'bargain', 'barn', 'barrier', 'base', 'baseball', 'basement', 'basic', 'basically', 'basis', 'basket', 'basketball', 'bass', 'bat', 'batch', 'bath', 'bathe', 'bathing', 'bathroom', 'batman', 'battery', 'battle', 'bay', 'bc', 'be', 'beach', 'bead', 'beam', 'bean', 'bear', 'bearable', 'bearer', 'bearpaw', 'beat', 'beating', 'beautiful', 'beautifully', 'beauty', 'because', 'become', 'bed', 'bedroom', 'bee', 'beef', 'beer', 'beeswax', 'before', 'beg', 'begin', 'beginning', 'behalf', 'behind', 'behold', 'beige', 'believe', 'believer', 'bell', 'belly', 'belong', 'belova', 'beloved', 'below', 'belt', 'bend', 'beneath', 'beneficial', 'benefit', 'bent', 'berkshire', 'beside', 'besides', 'best', 'bet', 'better', 'beware', 'beyond', 'bicycle', 'bid', 'bidding', 'bien', 'big', 'bigger', 'bike', 'bill', 'billfold', 'bin', 'bind', 'binder', 'binding', 'birch', 'bird', 'birkenstock', 'birth', 'birthday', 'birthstone', 'bit', 'bite', 'bitter', 'bizarre', 'black', 'bladder', 'blade', 'blaine', 'blame', 'blanket', 'blast', 'blaze', 'bleed', 'blend', 'bless', 'blessing', 'blind', 'blister', 'bloch', 'block', 'blood', 'blow', 'blue', 'bluish', 'blush', 'board', 'boat', 'bodice', 'body', 'bodysuit', 'boil', 'bold', 'bolster', 'bolt', 'bomb', 'bomber', 'bone', 'bonus', 'book', 'booklet', 'boot', 'border', 'bore', 'boring', 'boris', 'borrow', 'bosom', 'boss', 'boston', 'bostonian', 'both', 'bother', 'bothersome', 'bottle', 'bottom', 'bough', 'bought', 'bounce', 'bound', 'bout', 'boutique', 'bow', 'box', 'boxer', 'boy', 'boyfriend', 'boyshort', 'br', 'brace', 'bracelet', 'brag', 'brain', 'branch', 'brand', 'brass', 'bravado', 'brazil', 'breach', 'break', 'breaker', 'breaking', 'breast', 'breasted', 'breastfeed', 'breath', 'breathability', 'breathable', 'breathe', 'breathing', 'breeze', 'breezy', 'brick', 'bridesmaid', 'bridge', 'brief', 'briefcase', 'bright', 'brighter', 'brightly', 'brightness', 'brilliant', 'brim', 'bring', 'britain', 'british', 'brittle', 'broad', 'broke', 'broken', 'bronze', 'brother', 'brotherinlaw', 'brown', 'browse', 'bruise', 'brush', 'bsetup', 'bubble', 'buck', 'bucket', 'buckle', 'bud', 'budget', 'buena', 'buff', 'bug', 'buggy', 'build', 'building', 'bulge', 'bulk', 'bulky', 'bull', 'bullet', 'bump', 'bunch', 'bundle', 'bunion', 'burgundy', 'burn', 'bury', 'bus', 'bush', 'bushy', 'business', 'bust', 'busy', 'but', 'butt', 'butterfly', 'buttock', 'button', 'buxton', 'buy', 'buyer', 'buying', 'buzz', 'by', 'cadet', 'cage', 'cake', 'calculate', 'calculated', 'calculation', 'calendar', 'calf', 'calibre', 'calidad', 'california', 'call', 'calvin', 'camel', 'camera', 'camisole', 'camouflage', 'camp', 'camping', 'can', 'canada', 'cancel', 'cancer', 'candle', 'candy', 'canopy', 'canva', 'canvas', 'cap', 'capability', 'capable', 'capacity', 'cape', 'caper', 'capered', 'capezio', 'captain', 'capture', 'car', 'carbon', 'card', 'cardboard', 'cardinal', 'care', 'career', 'careful', 'carefully', 'careless', 'cargo', 'caribbean', 'carpenter', 'carpet', 'carpi', 'carrier', 'carry', 'cart', 'carter', 'case', 'caseback', 'cash', 'cashier', 'casque', 'cast', 'casual', 'casually', 'cat', 'catalogue', 'catch', 'category', 'caterpillar', 'cathcart', 'caught', 'cause', 'caution', 'cautious', 'cedar', 'celebrate', 'cell', 'cellar', 'celtic', 'cement', 'cent', 'center', 'central', 'century', 'ceremony', 'certain', 'certainly', 'chafe', 'chaff', 'chaffing', 'chain', 'chair', 'challenge', 'champ', 'champion', 'chance', 'change', 'changed', 'channel', 'chaos', 'character', 'characteristic', 'charcoal', 'charge', 'charity', 'charm', 'chart', 'chase', 'cheap', 'cheaper', 'cheaply', 'check', 'checkbook', 'checking', 'cheek', 'cheese', 'chemical', 'chemise', 'cherokee', 'chest', 'chester', 'chestnut', 'chew', 'chicago', 'chicken', 'chief', 'child', 'childhood', 'chill', 'chilly', 'chime', 'chin', 'china', 'chinchilla', 'chinese', 'chink', 'chintz', 'chip', 'chlorine', 'chocolate', 'choice', 'choke', 'choose', 'chose', 'christma', 'christmas', 'chronic', 'chronograph', 'chronometer', 'chubby', 'chuck', 'church', 'circle', 'circular', 'circulation', 'circumstance', 'citizen', 'city', 'civilian', 'cl', 'claim', 'clamp', 'clarity', 'clark', 'clash', 'clasp', 'class', 'classic', 'classroom', 'claw', 'clean', 'cleaner', 'cleaning', 'clear', 'clearance', 'clearly', 'cleavage', 'cleft', 'clergy', 'clever', 'click', 'client', 'climate', 'climb', 'climbing', 'clinch', 'cling', 'clinical', 'clip', 'clock', 'close', 'closed', 'closely', 'closer', 'closet', 'closing', 'closure', 'clot', 'cloth', 'clothe', 'clothing', 'cloud', 'clown', 'club', 'clue', 'clumsy', 'clung', 'clutch', 'cm', 'co', 'coach', 'coal', 'coarse', 'coast', 'coat', 'coating', 'cobbler', 'code', 'coffee', 'coffin', 'coil', 'coin', 'cold', 'colder', 'colfax', 'coli', 'collapse', 'collar', 'collect', 'collection', 'collector', 'college', 'color', 'colorado', 'colored', 'coloring', 'colour', 'coloured', 'colourful', 'columbia', 'comb', 'combat', 'combination', 'combine', 'come', 'comedy', 'comfort', 'comfortable', 'comfortablethe', 'comfortably', 'command', 'comment', 'commercial', 'common', 'commune', 'community', 'compact', 'companion', 'company', 'comparable', 'compare', 'comparison', 'compartment', 'compass', 'compensate', 'compete', 'competition', 'competitive', 'competitor', 'complain', 'complaint', 'complement', 'complete', 'completely', 'complex', 'complicate', 'complicated', 'compliment', 'comply', 'component', 'composite', 'composition', 'compress', 'compression', 'compromise', 'computer', 'con', 'conceal', 'concentrate', 'concept', 'concern', 'concerned', 'concert', 'conclusion', 'concrete', 'condition', 'cone', 'confidence', 'confident', 'configuration', 'confine', 'confirm', 'conform', 'confuse', 'confused', 'confusing', 'conjunction', 'connect', 'connection', 'connoisseur', 'conscious', 'consequently', 'conservative', 'consider', 'considerable', 'considerably', 'consideration', 'considering', 'consist', 'consistency', 'consistent', 'consistently', 'console', 'constant', 'constantly', 'constrict', 'construct', 'construction', 'consumer', 'contact', 'contain', 'container', 'content', 'contest', 'continually', 'continue', 'continuous', 'contour', 'contract', 'contractor', 'contrast', 'contribute', 'control', 'convenience', 'convenient', 'convention', 'conventional', 'conversation', 'converse', 'convert', 'convertible', 'convince', 'convinced', 'cook', 'cooking', 'cool', 'coolness', 'cooper', 'coordinate', 'copper', 'copy', 'coral', 'cord', 'cordon', 'core', 'cork', 'corn', 'corner', 'corporate', 'correct', 'correctly', 'correspond', 'corset', 'cortex', 'cos', 'cosmetic', 'cost', 'costa', 'costly', 'costo', 'costume', 'cotton', 'couch', 'could', 'couldn', 'count', 'countdown', 'counter', 'counterfeit', 'countless', 'country', 'county', 'couple', 'coupon', 'course', 'court', 'cousin', 'couture', 'cover', 'coverage', 'covered', 'cowboy', 'crack', 'cradle', 'craft', 'craftsmanship', 'cram', 'cramp', 'cramped', 'crawl', 'crazy', 'cream', 'crease', 'create', 'credit', 'creek', 'creep', 'crew', 'crime', 'cripple', 'crisp', 'criterion', 'critical', 'criticism', 'crooked', 'crop', 'cros', 'crosbody', 'cross', 'crouch', 'crowd', 'crown', 'cruise', 'crumple', 'crush', 'crutch', 'cruz', 'cry', 'crystal', 'cuba', 'cuff', 'culture', 'cumberland', 'cumbersome', 'cup', 'cure', 'curious', 'curl', 'curly', 'currency', 'current', 'currently', 'curse', 'curve', 'curved', 'cushion', 'cushioned', 'custom', 'customer', 'cut', 'cycle', 'cycling', 'cyclop', 'cylinder', 'da', 'dad', 'daddy', 'daily', 'dainty', 'dakin', 'dakota', 'damage', 'damaged', 'damn', 'damp', 'dan', 'dance', 'dancer', 'dancing', 'danger', 'dangerous', 'dangle', 'daniel', 'dare', 'dark', 'darker', 'darkness', 'darling', 'dash', 'database', 'date', 'datum', 'daughter', 'daughterinlaw', 'dawn', 'day', 'daycare', 'daylight', 'daypack', 'daysthe', 'daytime', 'dayton', 'de', 'dead', 'deal', 'dealer', 'dear', 'dearfoam', 'death', 'debate', 'debit', 'debut', 'decade', 'deceive', 'december', 'decent', 'decently', 'decide', 'decision', 'deck', 'declare', 'decline', 'decorate', 'decoration', 'decorative', 'deduce', 'deep', 'deeper', 'deer', 'def', 'default', 'defeat', 'defect', 'defective', 'defiantly', 'definite', 'definitely', 'definition', 'deglazer', 'degree', 'del', 'delay', 'delegate', 'delicate', 'delight', 'delighted', 'delightful', 'deliver', 'delivery', 'demand', 'deni', 'denis', 'dense', 'deny', 'deodorant', 'department', 'depend', 'dependable', 'dependent', 'depict', 'deploy', 'depth', 'describe', 'description', 'desert', 'deserve', 'design', 'designate', 'designer', 'desire', 'desk', 'desperate', 'despite', 'destination', 'destroy', 'detachable', 'detail', 'detailed', 'deter', 'detergent', 'deteriorate', 'determine', 'develop', 'device', 'dew', 'dexterity', 'diabetic', 'dial', 'diameter', 'diamond', 'didn', 'die', 'diet', 'differ', 'difference', 'different', 'differently', 'difficult', 'difficulty', 'dig', 'dighton', 'digit', 'digital', 'digitalanalog', 'dilute', 'dim', 'dimension', 'diminish', 'dingley', 'dingy', 'dining', 'dinner', 'dinnerless', 'dip', 'direct', 'direction', 'directly', 'dirt', 'dirty', 'disability', 'disabled', 'disagree', 'disappear', 'disappoint', 'disappointed', 'disappointing', 'disappointment', 'disc', 'discard', 'discoloration', 'discomfort', 'discontinue', 'discount', 'discover', 'discreet', 'discrepancy', 'discrete', 'disguise', 'dish', 'disintegrate', 'dislike', 'dismount', 'displace', 'display', 'disposable', 'disposal', 'dissection', 'distance', 'distinct', 'distinctive', 'distract', 'distressed', 'distribute', 'dive', 'diver', 'divide', 'diving', 'division', 'do', 'dock', 'doctor', 'document', 'doesn', 'dog', 'doll', 'dollar', 'dome', 'dominican', 'donate', 'donation', 'done', 'door', 'dootie', 'dose', 'dot', 'double', 'doubt', 'doubtful', 'down', 'downgrade', 'download', 'downpour', 'downside', 'downward', 'dozen', 'dr', 'drab', 'draft', 'drag', 'dragon', 'drain', 'drama', 'dramatic', 'dramatically', 'drape', 'draw', 'drawback', 'drawer', 'drawstr', 'drawstring', 'dread', 'dream', 'dres', 'dress', 'dressed', 'dresser', 'dressing', 'drift', 'drill', 'drink', 'drip', 'drive', 'driver', 'driveway', 'driving', 'drone', 'droning', 'droop', 'drop', 'dry', 'drying', 'du', 'dual', 'duck', 'duct', 'due', 'dull', 'dumb', 'dump', 'dung', 'dungaree', 'duplicate', 'duragold', 'during', 'dust', 'dusted', 'dutch', 'duty', 'dwyer', 'dye', 'each', 'eagle', 'ear', 'earlier', 'early', 'earmuff', 'earn', 'earner', 'earning', 'earring', 'earth', 'ease', 'easier', 'easily', 'east', 'easter', 'easy', 'eat', 'ebook', 'ecodrive', 'economic', 'economical', 'ecstatic', 'edge', 'edit', 'edition', 'edmund', 'effect', 'effective', 'effectively', 'efficient', 'effort', 'eg', 'egg', 'egypt', 'eight', 'either', 'el', 'elastic', 'elasticity', 'elbow', 'elder', 'elderly', 'electric', 'electricity', 'electronic', 'elegance', 'elegant', 'element', 'eleven', 'eligible', 'eliminate', 'elingwod', 'elite', 'elope', 'else', 'elsewhere', 'em', 'email', 'embarrass', 'embarrassed', 'embarrassing', 'emblem', 'emboss', 'embrace', 'embroider', 'embroidery', 'emergency', 'emphasize', 'employ', 'employment', 'empty', 'en', 'enable', 'enclose', 'encounter', 'encourage', 'end', 'endless', 'endorsement', 'endow', 'endowed', 'endure', 'enemy', 'energy', 'engage', 'engaged', 'engineer', 'engineering', 'england', 'english', 'enhance', 'enjoy', 'enormous', 'enough', 'ensure', 'enter', 'entire', 'entirely', 'entreat', 'entry', 'envelope', 'environment', 'equal', 'equally', 'equipment', 'equivalent', 'er', 'era', 'errand', 'error', 'es', 'escape', 'esp', 'especially', 'essential', 'essentially', 'est', 'estate', 'estimate', 'etc', 'euer', 'europe', 'european', 'evaluate', 'evan', 'eve', 'even', 'evening', 'evenly', 'event', 'eventhough', 'eventually', 'ever', 'every', 'everybody', 'everyday', 'everyone', 'everything', 'everytime', 'everywhere', 'evidence', 'evident', 'evidently', 'evil', 'ex', 'exact', 'exactly', 'examine', 'example', 'exceed', 'excellence', 'excellent', 'except', 'exception', 'exceptional', 'exceptionally', 'excess', 'excessive', 'excessively', 'exchange', 'excite', 'excited', 'excitement', 'exciting', 'exclusively', 'excursion', 'exercise', 'exist', 'exit', 'exodri', 'exoficio', 'expand', 'expandable', 'expansion', 'expect', 'expectation', 'expected', 'expedition', 'expense', 'expensive', 'experience', 'experienced', 'experiment', 'expert', 'explain', 'explanation', 'explore', 'expose', 'exposure', 'express', 'extend', 'extended', 'extension', 'extensive', 'extent', 'exterior', 'external', 'extra', 'extreme', 'extremely', 'eye', 'eyeglass', 'eyelid', 'fabric', 'fabulous', 'face', 'facility', 'fact', 'factor', 'factory', 'fad', 'fade', 'fail', 'failure', 'fair', 'fairly', 'fairy', 'faithful', 'fall', 'false', 'familiar', 'family', 'famous', 'fan', 'fancy', 'fanny', 'fantastic', 'far', 'fare', 'farm', 'farmer', 'farther', 'fashion', 'fashionable', 'fashioned', 'fashioning', 'fast', 'fasten', 'fastened', 'fastener', 'faster', 'fat', 'father', 'fatherinlaw', 'fatigue', 'fatty', 'fault', 'faut', 'favor', 'favorit', 'favorite', 'favourite', 'fear', 'fearless', 'fearlessly', 'feather', 'feature', 'feb', 'february', 'fee', 'feed', 'feedback', 'feel', 'feeling', 'feet', 'fell', 'fellow', 'felt', 'female', 'feminine', 'fence', 'festival', 'fetch', 'fete', 'few', 'fiance', 'fianceacute', 'fiancee', 'fibre', 'field', 'fifteen', 'fifth', 'fifty', 'fig', 'fight', 'figure', 'figured', 'file', 'filigree', 'fill', 'film', 'filter', 'filthy', 'final', 'finally', 'find', 'finding', 'fine', 'finer', 'finger', 'fingernail', 'fingertip', 'finish', 'finished', 'fir', 'fire', 'firing', 'firm', 'firmly', 'first', 'firstly', 'fish', 'fisherman', 'fishing', 'fit', 'fitness', 'fitted', 'fitting', 'five', 'fivestar', 'fix', 'flag', 'flair', 'flame', 'flannel', 'flap', 'flaps', 'flare', 'flash', 'flashlight', 'flat', 'flatten', 'flatter', 'flattering', 'flaw', 'fleecy', 'flesh', 'flex', 'flexibility', 'flexible', 'flight', 'flipflop', 'flipflops', 'float', 'flog', 'flood', 'floor', 'flop', 'floppy', 'flora', 'florida', 'florsheim', 'flow', 'flower', 'fluctuate', 'fluff', 'fluffy', 'fluid', 'flush', 'fly', 'foam', 'focus', 'fog', 'foi', 'foil', 'fold', 'folk', 'follow', 'follower', 'fond', 'font', 'food', 'fool', 'foot', 'football', 'footgear', 'footstep', 'for', 'forbid', 'force', 'forearm', 'forehead', 'foreign', 'foreman', 'foremost', 'forest', 'forever', 'forgery', 'forget', 'forgive', 'form', 'formal', 'format', 'former', 'formula', 'forth', 'fortunate', 'fortunately', 'fortune', 'forty', 'forward', 'fossil', 'found', 'foundation', 'four', 'fourth', 'fox', 'fraction', 'fragile', 'frame', 'france', 'frankly', 'fraser', 'fray', 'frayed', 'freak', 'free', 'freedom', 'freely', 'freeze', 'french', 'frequent', 'frequently', 'fresh', 'friction', 'friday', 'friend', 'friendly', 'frigid', 'fringe', 'from', 'front', 'frontier', 'fruit', 'frustrate', 'frustrated', 'frustration', 'frye', 'ft', 'fulfil', 'fulfill', 'full', 'fully', 'fulsize', 'fun', 'function', 'functional', 'functionality', 'funeral', 'funny', 'fur', 'furniture', 'fuss', 'fussy', 'future', 'gain', 'gaiter', 'gal', 'gallery', 'gallop', 'gamble', 'game', 'gap', 'garage', 'garden', 'gardening', 'garment', 'garter', 'gas', 'gascon', 'gasp', 'gate', 'gather', 'gauge', 'gauzy', 'gear', 'gem', 'general', 'generally', 'generation', 'generous', 'generously', 'genetic', 'genius', 'gentle', 'gentleman', 'gently', 'genuine', 'georgia', 'german', 'germany', 'get', 'getting', 'ghost', 'giant', 'gift', 'gigantic', 'gilman', 'ginger', 'girdle', 'girl', 'girlfriend', 'girth', 'give', 'glad', 'gladly', 'glamorise', 'glance', 'glander', 'glare', 'glass', 'glide', 'glimmer', 'glitter', 'glory', 'gloss', 'glossy', 'glove', 'glow', 'glue', 'go', 'goal', 'god', 'goddess', 'godlok', 'godson', 'gold', 'golden', 'golf', 'gone', 'good', 'goodness', 'goodwill', 'goose', 'gordon', 'gorge', 'gorgeous', 'got', 'gotten', 'gouge', 'gown', 'grab', 'gracious', 'grade', 'gradually', 'graduate', 'graft', 'grain', 'grand', 'grandchild', 'granddad', 'granddaughter', 'grandmother', 'grandson', 'granger', 'granny', 'grant', 'grape', 'graphic', 'grass', 'grateful', 'grave', 'gravel', 'gravity', 'gray', 'grease', 'great', 'greatly', 'green', 'greenish', 'grey', 'grid', 'grime', 'grind', 'grip', 'grm', 'grocer', 'grocery', 'groin', 'grommet', 'groom', 'groove', 'gross', 'ground', 'group', 'grow', 'grown', 'growth', 'grumpy', 'guarantee', 'guard', 'gues', 'guess', 'guest', 'guide', 'guideline', 'guilty', 'gum', 'gumma', 'gun', 'gusset', 'gust', 'gustave', 'gusto', 'gut', 'guy', 'ha', 'habit', 'hack', 'hair', 'haired', 'haiti', 'half', 'halfsize', 'halfway', 'halloween', 'halo', 'halt', 'hammer', 'hamper', 'hand', 'handcuff', 'handful', 'handkerchief', 'handle', 'handling', 'handsome', 'handwash', 'handy', 'hang', 'hanging', 'happen', 'happier', 'happily', 'happy', 'hard', 'harder', 'hardihood', 'hardly', 'hardware', 'hardy', 'harley', 'harm', 'harness', 'harold', 'harry', 'harsh', 'haste', 'hat', 'hata', 'hate', 'haul', 'havaiana', 'havana', 'have', 'haven', 'hawaii', 'head', 'headache', 'headband', 'headphone', 'heal', 'healing', 'health', 'healthy', 'heap', 'hear', 'hearing', 'heart', 'heartbroken', 'heartfelt', 'heartily', 'heat', 'heather', 'heaven', 'heavenly', 'heavier', 'heavily', 'heavy', 'heavyduty', 'heavyweight', 'heel', 'height', 'held', 'hell', 'hello', 'helmet', 'help', 'helpful', 'hem', 'hemp', 'hence', 'henry', 'her', 'here', 'herethe', 'hero', 'hesitate', 'hesitation', 'hetty', 'hey', 'hi', 'hidden', 'hide', 'hideous', 'hiding', 'high', 'higher', 'highly', 'highquality', 'hill', 'hinder', 'hinge', 'hint', 'hip', 'hiram', 'history', 'hit', 'hm', 'ho', 'hobby', 'hold', 'holder', 'holding', 'hole', 'holiday', 'holy', 'homage', 'home', 'homework', 'hondura', 'honest', 'honestly', 'honey', 'honeymoon', 'honor', 'hood', 'hooded', 'hoofs', 'hook', 'hooked', 'hop', 'hope', 'hopeful', 'hopefully', 'hoping', 'horizontal', 'horn', 'horrible', 'horribly', 'horrid', 'horror', 'horse', 'hosmer', 'hospital', 'host', 'hot', 'hotel', 'hour', 'hourglass', 'hours', 'house', 'household', 'how', 'however', 'hue', 'hug', 'huge', 'hum', 'human', 'humble', 'humid', 'humidity', 'hundred', 'hung', 'hunger', 'hunt', 'hunter', 'hunting', 'hurry', 'hurt', 'husband', 'husky', 'hut', 'hydration', 'ice', 'icy', 'idea', 'ideal', 'ideally', 'identical', 'identify', 'if', 'ignore', 'ii', 'ill', 'illuminate', 'illumination', 'iluminator', 'image', 'imagination', 'imagine', 'imitation', 'immediate', 'immediately', 'immensely', 'immersion', 'impact', 'imperfection', 'import', 'importance', 'important', 'importantly', 'impossible', 'impres', 'impress', 'impressed', 'impression', 'impressive', 'imprint', 'improve', 'improved', 'improvement', 'in', 'inaccurate', 'inbetwen', 'inch', 'incline', 'inclined', 'include', 'inconsistency', 'inconsistent', 'inconvenience', 'inconvenient', 'incorrect', 'incorrectly', 'increase', 'incredible', 'incredibly', 'indeed', 'indentation', 'indestructible', 'index', 'india', 'indicate', 'indicator', 'indie', 'indigo', 'individual', 'individually', 'indoor', 'indoors', 'induration', 'industrial', 'industry', 'inevitably', 'infant', 'infection', 'inferior', 'inflammable', 'inform', 'informal', 'information', 'ingenious', 'initial', 'initially', 'injury', 'ink', 'inner', 'insanely', 'insect', 'insert', 'inside', 'insight', 'insist', 'inspect', 'inspection', 'inspector', 'inspire', 'instal', 'install', 'instance', 'instant', 'instantly', 'instead', 'instep', 'instruct', 'instruction', 'instructor', 'instrument', 'insulate', 'insulated', 'insult', 'insurance', 'intact', 'integrity', 'intend', 'intended', 'intense', 'intent', 'intention', 'intentionally', 'interest', 'interested', 'interesting', 'interface', 'interfere', 'interior', 'internal', 'international', 'internet', 'interval', 'interview', 'intimate', 'into', 'introduce', 'intuition', 'invent', 'inventor', 'invest', 'investment', 'invisible', 'invite', 'involf', 'involve', 'involved', 'inward', 'ireland', 'iridium', 'irish', 'iron', 'ironic', 'irregular', 'irritate', 'irritated', 'irritating', 'irritation', 'island', 'isn', 'iso', 'isotoner', 'issue', 'it', 'italian', 'italy', 'itch', 'itchiness', 'itchy', 'item', 'ivory', 'jack', 'jacket', 'jam', 'jame', 'jan', 'jane', 'january', 'japan', 'japanese', 'jaw', 'jazz', 'jealous', 'jean', 'jeansthey', 'jersey', 'jesuit', 'jet', 'jewel', 'jeweller', 'jewellery', 'jezebel', 'jim', 'jingle', 'job', 'jockey', 'john', 'join', 'joint', 'joke', 'journey', 'joy', 'judge', 'julie', 'july', 'jump', 'jumper', 'jumping', 'june', 'jungle', 'junior', 'just', 'justice', 'justify', 'kangaroo', 'kayaking', 'keen', 'keep', 'keeper', 'keeping', 'keepsake', 'kenneth', 'kept', 'key', 'kick', 'kid', 'kill', 'killer', 'kind', 'kindle', 'kinetic', 'king', 'kis', 'kiss', 'kit', 'kitchen', 'kitty', 'knee', 'kneel', 'knife', 'knit', 'knob', 'knock', 'knockoff', 'knot', 'know', 'knowledge', 'known', 'knuckle', 'la', 'lab', 'label', 'labor', 'lace', 'lack', 'lacking', 'ladder', 'lady', 'lag', 'lagging', 'lake', 'lamb', 'lamp', 'land', 'landau', 'lane', 'language', 'lank', 'lap', 'large', 'largely', 'larger', 'las', 'last', 'lasting', 'lastly', 'latch', 'late', 'lately', 'later', 'lateral', 'lathe', 'latter', 'laugh', 'laura', 'laurel', 'lavender', 'law', 'lawless', 'lawn', 'lawton', 'lay', 'layer', 'laying', 'layout', 'lazy', 'lb', 'le', 'lead', 'leader', 'leaf', 'leak', 'leakage', 'lean', 'leap', 'learn', 'learning', 'least', 'leather', 'leave', 'lee', 'left', 'leg', 'legendary', 'legging', 'legible', 'legs', 'leisure', 'len', 'lend', 'length', 'lengthen', 'lengthwise', 'lengthy', 'lens', 'leopard', 'les', 'less', 'lessen', 'lesson', 'let', 'letter', 'level', 'lever', 'leverback', 'levi', 'levy', 'lewi', 'lewis', 'liable', 'liberal', 'license', 'lick', 'lid', 'lie', 'life', 'lifesaver', 'lifespan', 'lifestyle', 'lifetime', 'lift', 'lifting', 'ligament', 'light', 'lighter', 'lighting', 'lightly', 'lightness', 'lightning', 'lightweight', 'like', 'liked', 'likely', 'likewise', 'liking', 'lilac', 'lilyete', 'limb', 'lime', 'limit', 'limitation', 'limited', 'limp', 'lincoln', 'line', 'liner', 'linger', 'lingered', 'lingo', 'lining', 'link', 'lint', 'lip', 'lipped', 'lipping', 'lipstick', 'liquid', 'list', 'listen', 'literally', 'lithe', 'lithium', 'little', 'live', 'living', 'll', 'lo', 'load', 'loaded', 'loafer', 'loathe', 'lobster', 'local', 'locally', 'locate', 'location', 'lock', 'locket', 'log', 'logging', 'login', 'lollipop', 'london', 'long', 'longer', 'longevity', 'longlast', 'longsleve', 'look', 'looked', 'looking', 'lookout', 'loom', 'loop', 'loose', 'loosely', 'loosen', 'loot', 'lord', 'los', 'lose', 'loss', 'lost', 'lot', 'lotion', 'loud', 'louise', 'lounge', 'louse', 'love', 'loved', 'lovely', 'lover', 'loving', 'low', 'lower', 'loyal', 'luck', 'luckily', 'lucky', 'luggage', 'lui', 'luke', 'luman', 'lumen', 'luminescent', 'luminous', 'lump', 'lunaire', 'lunch', 'lure', 'luster', 'luxurious', 'luxury', 'ma', 'machine', 'mad', 'made', 'madman', 'madonna', 'magazine', 'magic', 'magical', 'magnet', 'magnetic', 'magnify', 'magnifying', 'mahogany', 'maidenform', 'mail', 'mailbox', 'main', 'maine', 'mainly', 'maintain', 'maintenance', 'major', 'majority', 'make', 'maker', 'making', 'male', 'mall', 'mamma', 'man', 'manage', 'mandate', 'maneuver', 'manipulate', 'manly', 'manner', 'manual', 'manufacture', 'manufacturer', 'manufacturing', 'many', 'map', 'marathon', 'march', 'margin', 'marine', 'mark', 'marked', 'marker', 'market', 'marketing', 'marking', 'maroon', 'married', 'marshall', 'marvelous', 'mary', 'masculine', 'mask', 'mass', 'massage', 'massive', 'master', 'mat', 'match', 'material', 'matter', 'mature', 'max', 'maxim', 'maximum', 'may', 'maybe', 'meal', 'mean', 'meaning', 'meant', 'meantime', 'measure', 'measured', 'measurement', 'mechanic', 'mechanical', 'mechanism', 'med', 'medal', 'medical', 'medium', 'meet', 'meeting', 'melissa', 'melt', 'member', 'membership', 'memory', 'mend', 'mental', 'mentally', 'mention', 'mephisto', 'merchandise', 'merchant', 'mere', 'merely', 'merit', 'merry', 'mesh', 'mess', 'message', 'messenger', 'metal', 'metallic', 'mete', 'method', 'mexico', 'mi', 'michigan', 'micro', 'microfiber', 'microphone', 'mid', 'midcalf', 'middle', 'midnight', 'midst', 'midwife', 'milan', 'mild', 'mile', 'mileage', 'military', 'milk', 'million', 'mimi', 'min', 'mind', 'minded', 'mine', 'mineral', 'minetonka', 'minetonkas', 'minimal', 'minimalist', 'minimize', 'minimum', 'minor', 'minus', 'minute', 'miracle', 'mirror', 'mis', 'miserable', 'misha', 'mislabel', 'mislead', 'miss', 'missing', 'mission', 'mistake', 'mistaken', 'misty', 'mix', 'mixed', 'mm', 'mo', 'mob', 'mobile', 'mock', 'mode', 'model', 'moderate', 'moderately', 'modern', 'modest', 'modestly', 'modesty', 'modification', 'modify', 'module', 'moisture', 'mold', 'molded', 'moment', 'mon', 'monday', 'money', 'monitor', 'monkey', 'monster', 'month', 'monthly', 'mood', 'moon', 'moral', 'more', 'moreover', 'mormon', 'morning', 'mortar', 'moscow', 'moss', 'most', 'mostly', 'mother', 'motherinlaw', 'motion', 'motorcycle', 'mount', 'mountain', 'mouth', 'movable', 'move', 'movement', 'movie', 'moving', 'mow', 'mrs', 'ms', 'much', 'mud', 'muddy', 'mug', 'mule', 'multi', 'multiple', 'multipurpose', 'mummy', 'munch', 'mundi', 'muscle', 'muscular', 'music', 'must', 'myoma', 'mystery', 'na', 'nail', 'naked', 'name', 'nan', 'narrow', 'narrowed', 'nasal', 'naso', 'nasty', 'national', 'native', 'natural', 'naturally', 'nature', 'naval', 'navigable', 'navy', 'nd', 'ne', 'near', 'nearby', 'nearly', 'neat', 'neatly', 'necessarily', 'necessary', 'necessity', 'neck', 'necklace', 'need', 'needed', 'needle', 'needless', 'negative', 'neighbor', 'neighborhood', 'neither', 'neoprene', 'nephew', 'nerve', 'nervous', 'net', 'nether', 'network', 'neuro', 'neuroma', 'neuropathic', 'neutral', 'never', 'nevertheless', 'new', 'newer', 'newport', 'news', 'newspaper', 'next', 'nice', 'nicely', 'nicer', 'nicest', 'nicety', 'nickel', 'niece', 'night', 'nightgown', 'nightmare', 'nighttime', 'nina', 'nine', 'nip', 'nipper', 'nipple', 'no', 'nobody', 'nodule', 'noise', 'noisy', 'non', 'none', 'nonetheless', 'nonexistent', 'nonpolariz', 'nonsense', 'nonslip', 'nonstop', 'noon', 'nordstrom', 'norm', 'normal', 'normally', 'north', 'northeast', 'northern', 'northwest', 'nose', 'not', 'notch', 'note', 'notebook', 'noted', 'nothing', 'notice', 'noticeable', 'noticeably', 'noticed', 'novel', 'november', 'now', 'nowadays', 'nowhere', 'numb', 'number', 'numerous', 'nurse', 'nursing', 'nut', 'nuts', 'ny', 'object', 'obnoxious', 'obscure', 'observation', 'obsess', 'obtain', 'obvious', 'obviously', 'occasion', 'occasional', 'occasionally', 'occur', 'ocean', 'october', 'odd', 'oddly', 'odor', 'of', 'off', 'offer', 'offering', 'office', 'officer', 'official', 'offset', 'often', 'oh', 'oil', 'oily', 'ointment', 'ok', 'oka', 'okay', 'old', 'oldfashion', 'olga', 'olive', 'on', 'one', 'onepiece', 'onethis', 'online', 'only', 'onset', 'onto', 'ooze', 'op', 'opaque', 'open', 'opened', 'opening', 'opera', 'operate', 'operation', 'operator', 'opinion', 'opportunity', 'oppose', 'opposite', 'opt', 'option', 'or', 'orange', 'order', 'ordered', 'ordering', 'ordinarily', 'ordinary', 'org', 'organic', 'organization', 'organizational', 'organize', 'organized', 'organizer', 'original', 'originally', 'orthopaedic', 'orthotic', 'other', 'otherwise', 'ought', 'ounce', 'out', 'outcast', 'outcome', 'outdoor', 'outer', 'outerwear', 'outfit', 'outgrowth', 'outing', 'outlet', 'outline', 'outrageous', 'outre', 'outside', 'outstanding', 'outward', 'oval', 'oven', 'over', 'overall', 'overcoat', 'overhead', 'overlap', 'overlay', 'overlie', 'overlook', 'overnight', 'overprice', 'overpriced', 'overseas', 'overshoe', 'overshoes', 'oversiz', 'oversized', 'overstuffed', 'overwhelming', 'owe', 'own', 'owner', 'oxford', 'oz', 'pace', 'pacific', 'pack', 'package', 'packed', 'packet', 'packing', 'pad', 'padded', 'page', 'pain', 'painful', 'painless', 'paint', 'painter', 'painting', 'pair', 'pairs', 'palace', 'pale', 'palm', 'palmar', 'panama', 'panel', 'pantyhose', 'pantyline', 'paper', 'paperthin', 'paperwork', 'par', 'para', 'parade', 'parameter', 'paratrooper', 'parent', 'paris', 'park', 'parking', 'part', 'partially', 'particular', 'particularly', 'partie', 'partition', 'partner', 'party', 'pas', 'pass', 'passion', 'passport', 'past', 'paste', 'pat', 'patch', 'patent', 'paternity', 'path', 'pathfinder', 'patience', 'patient', 'pattern', 'pavement', 'paw', 'pay', 'peace', 'peak', 'pear', 'pearl', 'peasant', 'pebble', 'peel', 'pen', 'pencil', 'penetrate', 'penny', 'people', 'per', 'percent', 'percentage', 'perfect', 'perfection', 'perfectly', 'perform', 'performance', 'perhaps', 'peri', 'period', 'periodically', 'periwinkle', 'permanent', 'permanently', 'perpetual', 'perry', 'person', 'personal', 'personality', 'personally', 'perspective', 'perspiration', 'pet', 'peter', 'petite', 'petty', 'phantom', 'phase', 'phone', 'photo', 'photograph', 'photographer', 'phrase', 'physical', 'pick', 'picking', 'pickpocket', 'picnic', 'picture', 'pictured', 'piece', 'pier', 'pierce', 'pierre', 'pig', 'pile', 'pill', 'pillage', 'pillow', 'pilot', 'pin', 'pinch', 'pink', 'pinkish', 'pip', 'pirate', 'pistol', 'pit', 'pitch', 'pity', 'place', 'placement', 'plague', 'plaid', 'plain', 'plan', 'plane', 'planet', 'planning', 'plant', 'plantar', 'planter', 'plastic', 'plate', 'platform', 'plating', 'platino', 'play', 'player', 'playing', 'plea', 'pleas', 'pleasant', 'pleasantly', 'please', 'pleased', 'pleasing', 'pleasure', 'plenty', 'pliable', 'plover', 'plug', 'plumber', 'plunge', 'plus', 'plush', 'pm', 'pobox', 'pock', 'pocket', 'podiatrist', 'point', 'pointed', 'poke', 'poland', 'polar', 'polarize', 'polarized', 'polartec', 'pole', 'police', 'policy', 'polish', 'polished', 'polite', 'poly', 'polyester', 'polyurethane', 'pool', 'poor', 'poorly', 'pop', 'popular', 'popularization', 'porch', 'port', 'portable', 'porter', 'portion', 'pose', 'position', 'positive', 'possibility', 'possible', 'possibly', 'post', 'postage', 'postpartum', 'posture', 'pot', 'potential', 'potentially', 'pouch', 'pound', 'pour', 'powder', 'power', 'powerful', 'pp', 'practical', 'practically', 'practice', 'praise', 'pre', 'preach', 'precious', 'precise', 'precisely', 'precision', 'predict', 'prefer', 'preferable', 'preference', 'preferred', 'pregnancy', 'pregnant', 'premature', 'premium', 'prepare', 'prepared', 'prepregnancy', 'preschool', 'prescription', 'present', 'presentable', 'presentation', 'preserve', 'preshrunk', 'preside', 'press', 'pressure', 'pretend', 'pretty', 'prevent', 'previous', 'previously', 'price', 'pricethe', 'prick', 'pricking', 'pride', 'primarily', 'primary', 'prime', 'princess', 'print', 'printing', 'prior', 'priority', 'private', 'pro', 'probably', 'problem', 'problematical', 'process', 'produce', 'product', 'production', 'profession', 'professional', 'professionally', 'profile', 'profit', 'program', 'progress', 'project', 'prolong', 'prominent', 'promise', 'promote', 'promotion', 'prompt', 'promptly', 'pron', 'pronation', 'prone', 'pronounce', 'pronounced', 'pronunciation', 'proof', 'prop', 'proper', 'properly', 'property', 'proportion', 'proportionate', 'protect', 'protection', 'protective', 'protrude', 'proud', 'prove', 'provide', 'provider', 'public', 'pucker', 'puddle', 'puff', 'puffy', 'pull', 'pump', 'punch', 'punishment', 'puppet', 'puppy', 'purchase', 'purchased', 'purchaser', 'purchasing', 'pure', 'purely', 'purple', 'purpose', 'purposely', 'purse', 'pursue', 'pus', 'push', 'put', 'quality', 'qualitythe', 'qualm', 'quantity', 'quarante', 'quart', 'quarter', 'que', 'queen', 'quest', 'question', 'quick', 'quickly', 'quiet', 'quietly', 'quit', 'quite', 'race', 'racerback', 'rack', 'radiant', 'radio', 'rag', 'ragged', 'rain', 'rainbow', 'raincoat', 'raincover', 'rainy', 'raise', 'ralph', 'ran', 'random', 'range', 'rank', 'rapid', 'rapidly', 'rare', 'rarely', 'rash', 'rat', 'rate', 'rather', 'rating', 'ratio', 'rattle', 'rave', 'raw', 'ray', 'rayban', 'razor', 'rd', 're', 'reach', 'reaction', 'read', 'readable', 'reader', 'readily', 'reading', 'readjust', 'ready', 'real', 'realise', 'realistic', 'reality', 'realize', 'really', 'rear', 'reason', 'reasonable', 'reasonably', 'recall', 'receipt', 'receive', 'received', 'receiver', 'recent', 'recently', 'reception', 'recess', 'recipient', 'reckless', 'recognition', 'recognize', 'recommend', 'recommendation', 'reconstruct', 'record', 'recorder', 'recover', 'rectangular', 'red', 'reddish', 'redoubt', 'redstone', 'reduce', 'reduction', 'reed', 'reef', 'refer', 'reference', 'reflect', 'reflection', 'reform', 'refresh', 'refund', 'refuse', 'regard', 'regardless', 'region', 'register', 'regret', 'regular', 'regularly', 'reinforce', 'reinforcement', 'relate', 'relation', 'relative', 'relatively', 'relax', 'relaxed', 'release', 'reliability', 'reliable', 'relief', 'relieve', 'relit', 'reluctant', 'reluctantly', 'rely', 'remain', 'remark', 'remarkable', 'remarkably', 'remedi', 'remedy', 'remember', 'remind', 'reminder', 'remote', 'removable', 'removal', 'remove', 'removed', 'render', 'renew', 'repair', 'repeat', 'repeatedly', 'repellent', 'replace', 'replaceable', 'replaced', 'replacement', 'reply', 'report', 'represent', 'republic', 'reputation', 'request', 'require', 'requirement', 'research', 'resect', 'resemble', 'reservation', 'reserve', 'reside', 'resident', 'residue', 'resin', 'resist', 'resistance', 'resistant', 'resolve', 'resort', 'respect', 'respond', 'response', 'responsible', 'rest', 'restaurant', 'restore', 'restrict', 'restrictive', 'restroom', 'result', 'retail', 'retailer', 'retain', 'retainer', 'retire', 'retract', 'retro', 'return', 'returned', 'reveal', 'reverse', 'reversible', 'review', 'reviews', 'rib', 'ribbed', 'ribbon', 'ribcage', 'rich', 'rid', 'ride', 'rider', 'ridge', 'ridiculous', 'ridiculously', 'riding', 'right', 'rigid', 'rigor', 'ring', 'rinse', 'rip', 'ripstop', 'rise', 'risk', 'risky', 'rite', 'rival', 'river', 'rivet', 'road', 'robe', 'robin', 'robust', 'rock', 'rocket', 'rockie', 'rockport', 'rocky', 'rod', 'role', 'roll', 'roller', 'rolling', 'roman', 'rome', 'roof', 'room', 'roomy', 'root', 'rope', 'rose', 'rosy', 'rotate', 'rotation', 'roth', 'rough', 'roughly', 'roughness', 'round', 'rounded', 'route', 'routine', 'row', 'royal', 'rub', 'rubber', 'rubberized', 'rude', 'ruffle', 'rug', 'rugg', 'rugged', 'ruin', 'rule', 'run', 'runner', 'running', 'rural', 'ruse', 'rush', 'russell', 'rust', 'ryazan', 'saber', 'sack', 'sacrifice', 'sad', 'saddle', 'sadly', 'safe', 'safely', 'safety', 'sage', 'sail', 'sailor', 'sake', 'salary', 'sale', 'salon', 'salt', 'same', 'samoan', 'san', 'sanction', 'sand', 'sandbag', 'sandstone', 'sandy', 'sang', 'sank', 'santa', 'santo', 'sap', 'sapphire', 'satin', 'satisfaction', 'satisfactory', 'satisfied', 'satisfy', 'saturday', 'sausage', 'savage', 'save', 'saving', 'saw', 'say', 'scale', 'scan', 'scandal', 'scar', 'scarf', 'scenario', 'scent', 'schedule', 'scheme', 'school', 'scissor', 'scoop', 'score', 'scot', 'scrap', 'scratch', 'scratched', 'scream', 'screen', 'screw', 'screwdown', 'screwdriver', 'scrub', 'scuffle', 'se', 'sea', 'seal', 'seam', 'seams', 'sear', 'search', 'season', 'seat', 'seattle', 'seawalker', 'sebago', 'second', 'secondary', 'secondly', 'secret', 'section', 'secure', 'securely', 'security', 'see', 'seek', 'seem', 'seemingly', 'seen', 'seize', 'seizing', 'seldom', 'select', 'selection', 'self', 'sell', 'seller', 'selling', 'semi', 'send', 'senior', 'sensation', 'sense', 'sensitive', 'sensitivity', 'separate', 'separately', 'separation', 'september', 'serie', 'series', 'serious', 'seriously', 'serve', 'service', 'serviceable', 'session', 'set', 'setting', 'settle', 'seven', 'several', 'severe', 'sevi', 'sew', 'sewing', 'sewn', 'sex', 'shade', 'shadowline', 'shaft', 'shake', 'shako', 'shakos', 'shall', 'shallow', 'shalt', 'shame', 'shampoo', 'shape', 'shapely', 'shapewear', 'share', 'sharp', 'shave', 'shaving', 'shawl', 'sheath', 'shed', 'sheen', 'sheep', 'sheepskin', 'sheer', 'sheet', 'shelf', 'shell', 'shelter', 'sherman', 'shield', 'shift', 'shin', 'shine', 'shiny', 'ship', 'shipment', 'shipper', 'shipping', 'shirt', 'shiver', 'shock', 'shocked', 'shod', 'shoe', 'shoelace', 'shoesandal', 'shoesthe', 'shoesthey', 'shoot', 'shop', 'shopping', 'shore', 'short', 'shortcoming', 'shorten', 'shorter', 'shortly', 'shot', 'should', 'shoulder', 'shout', 'shove', 'shovel', 'show', 'shower', 'showing', 'shrank', 'shred', 'shrink', 'shrinkage', 'shrinktofit', 'shrunk', 'shut', 'shy', 'si', 'sick', 'sickle', 'sickness', 'side', 'sidewalk', 'sideways', 'sigh', 'sight', 'sign', 'signal', 'signature', 'significant', 'significantly', 'silent', 'silhouette', 'silicon', 'silicone', 'silk', 'silly', 'silver', 'silvery', 'similar', 'similarly', 'simon', 'simple', 'simplicity', 'simply', 'sin', 'since', 'sing', 'singapore', 'single', 'sink', 'sinner', 'sister', 'sit', 'site', 'situation', 'six', 'size', 'sized', 'sizethe', 'skeptically', 'sketch', 'ski', 'skill', 'skin', 'skinny', 'skirt', 'skull', 'sky', 'slack', 'slander', 'slap', 'slate', 'sleek', 'sleep', 'sleeping', 'sleepless', 'sleev', 'sleeve', 'slender', 'slice', 'slide', 'slight', 'slightly', 'slim', 'sling', 'slip', 'slipper', 'slippered', 'slippers', 'slippery', 'slit', 'slogger', 'slope', 'slot', 'slough', 'sloughy', 'slow', 'slowly', 'small', 'smaller', 'smallish', 'smart', 'smartphone', 'smartwol', 'smash', 'smell', 'smile', 'smith', 'smoke', 'smooth', 'smoothly', 'smoothness', 'smudge', 'smythe', 'snack', 'snake', 'snakeskin', 'snap', 'sneer', 'snorkel', 'snort', 'snow', 'snowy', 'snuff', 'snug', 'snuggery', 'snugly', 'so', 'soak', 'soap', 'soccer', 'social', 'society', 'sock', 'socket', 'soda', 'soft', 'soften', 'softer', 'softly', 'softness', 'software', 'soil', 'sol', 'solar', 'solaratomic', 'soldier', 'sole', 'solid', 'solo', 'solution', 'solve', 'some', 'somebody', 'someday', 'somehow', 'someone', 'someplace', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'son', 'song', 'soninlaw', 'soon', 'sooner', 'soothe', 'sophisticated', 'sore', 'sorry', 'sort', 'soul', 'sound', 'source', 'south', 'southern', 'space', 'spacious', 'spade', 'spaghetti', 'spain', 'span', 'spanish', 'spare', 'sparkle', 'speak', 'speaker', 'special', 'specially', 'specific', 'specifically', 'specification', 'specify', 'speck', 'spectacular', 'speech', 'speed', 'speedy', 'spell', 'spend', 'spending', 'spent', 'spice', 'spider', 'spike', 'spill', 'spin', 'spine', 'spiral', 'spirit', 'spit', 'spite', 'splash', 'splint', 'split', 'spoil', 'sponge', 'spoon', 'sport', 'sporting', 'spot', 'spouse', 'spr', 'spray', 'spread', 'spring', 'springsumer', 'spur', 'spy', 'spyglass', 'square', 'squat', 'squeak', 'squeaky', 'squeeze', 'squish', 'squishy', 'st', 'stab', 'stability', 'stabilizer', 'stable', 'staff', 'stage', 'stain', 'stair', 'stamp', 'stance', 'stand', 'standard', 'standing', 'staple', 'star', 'starch', 'start', 'startle', 'state', 'statement', 'static', 'station', 'stationary', 'status', 'stay', 'stayed', 'stays', 'steady', 'steal', 'steam', 'steel', 'steep', 'stem', 'step', 'sterling', 'sternum', 'stick', 'sticky', 'stiff', 'stiffen', 'stiffness', 'still', 'stink', 'stitch', 'stitching', 'stock', 'stocking', 'stomach', 'stone', 'stonewash', 'stop', 'stoper', 'stoppage', 'stopwatch', 'storage', 'store', 'storm', 'story', 'stout', 'str', 'straight', 'straighten', 'straightforward', 'strain', 'strange', 'strangely', 'stranger', 'strap', 'straps', 'strapsthe', 'stray', 'stream', 'street', 'strength', 'strenuous', 'stress', 'stretch', 'stretchable', 'stretched', 'stretcher', 'stretchiness', 'strict', 'strictly', 'stride', 'strike', 'string', 'strip', 'stripe', 'stroke', 'stroll', 'strong', 'strongly', 'structure', 'struggle', 'stuck', 'stud', 'student', 'studio', 'study', 'stuff', 'stuffed', 'stumble', 'stun', 'stunning', 'stupid', 'sturdiness', 'sturdy', 'style', 'stylish', 'sub', 'subject', 'subjective', 'submarine', 'submerge', 'substance', 'substantial', 'substantially', 'substitute', 'subtle', 'subtract', 'success', 'successful', 'successfully', 'such', 'suck', 'sudden', 'suddenly', 'sue', 'suffer', 'suffice', 'sufficient', 'sufficiently', 'suggest', 'suggestion', 'suit', 'suitable', 'suitcase', 'suited', 'sum', 'summary', 'summer', 'summertime', 'sun', 'sunday', 'sundry', 'sunglass', 'sunlight', 'sunny', 'sunscreen', 'sunshine', 'super', 'superb', 'superbe', 'superbreak', 'superhero', 'superior', 'supper', 'supple', 'supplement', 'supplier', 'supply', 'support', 'suppose', 'supposed', 'supposedly', 'suppurative', 'sure', 'surely', 'surf', 'surface', 'surge', 'surgery', 'surgical', 'surpass', 'surplus', 'surprise', 'surprised', 'surprising', 'surprisingly', 'surround', 'survive', 'suspect', 'suspend', 'swam', 'swamp', 'swan', 'swap', 'swarovski', 'swear', 'sweat', 'sweatpant', 'sweatshirt', 'sweep', 'sweet', 'sweeter', 'swell', 'swim', 'swimmer', 'swimming', 'swimsuit', 'swing', 'swis', 'swiss', 'switch', 'swollen', 'sword', 'symbol', 'synthesis', 'system', 'ta', 'tabe', 'table', 'tablet', 'tack', 'tactical', 'tag', 'tail', 'tailor', 'take', 'talk', 'tall', 'tamarac', 'tangle', 'tank', 'tap', 'tape', 'taper', 'target', 'tarso', 'task', 'taste', 'tattoo', 'tax', 'taylor', 'te', 'tea', 'teach', 'teacher', 'teaching', 'team', 'teamster', 'tear', 'technical', 'technically', 'technique', 'technology', 'teenage', 'teenager', 'telephone', 'tell', 'temp', 'temperature', 'temple', 'temporary', 'tempt', 'ten', 'tend', 'tendency', 'tender', 'tendon', 'tennis', 'tension', 'tent', 'tenth', 'teramar', 'term', 'terrain', 'terrible', 'terribly', 'terrific', 'test', 'testing', 'texas', 'text', 'textbook', 'texture', 'th', 'thailand', 'than', 'thank', 'thankful', 'thanksgiv', 'that', 'the', 'theater', 'thembut', 'theme', 'themthese', 'themthey', 'themthis', 'then', 'theory', 'there', 'therefore', 'thermal', 'thermasilk', 'thermometer', 'these', 'thesethey', 'thick', 'thicker', 'thickness', 'thigh', 'thighigh', 'thighs', 'thin', 'thing', 'think', 'thinking', 'thinner', 'thinness', 'third', 'thirty', 'this', 'thither', 'thorax', 'thorn', 'thoroughly', 'those', 'thou', 'though', 'thought', 'thousand', 'thread', 'threadbare', 'three', 'threw', 'thrifty', 'thrill', 'thrilled', 'through', 'throughout', 'throw', 'thumb', 'thumbs', 'thursday', 'thus', 'thy', 'ti', 'tick', 'ticket', 'tie', 'tien', 'tiger', 'tight', 'tighten', 'tighter', 'tightly', 'tightness', 'til', 'tile', 'tiled', 'till', 'tilt', 'timberland', 'time', 'timekeeping', 'timely', 'timepiece', 'timezone', 'timing', 'timothy', 'tin', 'tint', 'tiny', 'tip', 'tire', 'tired', 'tireless', 'tis', 'tissue', 'tit', 'titanic', 'title', 'titus', 'tm', 'to', 'toast', 'today', 'toe', 'toes', 'together', 'toi', 'toil', 'toilet', 'toiletry', 'tolerable', 'tolerance', 'tolerate', 'toller', 'tomorrow', 'ton', 'tone', 'tongue', 'tonic', 'tonight', 'tonsil', 'too', 'tool', 'tooth', 'toothbrush', 'toothpaste', 'top', 'torn', 'tortoise', 'torture', 'tory', 'toss', 'total', 'totally', 'touch', 'tough', 'tour', 'tourist', 'toward', 'towards', 'towel', 'tower', 'town', 'toy', 'trace', 'track', 'traction', 'trade', 'tradition', 'traditional', 'traffic', 'trail', 'train', 'trainer', 'training', 'tramp', 'transfer', 'transition', 'translate', 'transparent', 'transport', 'trap', 'trash', 'travel', 'traveler', 'traveling', 'traveltime', 'tread', 'treadmill', 'treasure', 'treat', 'treatment', 'tree', 'tremendous', 'trend', 'trial', 'triangle', 'triangular', 'triathlon', 'trick', 'tricky', 'trifle', 'trigger', 'trim', 'trip', 'triple', 'troop', 'tropical', 'trotter', 'trouble', 'trouser', 'truck', 'true', 'truetosize', 'truly', 'trunk', 'trust', 'trusty', 'truth', 'try', 'trying', 'tub', 'tube', 'tuck', 'tucked', 'tug', 'tumble', 'tune', 'tungsten', 'tunic', 'turk', 'turn', 'turquoise', 'turtle', 'turtleneck', 'tut', 'twelve', 'twenty', 'twice', 'twin', 'twist', 'twisted', 'twitch', 'two', 'twofold', 'twotone', 'type', 'typical', 'typically', 'ugh', 'ugly', 'ultimate', 'ultimately', 'ultra', 'ultrasonic', 'umbrella', 'un', 'unable', 'unacceptable', 'unattractive', 'unbearable', 'unbelievable', 'unbelievably', 'uncle', 'uncomfortable', 'under', 'underarm', 'undergarment', 'undermine', 'underneath', 'underpant', 'undershirt', 'undersized', 'understand', 'undertake', 'underwater', 'underwear', 'underwir', 'underwire', 'undo', 'undone', 'uneven', 'unexpected', 'unexpectedly', 'unfordable', 'unfortunate', 'unfortunately', 'unhappy', 'unidirectional', 'uniform', 'union', 'unique', 'unit', 'unite', 'united', 'universal', 'unknown', 'unless', 'unlike', 'unlikely', 'unload', 'unlock', 'unnatural', 'unnecessary', 'unobtrusive', 'unpack', 'unpleasant', 'unravel', 'unseen', 'unsightly', 'untied', 'until', 'unusual', 'unusually', 'unwanted', 'up', 'update', 'updated', 'upgrade', 'uplift', 'upon', 'upper', 'upright', 'upset', 'upside', 'upward', 'upwards', 'urban', 'urge', 'us', 'usage', 'use', 'used', 'useful', 'usefulness', 'useless', 'user', 'usual', 'usually', 'utilitarian', 'utility', 'utilize', 'utterly', 'vacation', 'vagrant', 'valentine', 'valley', 'valuable', 'value', 'van', 'vanity', 'vantage', 'variation', 'variety', 'various', 'varnish', 'varnished', 'vary', 'vector', 'vehicle', 'vein', 'velcro', 'velvet', 'vendor', 'venezuela', 'venice', 'ventilator', 'venture', 'verify', 'versatile', 'versatility', 'version', 'versus', 'vertical', 'very', 'vest', 'via', 'vice', 'victor', 'victoria', 'victory', 'video', 'vienna', 'view', 'viewing', 'vigor', 'vigorous', 'vinegar', 'virtually', 'visibility', 'visible', 'vision', 'visit', 'visitor', 'visual', 'vital', 'vivid', 'vocabulary', 'voice', 'voila', 'vol', 'volume', 'vote', 'vs', 'wa', 'wad', 'wagram', 'waist', 'waistband', 'wait', 'wake', 'walk', 'walker', 'walking', 'walks', 'wall', 'wallerian', 'wallet', 'walnut', 'wan', 'wand', 'wander', 'want', 'wanted', 'war', 'wardrobe', 'ware', 'warehouse', 'warfare', 'warm', 'warmer', 'warmth', 'warn', 'warning', 'warrant', 'warranty', 'wary', 'wash', 'washable', 'washed', 'washerdryer', 'washing', 'washington', 'waste', 'watch', 'watchband', 'watchful', 'watchman', 'watchthe', 'watchthis', 'water', 'wateresistant', 'waterproof', 'waterproofing', 'wave', 'wax', 'way', 'wayfarer', 'weak', 'wealth', 'weapon', 'wear', 'wearer', 'wearing', 'wears', 'weary', 'weather', 'weave', 'web', 'webbing', 'webpage', 'webster', 'wed', 'wedding', 'wedge', 'wee', 'week', 'weekend', 'weekly', 'weeper', 'weigh', 'weight', 'weird', 'welcome', 'welfare', 'welfit', 'well', 'went', 'weren', 'west', 'western', 'wet', 'what', 'whatev', 'whatnot', 'whatsoever', 'wheel', 'wheelchair', 'when', 'whenever', 'whereas', 'wherever', 'whether', 'whichev', 'whim', 'whisper', 'whistle', 'white', 'who', 'whoever', 'whole', 'whose', 'wick', 'wicked', 'wide', 'widely', 'widen', 'wider', 'width', 'wife', 'wig', 'wild', 'wildly', 'will', 'willing', 'win', 'wind', 'windbreaker', 'winding', 'window', 'windsor', 'windy', 'wine', 'wing', 'winner', 'winter', 'wipe', 'wire', 'wirefre', 'wisconsin', 'wise', 'wish', 'with', 'within', 'without', 'withstand', 'wizard', 'wo', 'wodlore', 'wolf', 'woman', 'wonder', 'wonderful', 'wonderfully', 'wood', 'wooden', 'woodland', 'woodwork', 'wool', 'word', 'wore', 'work', 'workbag', 'worked', 'worker', 'workhouse', 'working', 'workmanship', 'workout', 'workshop', 'world', 'worldly', 'worn', 'worried', 'worry', 'worse', 'worth', 'worthless', 'worthwhile', 'worthy', 'would', 'wouldn', 'wound', 'wrangle', 'wrap', 'wreck', 'wrestle', 'wriggle', 'wrinkle', 'wrinkled', 'wrist', 'wristband', 'write', 'writer', 'writing', 'wrong', 'wythe', 'xx', 'yaktrax', 'yard', 'yea', 'yeah', 'year', 'yellow', 'yep', 'yes', 'yesterday', 'yet', 'yoke', 'york', 'young', 'youth', 'zealand', 'zenger', 'zero', 'zip', 'zone']\n"
     ]
    }
   ],
   "source": [
    "# Print feature names\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print (feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ab  abdominal  ability  able  abolish  about  abrasion  abroad  absent  \\\n",
      "0  0.0        0.0      0.0   0.0      0.0    0.0       0.0     0.0     0.0   \n",
      "1  0.0        0.0      0.0   0.0      0.0    0.0       0.0     0.0     0.0   \n",
      "2  0.0        0.0      0.0   0.0      0.0    0.0       0.0     0.0     0.0   \n",
      "3  0.0        0.0      0.0   0.0      0.0    0.0       0.0     0.0     0.0   \n",
      "4  0.0        0.0      0.0   0.0      0.0    0.0       0.0     0.0     0.0   \n",
      "\n",
      "   absolute  ...   yet  yoke  york  young  youth  zealand  zenger  zero  zip  \\\n",
      "0       0.0  ...   0.0   0.0   0.0    0.0    0.0      0.0     0.0   0.0  0.0   \n",
      "1       0.0  ...   0.0   0.0   0.0    0.0    0.0      0.0     0.0   0.0  0.0   \n",
      "2       0.0  ...   0.0   0.0   0.0    0.0    0.0      0.0     0.0   0.0  0.0   \n",
      "3       0.0  ...   0.0   0.0   0.0    0.0    0.0      0.0     0.0   0.0  0.0   \n",
      "4       0.0  ...   0.0   0.0   0.0    0.0    0.0      0.0     0.0   0.0  0.0   \n",
      "\n",
      "   zone  \n",
      "0   0.0  \n",
      "1   0.0  \n",
      "2   0.0  \n",
      "3   0.0  \n",
      "4   0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "features = tfidf_train_features.todense()\n",
    "features_tfidf = np.round(features, 2)\n",
    "display_features(features_tfidf[0:5], feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Averaged Word Vector Features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize documents\n",
    "tokenized_train = [nltk.word_tokenize(text) for text in train_corpus]\n",
    "tokenized_test = [nltk.word_tokenize(text) for text in test_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# build word2vec model                   \n",
    "model = gensim.models.Word2Vec(tokenized_train,\n",
    "                               size=5000,\n",
    "                               window=100,\n",
    "                               min_count=2,\n",
    "                               sample=1e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# averaged word vector features\n",
    "avg_wv_train_features = averaged_word_vectorizer(corpus=tokenized_train,\n",
    "                                                 model=model,\n",
    "                                                 num_features=5000)                   \n",
    "avg_wv_test_features = averaged_word_vectorizer(corpus=tokenized_test,\n",
    "                                                model=model,\n",
    "                                                num_features=5000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.137  0.031 -0.144 ..., -0.038  0.015 -0.078]\n",
      " [ 0.397 -0.162  0.35  ..., -0.028 -0.035 -0.047]\n",
      " [ 0.077  0.035 -0.05  ..., -0.023 -0.026 -0.104]\n",
      " ..., \n",
      " [ 0.255 -0.155  0.278 ..., -0.091  0.059  0.107]\n",
      " [ 0.693 -0.297  0.498 ..., -0.044 -0.097 -0.08 ]\n",
      " [ 0.226 -0.104  0.119 ..., -0.03  -0.004 -0.124]]\n"
     ]
    }
   ],
   "source": [
    "# Print test features\n",
    "print (np.round(avg_wv_test_features, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __TF-IDF Weighted Averaged Word Vector features__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tfidf weighted averaged word vector features\n",
    "vocab = tfidf_vectorizer.vocabulary_\n",
    "tfidf_wv_train_features = tfidf_weighted_averaged_word_vectorizer(corpus=tokenized_train, \n",
    "                                                                  tfidf_vectors=tfidf_train_features, \n",
    "                                                                  tfidf_vocabulary=vocab, \n",
    "                                                                  model=model, \n",
    "                                                                  num_features=5000)\n",
    "tfidf_wv_test_features = tfidf_weighted_averaged_word_vectorizer(corpus=tokenized_test, \n",
    "                                                                 tfidf_vectors=tfidf_test_features, \n",
    "                                                                 tfidf_vocabulary=vocab, \n",
    "                                                                 model=model, \n",
    "                                                                 num_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.198  0.067 -0.203 ..., -0.04   0.014 -0.087]\n",
      " [ 0.399 -0.173  0.339 ..., -0.022 -0.022 -0.053]\n",
      " [ 0.039  0.034 -0.073 ..., -0.017 -0.012 -0.095]\n",
      " ..., \n",
      " [ 0.193 -0.13   0.22  ..., -0.091  0.058  0.098]\n",
      " [ 0.682 -0.285  0.484 ..., -0.043 -0.094 -0.086]\n",
      " [ 0.51  -0.251  0.332 ..., -0.02   0.003 -0.173]]\n"
     ]
    }
   ],
   "source": [
    "# Print test features\n",
    "print (np.round(tfidf_wv_test_features, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluating Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def get_metrics(true_labels, predicted_labels):\n",
    "    print ('Accuracy: ', accuracy_score(true_labels,predicted_labels))\n",
    "    print (classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_predict_evaluate_model(classifier, \n",
    "                                 train_features, train_labels, \n",
    "                                 test_features, test_labels):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    train_predictions = classifier.predict(train_features)\n",
    "    test_predictions = classifier.predict(test_features) \n",
    "    # evaluate model prediction performance \n",
    "    print ('Training set performance:')\n",
    "    get_metrics(true_labels=train_labels, predicted_labels=train_predictions)\n",
    "    print ('Test set performance:')\n",
    "    get_metrics(true_labels=test_labels, predicted_labels=test_predictions)\n",
    "    return test_predictions    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Develop and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Build ML methods\n",
    "clf_LR = LogisticRegression()\n",
    "clf_MNB = MultinomialNB()\n",
    "clf_LSVC = LinearSVC()\n",
    "clf_SGD = SGDClassifier()\n",
    "clf_RFC = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Logistic Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.790583333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.90      0.67      0.77       856\n",
      "          2       0.86      0.55      0.67      1233\n",
      "          3       0.77      0.53      0.63      2274\n",
      "          4       0.71      0.47      0.57      4833\n",
      "          5       0.80      0.96      0.87     14804\n",
      "\n",
      "avg / total       0.79      0.79      0.77     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.652891184803\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.27      0.35       214\n",
      "          2       0.34      0.20      0.25       308\n",
      "          3       0.34      0.22      0.27       569\n",
      "          4       0.40      0.26      0.32      1209\n",
      "          5       0.74      0.91      0.81      3701\n",
      "\n",
      "avg / total       0.60      0.65      0.62      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with bag of words features\n",
    "LR_bow_predictions = train_predict_evaluate_model(classifier=clf_LR,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.703583333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.22      0.35       856\n",
      "          2       0.69      0.19      0.30      1233\n",
      "          3       0.60      0.26      0.37      2274\n",
      "          4       0.56      0.32      0.41      4833\n",
      "          5       0.73      0.97      0.83     14804\n",
      "\n",
      "avg / total       0.68      0.70      0.66     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.656223962673\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.14      0.24       214\n",
      "          2       0.33      0.09      0.14       308\n",
      "          3       0.35      0.16      0.22       569\n",
      "          4       0.42      0.22      0.29      1209\n",
      "          5       0.71      0.95      0.81      3701\n",
      "\n",
      "avg / total       0.59      0.66      0.60      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with tfidf features\n",
    "LR_tfidf_predictions = train_predict_evaluate_model(classifier=clf_LR,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.639916666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.38      0.07      0.11       856\n",
      "          2       0.30      0.02      0.04      1233\n",
      "          3       0.31      0.07      0.12      2274\n",
      "          4       0.39      0.18      0.25      4833\n",
      "          5       0.68      0.96      0.80     14804\n",
      "\n",
      "avg / total       0.56      0.64      0.56     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.641559740043\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.39      0.07      0.11       214\n",
      "          2       0.39      0.03      0.05       308\n",
      "          3       0.31      0.07      0.12       569\n",
      "          4       0.40      0.18      0.25      1209\n",
      "          5       0.68      0.97      0.80      3701\n",
      "\n",
      "avg / total       0.56      0.64      0.56      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with averaged word vector features\n",
    "LR_avgwv_predictions = train_predict_evaluate_model(classifier=clf_LR,\n",
    "                                           train_features=avg_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.633875\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.31      0.04      0.08       856\n",
      "          2       0.22      0.01      0.02      1233\n",
      "          3       0.26      0.05      0.08      2274\n",
      "          4       0.38      0.17      0.23      4833\n",
      "          5       0.67      0.96      0.79     14804\n",
      "\n",
      "avg / total       0.54      0.63      0.55     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.636560573238\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.27      0.03      0.05       214\n",
      "          2       0.57      0.03      0.05       308\n",
      "          3       0.25      0.05      0.08       569\n",
      "          4       0.40      0.17      0.23      1209\n",
      "          5       0.67      0.97      0.79      3701\n",
      "\n",
      "avg / total       0.56      0.64      0.55      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with tfidf weighted averaged word vector features\n",
    "LR_tfidfwv_predictions = train_predict_evaluate_model(classifier=clf_LR,\n",
    "                                           train_features=tfidf_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_wv_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Multinomial Naive Bayes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.714791666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.53      0.59       856\n",
      "          2       0.59      0.46      0.52      1233\n",
      "          3       0.52      0.47      0.49      2274\n",
      "          4       0.52      0.42      0.47      4833\n",
      "          5       0.79      0.88      0.83     14804\n",
      "\n",
      "avg / total       0.70      0.71      0.70     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.634227628729\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.46      0.30      0.37       214\n",
      "          2       0.26      0.18      0.21       308\n",
      "          3       0.29      0.26      0.28       569\n",
      "          4       0.37      0.31      0.33      1209\n",
      "          5       0.77      0.86      0.81      3701\n",
      "\n",
      "avg / total       0.60      0.63      0.62      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes with bag of words features\n",
    "MNB_bow_predictions = train_predict_evaluate_model(classifier=clf_MNB,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.630916666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.01      0.02       856\n",
      "          2       0.83      0.00      0.01      1233\n",
      "          3       0.60      0.02      0.03      2274\n",
      "          4       0.58      0.07      0.13      4833\n",
      "          5       0.63      1.00      0.77     14804\n",
      "\n",
      "avg / total       0.64      0.63      0.51     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.620396600567\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00       214\n",
      "          2       1.00      0.00      0.01       308\n",
      "          3       0.33      0.00      0.01       569\n",
      "          4       0.37      0.03      0.06      1209\n",
      "          5       0.63      0.99      0.77      3701\n",
      "\n",
      "avg / total       0.54      0.62      0.49      6001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toniachu/ProgramFiles/Anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes with tfidf features                                           \n",
    "MNB_tfidf_predictions = train_predict_evaluate_model(classifier=clf_MNB,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Linear Support Vector Classification__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.837375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.96      0.88      0.92       856\n",
      "          2       0.92      0.78      0.84      1233\n",
      "          3       0.83      0.67      0.74      2274\n",
      "          4       0.78      0.55      0.64      4833\n",
      "          5       0.84      0.96      0.90     14804\n",
      "\n",
      "avg / total       0.83      0.84      0.83     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.628895184136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.34      0.30      0.32       214\n",
      "          2       0.26      0.22      0.24       308\n",
      "          3       0.29      0.23      0.26       569\n",
      "          4       0.37      0.25      0.30      1209\n",
      "          5       0.75      0.87      0.80      3701\n",
      "\n",
      "avg / total       0.59      0.63      0.60      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classification with bag of words features\n",
    "LSVC_bow_predictions = train_predict_evaluate_model(classifier=clf_LSVC,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.78375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      0.69      0.77       856\n",
      "          2       0.83      0.54      0.65      1233\n",
      "          3       0.75      0.50      0.60      2274\n",
      "          4       0.68      0.46      0.55      4833\n",
      "          5       0.80      0.96      0.87     14804\n",
      "\n",
      "avg / total       0.78      0.78      0.77     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.653057823696\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.29      0.36       214\n",
      "          2       0.37      0.20      0.26       308\n",
      "          3       0.33      0.21      0.25       569\n",
      "          4       0.39      0.26      0.31      1209\n",
      "          5       0.74      0.91      0.82      3701\n",
      "\n",
      "avg / total       0.60      0.65      0.62      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classification with tfidf features                                           \n",
    "LSVC_tfidf_predictions = train_predict_evaluate_model(classifier=clf_LSVC,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.639666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.03      0.06       856\n",
      "          2       0.48      0.01      0.02      1233\n",
      "          3       0.28      0.04      0.07      2274\n",
      "          4       0.39      0.18      0.24      4833\n",
      "          5       0.67      0.97      0.79     14804\n",
      "\n",
      "avg / total       0.56      0.64      0.55     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.639560073321\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.33      0.02      0.04       214\n",
      "          2       0.43      0.01      0.02       308\n",
      "          3       0.22      0.04      0.06       569\n",
      "          4       0.40      0.17      0.24      1209\n",
      "          5       0.67      0.97      0.79      3701\n",
      "\n",
      "avg / total       0.55      0.64      0.55      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classification with averaged word vector features\n",
    "LSVC_avgwv_predictions = train_predict_evaluate_model(classifier=clf_LSVC,\n",
    "                                           train_features=avg_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.632958333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.35      0.01      0.03       856\n",
      "          2       0.18      0.00      0.01      1233\n",
      "          3       0.26      0.03      0.05      2274\n",
      "          4       0.38      0.15      0.22      4833\n",
      "          5       0.66      0.97      0.79     14804\n",
      "\n",
      "avg / total       0.53      0.63      0.53     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.635060823196\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.33      0.01      0.03       214\n",
      "          2       0.50      0.00      0.01       308\n",
      "          3       0.20      0.02      0.04       569\n",
      "          4       0.38      0.15      0.21      1209\n",
      "          5       0.66      0.98      0.79      3701\n",
      "\n",
      "avg / total       0.54      0.64      0.53      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classification with tfidf weighted averaged word vector features\n",
    "LSVC_tfidfwv_predictions = train_predict_evaluate_model(classifier=clf_LSVC,\n",
    "                                           train_features=tfidf_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_wv_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __SGD Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.716375\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.42      0.54       856\n",
      "          2       0.61      0.34      0.43      1233\n",
      "          3       0.52      0.37      0.43      2274\n",
      "          4       0.52      0.47      0.49      4833\n",
      "          5       0.79      0.90      0.84     14804\n",
      "\n",
      "avg / total       0.70      0.72      0.70     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.628561906349\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.46      0.18      0.26       214\n",
      "          2       0.27      0.16      0.20       308\n",
      "          3       0.32      0.21      0.25       569\n",
      "          4       0.36      0.32      0.34      1209\n",
      "          5       0.74      0.86      0.80      3701\n",
      "\n",
      "avg / total       0.59      0.63      0.60      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier with bag of words features\n",
    "SGD_bow_predictions = train_predict_evaluate_model(classifier=clf_SGD,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.705083333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.87      0.38      0.53       856\n",
      "          2       0.79      0.31      0.44      1233\n",
      "          3       0.71      0.25      0.37      2274\n",
      "          4       0.59      0.23      0.33      4833\n",
      "          5       0.71      0.98      0.82     14804\n",
      "\n",
      "avg / total       0.70      0.71      0.65     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.657557073821\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.24      0.33       214\n",
      "          2       0.37      0.12      0.18       308\n",
      "          3       0.44      0.14      0.21       569\n",
      "          4       0.41      0.15      0.22      1209\n",
      "          5       0.69      0.97      0.81      3701\n",
      "\n",
      "avg / total       0.59      0.66      0.58      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier with tfidf features \n",
    "SGD_tfidf_predictions = train_predict_evaluate_model(classifier=clf_SGD,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.521625\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.15      0.24      0.19       856\n",
      "          2       0.06      0.04      0.05      1233\n",
      "          3       0.24      0.03      0.06      2274\n",
      "          4       0.27      0.48      0.34      4833\n",
      "          5       0.76      0.67      0.71     14804\n",
      "\n",
      "avg / total       0.56      0.52      0.52     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.516080653224\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.18      0.29      0.22       214\n",
      "          2       0.06      0.04      0.05       308\n",
      "          3       0.22      0.03      0.05       569\n",
      "          4       0.26      0.46      0.33      1209\n",
      "          5       0.76      0.66      0.71      3701\n",
      "\n",
      "avg / total       0.55      0.52      0.52      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD Classification with averaged word vector features\n",
    "SGD_avgwv_predictions = train_predict_evaluate_model(classifier=clf_SGD,\n",
    "                                           train_features=avg_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.515458333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.13      0.11      0.12       856\n",
      "          2       0.10      0.20      0.13      1233\n",
      "          3       0.13      0.02      0.03      2274\n",
      "          4       0.27      0.45      0.34      4833\n",
      "          5       0.79      0.66      0.72     14804\n",
      "\n",
      "avg / total       0.56      0.52      0.53     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.5064155974\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.11      0.08      0.09       214\n",
      "          2       0.10      0.21      0.14       308\n",
      "          3       0.09      0.01      0.02       569\n",
      "          4       0.27      0.45      0.33      1209\n",
      "          5       0.78      0.65      0.71      3701\n",
      "\n",
      "avg / total       0.55      0.51      0.52      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD Classification with tfidf weighted averaged word vector features\n",
    "SGD_tfidfwv_predictions = train_predict_evaluate_model(classifier=clf_SGD,\n",
    "                                           train_features=tfidf_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_wv_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Random Forest Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.989416666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.98      0.99       856\n",
      "          2       1.00      0.97      0.99      1233\n",
      "          3       1.00      0.98      0.99      2274\n",
      "          4       0.99      0.97      0.98      4833\n",
      "          5       0.99      1.00      0.99     14804\n",
      "\n",
      "avg / total       0.99      0.99      0.99     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.61106482253\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.29      0.09      0.14       214\n",
      "          2       0.22      0.07      0.10       308\n",
      "          3       0.28      0.10      0.15       569\n",
      "          4       0.33      0.20      0.25      1209\n",
      "          5       0.68      0.90      0.77      3701\n",
      "\n",
      "avg / total       0.53      0.61      0.55      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with bag of words features\n",
    "RFC_bow_predictions = train_predict_evaluate_model(classifier=clf_RFC,\n",
    "                                           train_features=bow_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=bow_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.988041666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.98      0.99       856\n",
      "          2       1.00      0.97      0.98      1233\n",
      "          3       1.00      0.97      0.98      2274\n",
      "          4       1.00      0.97      0.98      4833\n",
      "          5       0.98      1.00      0.99     14804\n",
      "\n",
      "avg / total       0.99      0.99      0.99     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.622562906182\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.25      0.09      0.13       214\n",
      "          2       0.30      0.06      0.11       308\n",
      "          3       0.40      0.12      0.19       569\n",
      "          4       0.32      0.15      0.20      1209\n",
      "          5       0.67      0.93      0.78      3701\n",
      "\n",
      "avg / total       0.54      0.62      0.55      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with tfidf features                                           \n",
    "RFC_tfidf_predictions = train_predict_evaluate_model(classifier=clf_RFC,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.990041666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.98      0.99       856\n",
      "          2       1.00      0.98      0.99      1233\n",
      "          3       0.99      0.98      0.99      2274\n",
      "          4       0.99      0.97      0.98      4833\n",
      "          5       0.99      1.00      0.99     14804\n",
      "\n",
      "avg / total       0.99      0.99      0.99     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.59356773871\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.31      0.13      0.18       214\n",
      "          2       0.19      0.10      0.14       308\n",
      "          3       0.23      0.15      0.19       569\n",
      "          4       0.29      0.23      0.25      1209\n",
      "          5       0.71      0.85      0.77      3701\n",
      "\n",
      "avg / total       0.54      0.59      0.56      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with averaged word vector features\n",
    "RFC_avgwv_predictions = train_predict_evaluate_model(classifier=clf_RFC,\n",
    "                                           train_features=avg_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance:\n",
      "Accuracy:  0.989833333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.99      0.98      0.99       856\n",
      "          2       1.00      0.98      0.99      1233\n",
      "          3       1.00      0.97      0.98      2274\n",
      "          4       0.99      0.98      0.99      4833\n",
      "          5       0.99      1.00      0.99     14804\n",
      "\n",
      "avg / total       0.99      0.99      0.99     24000\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.59073487752\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.24      0.11      0.15       214\n",
      "          2       0.22      0.11      0.15       308\n",
      "          3       0.20      0.12      0.15       569\n",
      "          4       0.29      0.22      0.25      1209\n",
      "          5       0.70      0.85      0.77      3701\n",
      "\n",
      "avg / total       0.53      0.59      0.55      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with tfidf weighted averaged word vector features\n",
    "RFC_tfidfwv_predictions = train_predict_evaluate_model(classifier=clf_RFC,\n",
    "                                           train_features=tfidf_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_wv_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Confusion Matrix for Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>49</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>128</td>\n",
       "      <td>146</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>97</td>\n",
       "      <td>317</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>251</td>\n",
       "      <td>3355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   2    3    4     5\n",
       "1  57  41   20   22    74\n",
       "2  21  61   58   49   119\n",
       "3  20  47  128  146   228\n",
       "4   6  16   97  317   773\n",
       "5   9  12   74  251  3355"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "LR_bow_cm = confusion_matrix(test_labels, LR_bow_predictions)\n",
    "pd.DataFrame(LR_bow_cm, index=range(1,6), columns=range(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>22</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>58</td>\n",
       "      <td>47</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>90</td>\n",
       "      <td>157</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>272</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>157</td>\n",
       "      <td>3517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   2   3    4     5\n",
       "1  31  27  28   22   106\n",
       "2  12  28  58   47   163\n",
       "3   4  21  90  157   297\n",
       "4   2   6  58  272   871\n",
       "5   0   4  23  157  3517"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_tfidf_cm = confusion_matrix(test_labels, LR_tfidf_predictions)\n",
    "pd.DataFrame(LR_tfidf_cm, index=range(1,6), columns=range(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>55</td>\n",
       "      <td>83</td>\n",
       "      <td>56</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>147</td>\n",
       "      <td>172</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>139</td>\n",
       "      <td>370</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>95</td>\n",
       "      <td>384</td>\n",
       "      <td>3169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   2    3    4     5\n",
       "1  65  47   35   23    44\n",
       "2  30  55   83   56    84\n",
       "3  14  52  147  172   184\n",
       "4   9  30  139  370   661\n",
       "5  22  31   95  384  3169"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB_bow_cm = confusion_matrix(test_labels, MNB_bow_predictions)\n",
    "pd.DataFrame(MNB_bow_cm, index=range(1,6), columns=range(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>59</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>118</td>\n",
       "      <td>163</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>93</td>\n",
       "      <td>316</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>66</td>\n",
       "      <td>252</td>\n",
       "      <td>3363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   2    3    4     5\n",
       "1  61  32   29   22    70\n",
       "2  26  61   51   59   111\n",
       "3  22  42  118  163   224\n",
       "4  12  19   93  316   769\n",
       "5   7  13   66  252  3363"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSVC_tfidf_cm = confusion_matrix(test_labels, LSVC_tfidf_predictions)\n",
    "pd.DataFrame(LSVC_tfidf_cm, index=range(1,6), columns=range(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>115</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>182</td>\n",
       "      <td>971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>79</td>\n",
       "      <td>3598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   2   3    4     5\n",
       "1  51  20  13   13   117\n",
       "2  22  36  30   50   170\n",
       "3  11  28  79  115   336\n",
       "4   9   9  38  182   971\n",
       "5   1   4  19   79  3598"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD_tfidf_cm = confusion_matrix(test_labels, SGD_tfidf_predictions)\n",
    "pd.DataFrame(SGD_tfidf_cm, index=range(1,6), columns=range(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>85</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>88</td>\n",
       "      <td>160</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>104</td>\n",
       "      <td>277</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>40</td>\n",
       "      <td>106</td>\n",
       "      <td>396</td>\n",
       "      <td>3137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1   2    3    4     5\n",
       "1  28  23   36   47    80\n",
       "2  14  32   47   85   130\n",
       "3  10  47   88  160   264\n",
       "4  17  24  104  277   787\n",
       "5  22  40  106  396  3137"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_avgwv_cm = confusion_matrix(test_labels, RFC_avgwv_predictions)\n",
    "pd.DataFrame(RFC_avgwv_cm, index=range(1,6), columns=range(1,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 6. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def get_optimal_parameters(classifier, param_grid, \n",
    "                    train_features, train_labels, \n",
    "                    test_features, test_labels):\n",
    "    # Instantiate the GridSearchCV object\n",
    "    classifier_cv = GridSearchCV(classifier, param_grid, cv=5)\n",
    "    # build model    \n",
    "    classifier_cv.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    test_predictions = classifier_cv.predict(test_features) \n",
    "    print(\"Tuned Parameter: {}\".format(classifier_cv.best_params_))\n",
    "    print(\"Tuned Score: {}\".format(classifier_cv.best_score_))\n",
    "    print()\n",
    "    # evaluate model prediction performance \n",
    "    print ('Test set performance:')\n",
    "    get_metrics(true_labels=test_labels, predicted_labels=test_predictions)\n",
    "    # Print the optimal parameters and best score\n",
    "    return classifier_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* __Logistic Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate the GridSearchCV object\n",
    "clf_LR_bow_cv = GridSearchCV(clf_LR, param_grid, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  1.00000e-05,   8.48343e-05,   7.19686e-04,   6.10540e-03,\n",
       "         5.17947e-02,   4.39397e-01,   3.72759e+00,   3.16228e+01,\n",
       "         2.68270e+02,   2.27585e+03,   1.93070e+04,   1.63789e+05,\n",
       "         1.38950e+06,   1.17877e+07,   1.00000e+08]), 'penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it to the training data\n",
    "clf_LR_bow_cv.fit(bow_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set performance:\n",
      "Accuracy:  0.65989001833\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.24      0.33       214\n",
      "          2       0.32      0.12      0.18       308\n",
      "          3       0.38      0.19      0.25       569\n",
      "          4       0.43      0.24      0.31      1209\n",
      "          5       0.72      0.94      0.82      3701\n",
      "\n",
      "avg / total       0.60      0.66      0.61      6001\n",
      "\n",
      "Tuned Parameter: {'C': 0.43939705607607948, 'penalty': 'l1'}\n",
      "Tuned Recall Score: 0.6571666666666667\n"
     ]
    }
   ],
   "source": [
    "# predict using model\n",
    "test_predictions = clf_LR_bow_cv.predict(bow_test_features) \n",
    "# evaluate model prediction performance \n",
    "print ('Test set performance:')\n",
    "get_metrics(true_labels=test_labels, predicted_labels=test_predictions)\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Parameter: {}\".format(clf_LR_bow_cv.best_params_))\n",
    "print(\"Tuned Recall Score: {}\".format(clf_LR_bow_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-3, 2, 9)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameter: {'C': 0.31622776601683794, 'penalty': 'l1'}\n",
      "Tuned Score: 0.6575416666666667\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.658723546076\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.24      0.33       214\n",
      "          2       0.29      0.10      0.15       308\n",
      "          3       0.37      0.17      0.23       569\n",
      "          4       0.43      0.23      0.30      1209\n",
      "          5       0.72      0.94      0.81      3701\n",
      "\n",
      "avg / total       0.60      0.66      0.60      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with bag of words features\n",
    "LR_bow_model = get_optimal_parameters(classifier=clf_LR, param_grid=param_grid, \n",
    "                                    train_features=bow_train_features,\n",
    "                                    train_labels=train_labels,\n",
    "                                    test_features=bow_test_features,\n",
    "                                    test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-3, 2, 9)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameter: {'C': 1.333521432163324, 'penalty': 'l1'}\n",
      "Tuned Recall Score: 0.6625416666666667\n",
      "Test set performance:\n",
      "Accuracy:  0.66272287952\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.25      0.34       214\n",
      "          2       0.31      0.11      0.16       308\n",
      "          3       0.39      0.19      0.25       569\n",
      "          4       0.43      0.24      0.31      1209\n",
      "          5       0.72      0.94      0.82      3701\n",
      "\n",
      "avg / total       0.60      0.66      0.61      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with tfidf features\n",
    "LR_tfidf_model = get_optimal_parameters(classifier=clf_LR, param_grid=param_grid, \n",
    "                                        train_features=tfidf_train_features,\n",
    "                                        train_labels=train_labels,\n",
    "                                        test_features=tfidf_test_features,\n",
    "                                        test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Multinomial Naive Bayes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "alpha_space = np.logspace(-3, 3, 10)\n",
    "param_grid = {'alpha': alpha_space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameter: {'alpha': 2.154434690031882}\n",
      "Tuned Recall Score: 0.63275\n",
      "Test set performance:\n",
      "Accuracy:  0.637727045492\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.22      0.31       214\n",
      "          2       0.29      0.13      0.18       308\n",
      "          3       0.30      0.23      0.26       569\n",
      "          4       0.37      0.32      0.34      1209\n",
      "          5       0.75      0.87      0.81      3701\n",
      "\n",
      "avg / total       0.60      0.64      0.61      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes with bag of words features\n",
    "MNB_bow_model = get_optimal_parameters(classifier=clf_MNB, param_grid=param_grid, \n",
    "                                    train_features=bow_train_features,\n",
    "                                    train_labels=train_labels,\n",
    "                                    test_features=bow_test_features,\n",
    "                                    test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Linear Support Vector Classification__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-3, 2, 10)\n",
    "param_grid = {'C': c_space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameter: {'C': 0.1668100537200059}\n",
      "Tuned Recall Score: 0.657\n",
      "Test set performance:\n",
      "Accuracy:  0.662556240627\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.22      0.33       214\n",
      "          2       0.35      0.12      0.18       308\n",
      "          3       0.36      0.16      0.22       569\n",
      "          4       0.42      0.24      0.30      1209\n",
      "          5       0.72      0.95      0.82      3701\n",
      "\n",
      "avg / total       0.60      0.66      0.61      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Support Vector Classification with tfidf features                                           \n",
    "LSVC_tfidf_model = get_optimal_parameters(classifier=clf_LSVC, param_grid=param_grid, \n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __SGD Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "l1_space = np.linspace(0, 1, 20)\n",
    "param_grid = {'l1_ratio': l1_space}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameter: {'l1_ratio': 0.73684210526315785}\n",
      "Tuned Score: 0.6538333333333334\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.658223629395\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.30      0.35       214\n",
      "          2       0.33      0.11      0.17       308\n",
      "          3       0.40      0.18      0.25       569\n",
      "          4       0.45      0.13      0.20      1209\n",
      "          5       0.70      0.97      0.81      3701\n",
      "\n",
      "avg / total       0.59      0.66      0.59      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier with tfidf features \n",
    "SGD_tfidf_model = get_optimal_parameters(classifier=clf_SGD, param_grid=param_grid,\n",
    "                                           train_features=tfidf_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=tfidf_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Random Forest Classifier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the hyperparameter grid\n",
    "n_options = [10,20,50,100,200]\n",
    "sample_leaf_options = [1,5,10,50,100,200,500]\n",
    "param_grid = {'n_estimators': n_options, 'min_samples_leaf': sample_leaf_options}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Parameter: {'min_samples_leaf': 10, 'n_estimators': 100}\n",
      "Tuned Score: 0.6353333333333333\n",
      "\n",
      "Test set performance:\n",
      "Accuracy:  0.636227295451\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.32      0.04      0.07       214\n",
      "          2       0.36      0.05      0.09       308\n",
      "          3       0.24      0.07      0.10       569\n",
      "          4       0.34      0.16      0.22      1209\n",
      "          5       0.68      0.96      0.80      3701\n",
      "\n",
      "avg / total       0.54      0.64      0.55      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier with averaged word vector features\n",
    "RFC_avgwv_model = get_optimal_parameters(classifier=clf_RFC, param_grid=param_grid,\n",
    "                                           train_features=avg_wv_train_features,\n",
    "                                           train_labels=train_labels,\n",
    "                                           test_features=avg_wv_test_features,\n",
    "                                           test_labels=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
